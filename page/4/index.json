
{
    
    
    
    
    
    
    
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
    "articles": [{"date":"2018-01-13","image":"","imageAlt":"","link":"http://localhost:1313/post/technology/blockchain/bitcoin-intro/","summary":"区块链本质上讲是一个分布式存储，目前流行的比特币/以太坊主要用来存储交易数据，那么是否可以利用这些公链存储别的信息呢？\n当然是有的，收集了几篇关于如何使用区块链存储数据文章，回头有空了再来整理一下。\nhttp://www.righto.com/2014/02/ascii-bernanke-wikileaks-photographs.html https://bitcoin.stackexchange.com/questions/39347/how-to-store-data-on-the-blockchain https://ethereum.stackexchange.com/questions/7884/how-can-i-store-data-in-ethereum-blockchain https://docs.google.com/document/d/1UwaaUgunnrFpL6jetA_DdNLQsbbqBx1HLcln07kLrUw/edit ","tags":["blockchain"],"title":"在区块链上存储信息"},{"date":"2018-01-11","image":"","imageAlt":"","link":"http://localhost:1313/post/bigdata/spark/spark-intro/","summary":"使用scala进行开发 Step1: 安装sbt 配置源：\nStep2: 创建项目 可以使用Giter8模版创建项目。\nspark相关的几个模版：\nholdenk/sparkProjectTemplate.g8 (Template for Scala Apache Spark project). imarios/frameless.g8 (A simple frameless template to start with more expressive types for Spark) nttdata-oss/basic-spark-project.g8 (Spark basic project.) spark-jobserver/spark-jobserver.g8 (Template for Spark Jobserver) Step3: 编写代码 创建出的项目目录中包含一下主要条目：\n编写的代码放在 \u0026lsquo;src/main/scala/\u0026rsquo; 目录中：\nStep4: 编译打包 程序开发好之后首先需要编译打包：\n编译打包成功后的文件输出在 \u0026rsquo;target/scala-2.11/\u0026rsquo; 目录中：\n/home/spark/scala/frameless/target/scala-2.11/frameless_2.11-0.1.jar\nStep5: 部署运行 \u0026ndash;master: 指定spark driver的运行模式。 yarn-cluster: spark driver运行在yarn的application master进程中。如果应用只是进行计算可以使用这种方式运行，如果需要跟前台进行交互则可以考虑yarn-client模式。 yarn-client: spark driver运行在client进程中，此时application master只负责向yarn申请资源。 使用python进行开发 使用HDP环境提交任务 创建python文件pi.py\nimport sys from random import random from operator import add from pyspark.","tags":["python","scala","spark"],"title":"Spark开发"},{"date":"2018-01-11","image":"","imageAlt":"","link":"http://localhost:1313/post/bigdata/hive/hive-intro/","summary":"Reference * Hive document ","tags":["Hive"],"title":"Hive Intro"},{"date":"2018-01-11","image":"","imageAlt":"","link":"http://localhost:1313/post/bigdata/hcatalog/hcatalog/","summary":"HCatalog是Hadoop生态链中的一个有趣的组件。HCatalog构建于Hive的metastore之上并结合了Hive的DDL，通过服务的形式开放给Hadoop生态链中的其他组件，这样即可用一种统一的形式将Hive数据仓库中的数据的metadata开放给需要的服务，这样的话需要的服务就可以通过HCatalog来了解到所使用的数据的内容以及格式等等元信息。\n下图展示了HCatalog在Hadoop生态系统中的定位：\n可以看出HCatalog内置可以支持多种数据格式：\nORC RC Text SequenceFile 另外用户还可以自定义格式，不过需要编写InputFormat, OutputFormat, SerDe(Serializer/Deserializer):\nHCatalog提供了\u0026rsquo;hcat'\n参数**-e**提供了使用Hive \u0026lsquo;DDL\u0026rsquo;命令的接口\nDDL命令 解释 CREATE TABLE 建表操作，注意如果建表时使用了“CLUSTERED BY”那么这个表不能被Pig和MapReduce使用 ALTER TABLE 修改表 SHOW TABLES 查询表 DROP TABLE 删除表 CREATE/ALTER/DROP VIEW 管理view SHOW PARTITIONS 查询分区表的分区信息 Create/Drop Index 管理index DESCRIBE 查询表结构 例子：\nAPIs\nAPI 解释 HCatReader 从hdfs中读取数据 HCatWriter 向hdfs中写入数据 DataTransferFactory 创建HCatReader/HCatWriter实例 HCatInputFormat 利用MapReduce job从表结构由HCatalog管理的表中读取并处理数据 HCatOutputFormat 利用MapReduce job处理数据并向表结构由HCatalog管理的表中写入数据 HCatLoader Pig script用来读取表结构由HCatalog管理的数据 HCatStorer Pig script用来写入表结构由HCatalog管理的数据 参考信息 HCataLog quick guide Hive metastore ","tags":["HCatalog"],"title":"Hcatalog简介"},{"date":"2017-12-29","image":"","imageAlt":"","link":"http://localhost:1313/post/bigdata/yarn/yarn-config/","summary":"Resource manager\nNode manager\nApplication master\n资源\nContainer\ncontainer所需资源，minimum/maximum memory/vcores Scheduler\nFIFO CapacityScheduler FairScheduler Queue\nApplication \u0026mdash; scheduler \u0026mdash;\u0026gt; Queue\nyarn-site.xml中配置。\n下文引用自http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/\nNode manager Node manager architecture\nResourceManager相关配置参数 （1） yarn.resourcemanager.address 参数解释：ResourceManager 对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等。\n默认值：${yarn.resourcemanager.hostname}:8032\n（2） yarn.resourcemanager.scheduler.address 参数解释：ResourceManager 对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等。\n默认值：${yarn.resourcemanager.hostname}:8030\n（3） yarn.resourcemanager.resource-tracker.address 参数解释：ResourceManager 对NodeManager暴露的地址.。NodeManager通过该地址向RM汇报心跳，领取任务等。 默认值：${yarn.resourcemanager.hostname}:8031\n（4） yarn.resourcemanager.admin.address 参数解释：ResourceManager 对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等。\n默认值：${yarn.resourcemanager.hostname}:8033\n（5） yarn.resourcemanager.webapp.address 参数解释：ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息。\n默认值：${yarn.resourcemanager.hostname}:8088\n（6） yarn.resourcemanager.scheduler.class 参数解释：启用的资源调度器主类。目前可用的有FIFO、Capacity Scheduler和Fair Scheduler。\n默认值： org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\n（7） yarn.resourcemanager.resource-tracker.client.thread-count 参数解释：处理来自NodeManager的RPC请求的Handler数目。\n默认值：50\n（8） yarn.resourcemanager.scheduler.client.thread-count 参数解释：处理来自ApplicationMaster的RPC请求的Handler数目。\n默认值：50\n（9） yarn.","tags":["Yarn"],"title":"Yarn Config"},{"date":"2017-12-25","image":"","imageAlt":"","link":"http://localhost:1313/post/bigdata/sqoop/sqoop/","summary":"1. HDP中使用sqoop进行工作流处理准备工作 1.1 准备hdfs中的用户目录 在进行hdfs操作前需要切换用户到\u0026rsquo;hdfs'\n# su - hdfs 为操作用户创建hdfs环境\n此处为ambari的admin用户准备环境：\n$ hdfs dfs -mkdir /user/admin $ hdfs dfs -chown admin:hdfs /user/admin $ hdfs dfs -ls /user $ hdfs dfs -chmod -R 770 /user/admin 1.2 配置ozzie 设置ozzie进程在hdfs中的proxy user\n配置项：hadoop.proxyuser.oozie.groups 值：$USER_GROUPS_THAT_ALLOW_IMPERSONATION 配置项: hadoop.proxyuser.oozie.hosts 值：$OOZIE_SERVER_HOSTNAME PS. 代理机制 ：http://dongxicheng.org/mapreduce-nextgen/hadoop-secure-impersonation/\n主备namenode和resoucemanager（hadoop 2.0）上的core-site.xml中增加以下配置:\n\u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.proxyuser.oozie.groups\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;group1,group2\u0026lt;value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.proxyuser.oozie.hosts\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;host1,host2\u0026lt;value\u0026gt; \u0026lt;/property\u0026gt; 这里，假设用户user1属于group1（注意，这里的user1和group1都是linux用户和用户组，需要在namenode和jobtracker上进行添加），此外，为了限制客户端随意部署，超级用户代理功能只支持host1和host2两个节点。经过以上配置后，在host1和host2上的客户端上，属于group1和group2的用户可以sudo成oozie用户，执行作业流。\n拷贝mysql-connector及配置 切换到oozie用户后执行：\n# 复制mysql-connector $ hdfs dfs -put /$PATH/mysql-connector-java-5.1.37.jar /user/oozie/share/lib/lib_$TIMESTAMP/sqoop # 复制配置文件 $ hdfs dfs -put /etc/hive/conf/hive-site.","tags":["ETL","Hadoop","Sqoop"],"title":"Sqoop介绍及使用"},{"date":"2017-12-23","image":"","imageAlt":"","link":"http://localhost:1313/post/network/web/nginx/nginx-static/","summary":"nginx配置静态文件服务器\n搭建文件服务器 要点就是root目录,会自动指向索引文件 如： index, index.html等\nserver { client_max_body_size 4G; listen 80; ## listen for ipv4; this line is default and implied server_name static.test.sdk.iwplay.com.tw; root /home/mini/Sync; location / { } } 建立索引 建立目录索引也同样如此，不要带索引名称之类的文件，否则会直接显示文件，而不是目录\nserver { client_max_body_size 4G; listen 80; ## listen for ipv4; this line is default and implied server_name static.test.sdk.iwplay.com.tw; root /home/mini/Sync; location / { autoindex on; //显示索引 autoindex_exact_size on; //显示大小 autoindex_localtime on; //显示时间 } } 设置密码 搭建文件服务器有时候不想让别人任意访问，想做成一个私有的该怎么办呢，这个时候我们可以用到nginx自带的认证模块。 同样关键的是auth_basic/auth_basic_user_file字段","tags":["nginx","static"],"title":"Nginx Static"},{"date":"2017-12-23","image":"","imageAlt":"","link":"http://localhost:1313/post/bigdata/hadoop/hdp/","summary":"安装ambari-server # yum install ambari-server 配置ambari cluster # ambari-server setup # ambari-server start 配置cluster 步骤1:\n将clsuter中的所有node设置成ssh免密码登录了的方式。\n步骤2:\n访问 http://\u0026lt;ambari-server\u0026gt;:8080\n步骤3:\n设置cluster名称\n步骤4:\n配置安装源，可以使用私有源：\nHDP私有源：\nhttp://hdp-repo.iwaterdata.com:7300/HDP/centos7/2.x/updates/2.6.3.0 HDP-UTILS私有源：\nhttp://hdp-repo.iwaterdata.com:7300/HDP-UTILS-1.1.0.21/repos/centos7 步骤5:\n安装程序检查配置节点\n步骤6:\n选择安装软件列表\n步骤7:\n设置各软件的配置信息\n步骤8:\n安装完成后程序会尝试启动各服务，有可能启动会失败（比如内存不足无法启动所有程序），只要确定程序正确安装可以继续\nmisc 设置JDBC driver(Customize service中 oozie需要)\n# ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar ","tags":["Ambari","Hadoop","Hortonworks"],"title":"Horwonworks HDP 2.6安装过程"},{"date":"2017-12-05","image":"","imageAlt":"","link":"http://localhost:1313/post/programming/go/golang-udp/","summary":"学习golang进行UDP client/server通讯的过程中发现Read/ReadFromUDP/Write/WriteToUDP的使用有些需要注意之处，这里记录一下。\n代码实验 UDP server UDP服务器端在调用\u0026quot;net.ListenUDP()\u0026ldquo;后创建\u0026quot;net.UDPConn\u0026rdquo;，read/write操作是通过这个UDPConn来完成的。因为listen的时候只指定了本地绑定的地址，它只能被动的接收来自客户端的消息，因此这个UDPConn在golang中为\u0026rsquo;unconnected\u0026rsquo;类型的。\n这种类型的UDPConn的读操作可以接受Read()及ReadFromUDP()。区别是Read()无法知道远程连接的地址信息而ReadFromUDP()可以，所以如果后续需要跟远程进行双向通讯需要使用ReadFromUDP()。\n这种类型的UDPConn在进行写操作时必须使用WriteToUDP()完成，并且需要指定对方的地址信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) var host = flag.String(\u0026#34;host\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Specify the hostname\u0026#34;) var port = flag.","tags":["golang","Read","ReadFromUDP","UDP","Write","WriteToUDP"],"title":"golang UDP中Read()/ReadFromUDP()/Write()/WriteToUDP()的使用"},{"date":"2017-12-02","image":"","imageAlt":"","link":"http://localhost:1313/post/programming/go/go-deps/","summary":"学习GO开发的过程中发现GO的依赖管理有些不够合理之处。\n首先，使用GO开发时在假设项目及依赖关系都通过全系统唯一的GOPATH进行管理，可事实上一个开发人员不可能同时只做一个项目开发，不能假设不同项目的依赖都是一致的。这个问题自从v1.5引入vendor管理方法得到了一定改善。可是go get对vendor支持并不友好，这增加了管理的工作量。很多项目也被开发出来解决这个问题，比如\u0026rsquo;govendor\u0026rsquo;。\n引入vendor方法后的项目依赖查找顺序如下：\n首先查找当前包下面的vendor目录 向上一级目录查找，直至找到src目录下的vendor目录 在GOPATH下面查找 在GOROOT下面查找 第二个不合理的地方，虽然引入了vendor目录解决单独项目的局部依赖管理问题，但依然要求把每个项目放入系统全局GOPATH中进行管理。可是一个项目可能只是一个大项目中的一小部分，而整个大项目可能有不同的开发语言构成，那么管理这种混合项目就是一个很麻烦的事情。另外每一个项目本身随着开发时间的推移会出现多个版本，当你在处理一个版本的问题是可能需要临时切换到另一个版本，基于同一个GOPATH目录开发时对于这种切换管理也并不算友好。\u0026lsquo;gb\u0026rsquo;这个项目开发出来后解决了这一问题，但这导致了项目管理必须使用gb工具，就连基本的build也脱离不开这种依赖，这也导致了本人碰到的第三个问题。\n第三个不合理之处是对于编辑器的不友好。由于个人的主要编辑器是vim，并且使用了vim-go插件，这个插件支持了Go的开发工具链，可以在vim中方便的使用GoFmt/GoImports/GoBuild/GoTest等这些命令进行开发。但是由于gb对vim的支持欠缺导致在gb创建的项目若不放入标准的GOPATH中有些vim-go的命令执行会出现问题。","tags":["dependency management","Go"],"title":"GO语言依赖管理那些事儿"}],
    "test": "基于 Kalman filter 的目标跟踪   在 Apple silicon (M3 Max) 上对 Llama2 进行微调   tmux AI 助手   使用 ros::waitForShutdown() 导致 dynamic_reconfigure::Server 无法正常获取配置更新的问题   django-rest-framework 和 simplejwt 的类关系   PCL 点云数据过滤处理   Python 内存管理   Wechat_development   左乘/右乘旋转   多媒体格式标准、H264 编码与 MP4 格式简要介绍   摄像机模型及实现   旋转矩阵   NLP 资源整理   ssh代理方法   机器学习笔记 - 贝叶斯分类法推导   VMware ESXi 6.7.0 update2 使用 GPU Passthrough 模式的坑   Firefox cache2 数据结构解析   哈希计算图片相似性   机器学习 - 决策树   模型评估指标   机器学习资料收集   阿里ECS服务器使用腾讯企业邮箱发送SMTP邮件的问题   解决flask_restful无法对Decimal类型数据进行序列化问题   Build Tensorflow v1.7 on NVIDIA Jetson tx2   说一说反弹shell   使用Python的Selenium驱动浏览器行为   自动饮水机   使用Nvidia Jetson TX2挖以太币   python2 和 python3 的一些区别   Mysql charset/collation字符编码设置   在区块链上存储信息   Spark开发   Hive Intro   Hcatalog简介   Yarn Config   Sqoop介绍及使用   Nginx Static   Horwonworks HDP 2.6安装过程   golang UDP中Read()/ReadFromUDP()/Write()/WriteToUDP()的使用   GO语言依赖管理那些事儿   Beego开发入门   Git Submodule使用方法   Vim 8 Mac   Hyperledger Intro   Django静态文件配置   Go语言编程陷阱   GO开发技巧   Temp Sensor Comparasion   使用vim进行16进制编辑   Go语言中new与make的比较   GO语言中array与slice的比较   Docker   Macbook Air换电池记   softmax输出层公式推导及代码实验   神经网络之反向传播算法   在 Nvidia Jetson TX2 上编译安装tensorflow   数学期望、方差、标准差、协方差   The Current State of Machine Intelligence (from Shivon Zilis)   用scrapy爬取京东商品信息   神经网络实践：自动驾驶   图像卷积实践   python中__main__的作用域及变量使用   nmap NSE脚本中host/port的内容   esp8266_sprint_float   esp8266启动模式 - 如何理解'rst cause:2, boot mode:(3,6)'   在ESP 8266 nodeMCU上运行MQTT   如何在CentOS上部署shadowsocks服务   使用Arduino IDE进行nodeMCU开发   在Mac OS上设置ESP 8266开发环境   numpy学习笔记[1]   postgres数据库使用指南   tensorflow playground   玩转阿波罗11号飞船导航计算机模拟器   阿里云ECS EIP服务进行IPv6改造的方法   一行代码让你的字符终端下起雪来！   搭建SoftEther VPN 服务   使用nginx搭建hugo静态blog服务         Manifest   Search   SearchEngine   ",
    "page": "4",
    "next": 
        "http://localhost:1313/page/5/index.json"
    
}


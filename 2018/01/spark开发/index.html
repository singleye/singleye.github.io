

  
    
  


  





  

<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.49 with theme Tranquilpeak 0.4.3-BETA">
    <title>Spark开发</title>
    <meta name="author" content="singleye">
    <meta name="keywords" content="spark, scala, python">

    <link rel="icon" href="https://www.singleye.net/favicon.png">
    

    
    <meta name="description" content="使用scala进行开发 Step1: 安装sbt  $ curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo $ sudo yum install sbt  配置源：
 # cat ~/.sbt/repositories [repositories] # 本地源 local # 阿里源 aliyun: http://maven.aliyun.com/nexus/content/groups/public/ typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly sonatype-oss-releases maven-central sonatype-oss-snapshots  Step2: 创建项目 可以使用Giter8模版创建项目。
 $ sbt new imarios/frameless.g8  spark相关的几个模版：
 holdenk/sparkProjectTemplate.g8 (Template for Scala Apache Spark project). imarios/frameless.g8 (A simple frameless template to start with more expressive types for Spark) nttdata-oss/basic-spark-project.">
    <meta property="og:description" content="使用scala进行开发 Step1: 安装sbt  $ curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo $ sudo yum install sbt  配置源：
 # cat ~/.sbt/repositories [repositories] # 本地源 local # 阿里源 aliyun: http://maven.aliyun.com/nexus/content/groups/public/ typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly sonatype-oss-releases maven-central sonatype-oss-snapshots  Step2: 创建项目 可以使用Giter8模版创建项目。
 $ sbt new imarios/frameless.g8  spark相关的几个模版：
 holdenk/sparkProjectTemplate.g8 (Template for Scala Apache Spark project). imarios/frameless.g8 (A simple frameless template to start with more expressive types for Spark) nttdata-oss/basic-spark-project.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Spark开发">
    <meta property="og:url" content="/2018/01/spark%E5%BC%80%E5%8F%91/">
    <meta property="og:site_name" content="好奇心是探索未知世界的钥匙">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="好奇心是探索未知世界的钥匙">
    <meta name="twitter:description" content="使用scala进行开发 Step1: 安装sbt  $ curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo $ sudo yum install sbt  配置源：
 # cat ~/.sbt/repositories [repositories] # 本地源 local # 阿里源 aliyun: http://maven.aliyun.com/nexus/content/groups/public/ typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly sonatype-oss-releases maven-central sonatype-oss-snapshots  Step2: 创建项目 可以使用Giter8模版创建项目。
 $ sbt new imarios/frameless.g8  spark相关的几个模版：
 holdenk/sparkProjectTemplate.g8 (Template for Scala Apache Spark project). imarios/frameless.g8 (A simple frameless template to start with more expressive types for Spark) nttdata-oss/basic-spark-project.">
    
    

    
    

    
      <meta property="og:image" content="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/images/avatar.png">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://www.singleye.net/css/style-xlk5y0ryj5axy7jbwodqvhtodmk0fc90eewtlacey1uvrjqw1eaqwgcyz4xb.min.css" />
    
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-90087618-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\$', '\$']]                  
    }
  };
</script>


  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="2">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://www.singleye.net/">好奇心是探索未知世界的钥匙</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://www.singleye.net/#about">
    
    
    
      
        <img class="header-picture" src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/images/avatar.png" alt="作者的图片" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="2">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://www.singleye.net/#about">
          <img class="sidebar-profile-picture" src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/images/avatar.png" alt="作者的图片" />
        </a>
        <h4 class="sidebar-profile-name">singleye</h4>
        
          <h5 class="sidebar-profile-bio"><strong>Email:</strong> <a href="mailto:singleye512@gmail.com">singleye512@gmail.com</a></h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.singleye.net/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">首页</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.singleye.net/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">分类</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.singleye.net/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">标签</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.singleye.net/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">归档</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.singleye.net/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">关于</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/singleye" target="_blank" rel="noopener">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.singleye.net/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="2"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Spark开发
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-01-11T23:10:50&#43;08:00">
        
  一月 11, 2018

      </time>
    
    
  
  
    <span>发布在</span>
    
      <a class="category-link" href="https://www.singleye.net/categories/bigdata">BigData</a>, 
    
      <a class="category-link" href="https://www.singleye.net/categories/spark">Spark</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              

<h2 id="使用scala进行开发">使用scala进行开发</h2>

<h3 id="step1-安装sbt">Step1: 安装sbt</h3>

<pre><code>
$ curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo
$ sudo yum install sbt
</code></pre>

<p>配置源：</p>

<pre><code>
# cat ~/.sbt/repositories
[repositories]
  # 本地源
  local
  # 阿里源
  aliyun: http://maven.aliyun.com/nexus/content/groups/public/
  typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly
  sonatype-oss-releases
  maven-central
  sonatype-oss-snapshots
</code></pre>

<h3 id="step2-创建项目">Step2: 创建项目</h3>

<p>可以使用Giter8模版创建项目。</p>

<pre><code>
$ sbt new imarios/frameless.g8
</code></pre>

<p>spark相关的几个模版：</p>

<ul>
<li>holdenk/sparkProjectTemplate.g8 (Template for Scala Apache Spark project).</li>
<li>imarios/frameless.g8 (A simple frameless template to start with more expressive types for Spark)</li>
<li>nttdata-oss/basic-spark-project.g8 (Spark basic project.)</li>
<li>spark-jobserver/spark-jobserver.g8 (Template for Spark Jobserver)</li>
</ul>

<h3 id="step3-编写代码">Step3: 编写代码</h3>

<p>创建出的项目目录中包含一下主要条目：</p>

<pre><code>
$ ls
build.sbt  project  src  target
</code></pre>

<p>编写的代码放在 &lsquo;src/main/scala/&rsquo; 目录中：</p>

<pre><code>
$ ls src/main/scala/
SimpleApp.scala

$ cat src/main/scala/SimpleApp.scala
import org.apache.spark.sql.SparkSession

object SimpleApp {
  def main(args: Array[String]) {
    val logFile = "people.txt" // Should be some file on your system
    val spark = SparkSession.builder.appName("Simple Application").getOrCreate()
    val logData = spark.read.textFile(logFile).cache()
    val numAs = logData.filter(line => line.contains("a")).count()
    val numBs = logData.filter(line => line.contains("b")).count()
    println(s"Lines with a: $numAs, Lines with b: $numBs")
    spark.stop()
  }
}
</code></pre>

<h3 id="step4-编译打包">Step4: 编译打包</h3>

<p>程序开发好之后首先需要编译打包：</p>

<pre><code>
$ sbt package
[info] Loading project definition from /home/spark/scala/frameless/project
[info] Updating {file:/home/spark/scala/frameless/project/}frameless-build...
[info] Resolving org.fusesource.jansi#jansi;1.4 ...
[info] Done updating.
[info] Set current project to frameless (in build file:/home/spark/scala/frameless/)
[info] Updating {file:/home/spark/scala/frameless/}root...
[info] Resolving org.sonatype.oss#oss-parent;9 ...
[info] downloading https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.11.11/scala-library-2.11.11.jar ...
[info]  [SUCCESSFUL ] org.scala-lang#scala-library;2.11.11!scala-library.jar (94788ms)

...

[info] downloading https://repo1.maven.org/maven2/jline/jline/2.14.3/jline-2.14.3.jar ...
[info]  [SUCCESSFUL ] jline#jline;2.14.3!jline.jar (4836ms)
[info] Done updating.
[info] Compiling 1 Scala source to /home/spark/scala/frameless/target/scala-2.11/classes...
[info] 'compiler-interface' not yet compiled for Scala 2.11.11. Compiling...
[info]   Compilation completed in 24.981 s
[info] Packaging /home/spark/scala/frameless/target/scala-2.11/frameless_2.11-0.1.jar ...
[info] Done packaging.
[success] Total time: 2795 s, completed Jan 16, 2018 3:03:12 PM
</code></pre>

<p>编译打包成功后的文件输出在 &lsquo;target/scala-2.11/&rsquo; 目录中：</p>

<p>/home/spark/scala/frameless/target/scala-2.11/frameless_2.11-0.1.jar</p>

<h3 id="step5-部署运行">Step5: 部署运行</h3>

<pre><code>
# su - spark
$ export SPARK_MAJOR_VERSION=2

$ spark-submit --class SimpleApp --master yarn-client --num-executors 1 --driver-memory 512m --executor-memory 512m --executor-cores 1 target/scala-2.11/frameless_2.11-0.1.jar
SPARK_MAJOR_VERSION is set to 2, using Spark2
Warning: Master yarn-client is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
18/01/17 15:20:18 INFO SparkContext: Running Spark version 2.2.0.2.6.3.0-235
18/01/17 15:20:19 INFO SparkContext: Submitted application: Simple Application
18/01/17 15:20:19 INFO SecurityManager: Changing view acls to: spark
18/01/17 15:20:19 INFO SecurityManager: Changing modify acls to: spark
18/01/17 15:20:19 INFO SecurityManager: Changing view acls groups to:
18/01/17 15:20:19 INFO SecurityManager: Changing modify acls groups to:
18/01/17 15:20:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view
 permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
18/01/17 15:20:20 INFO Utils: Successfully started service 'sparkDriver' on port 43573.

...

18/01/17 15:21:30 INFO YarnScheduler: Adding task set 3.0 with 1 tasks
18/01/17 15:21:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, bdtest-002, executor 1, partition 0, NODE_LOCAL, 4737 bytes)
18/01/17 15:21:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on bdtest-002:44065 (size: 3.7 KB, free: 93.2 MB)
18/01/17 15:21:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.1.4:44312
18/01/17 15:21:30 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 141 bytes
18/01/17 15:21:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 96 ms on bdtest-002 (executor 1) (1/1)
18/01/17 15:21:30 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool
18/01/17 15:21:30 INFO DAGScheduler: ResultStage 3 (count at SimpleApp.scala:10) finished in 0.096 s
18/01/17 15:21:30 INFO DAGScheduler: Job 1 finished: count at SimpleApp.scala:10, took 0.289165 s
Lines with a: 1, Lines with b: 0
18/01/17 15:21:30 INFO AbstractConnector: Stopped Spark@17b03218{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
18/01/17 15:21:30 INFO SparkUI: Stopped Spark web UI at http://192.168.1.5:4042
18/01/17 15:21:30 INFO YarnClientSchedulerBackend: Interrupting monitor thread
18/01/17 15:21:30 INFO YarnClientSchedulerBackend: Shutting down all executors
18/01/17 15:21:30 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
18/01/17 15:21:30 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
18/01/17 15:21:30 INFO YarnClientSchedulerBackend: Stopped
18/01/17 15:21:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/01/17 15:21:31 INFO MemoryStore: MemoryStore cleared
18/01/17 15:21:31 INFO BlockManager: BlockManager stopped
18/01/17 15:21:31 INFO BlockManagerMaster: BlockManagerMaster stopped
18/01/17 15:21:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/01/17 15:21:31 INFO SparkContext: Successfully stopped SparkContext
18/01/17 15:21:31 INFO ShutdownHookManager: Shutdown hook called
18/01/17 15:21:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-730219ef-2995-4225-8743-5769fa6269db
</code></pre>

<ul>
<li>&ndash;master: 指定spark driver的运行模式。

<ul>
<li>yarn-cluster: spark driver运行在yarn的application master进程中。如果应用只是进行计算可以使用这种方式运行，如果需要跟前台进行交互则可以考虑yarn-client模式。</li>
<li>yarn-client: spark driver运行在client进程中，此时application master只负责向yarn申请资源。</li>
</ul></li>
</ul>

<h2 id="使用python进行开发">使用python进行开发</h2>

<h3 id="使用hdp环境提交任务">使用HDP环境提交任务</h3>

<p>创建python文件<code>pi.py</code></p>

<pre><code>import sys
from random import random
from operator import add

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;PythonPi&quot;)\.getOrCreate()

partitions = int(sys.argv[1]) if len(sys.argv) &gt; 1 else 2
n = 100000 * partitions

def f(any):
    x = random() * 2 - 1
    y = random() * 2 - 1
    return 1 if x ** 2 + y ** 2 &lt;= 1 else 0

count = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)
print(&quot;Pi is roughly %f&quot; % (4.0 * count / n))

spark.stop()
</code></pre>

<p>运行<code>pi.py</code>，这里指定使用yarn的cluster模式</p>

<pre><code>SPARK_MAJOR_VERSION=2 spark-submit --master yarn --deploy-mode cluster --driver-memory 512m --executor-memory 512m --deploy pi.py 10
</code></pre>

<h3 id="在hdp环境运行jupyter-server">在HDP环境运行jupyter server</h3>

<p>使用yarn的cluster模式运行，在运行期间会始终在yarn中占用资源，如果需要长期运行，使用<code>--master local</code>比较好</p>

<pre><code>XDG_RUNTIME_DIR=&quot;&quot; SPARK_MAJOR_VERSION=2 PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 121.43.171.231' pyspark --master yarn --deploy-mode cluster --driver-memory 512m --executor-memory 512m
</code></pre>

<p>为jupyter server设置密码等操作参考<a href="https://jupyter-notebook.readthedocs.io/en/stable/public_server.html">jupyter文档</a></p>

<p>运行后访问服务器8888端口即可访问jupyter服务</p>

<h3 id="非hdp环境开发">非HDP环境开发</h3>

<p>确保本机有一份spark二进制文件，比如<code>spark-2.2.1-bin-hadoop2.7</code></p>

<p>安装pyspark</p>

<pre><code>pip install pyspark
</code></pre>

<p>设置SPARK_HOME（可选）</p>

<pre><code>export SPARK_HOME=/home/xxx/spark-2.2.1-bin-hadoop2.7
</code></pre>

<p>通过代码提交任务</p>

<pre><code>import os
from pyspark import SparkConf, SparkContext

# if `SPARK_HOME` is undefined yet
if 'SPARK_HOME' not in os.environ:
    os.environ['SPARK_HOME'] = '/home/xxx/spark-2.2.1-bin-hadoop2.7'

conf = SparkConf().setAppName('Demo').setMaster('yarn').set('spark.yarn.deploy.mode', 'cluster')
sc = SparkContext(conf=conf)

# Do something with sc...
</code></pre>

<p>或者使用<code>SparkSession</code> API</p>

<pre><code>from spark.sql import SparkSession
spark = (SparkSession.builder
          .master(&quot;yarn&quot;)
          .appName(&quot;Demo&quot;)
          .config(&quot;spark.yarn.deploy.mode&quot;, &quot;cluster&quot;)
          .getOrCreate())

# Do something with spark...
</code></pre>

<h1 id="oozie自动化">oozie自动化</h1>

<p>TODO</p>

<h1 id="development">Development</h1>

<p>Spark 2.0之前的开发接口主要是RDD（Resilient Distributed Dataset），从2.0之后原有<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html">RDD接口</a>仍然支持，但RDD被Dataset取代，如果使用Dataset编程的话需要使用<a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a>。</p>

<h2 id="api">API</h2>

<p><a href="http://spark.apache.org/docs/1.3.1/api/scala/index.html">http://spark.apache.org/docs/1.3.1/api/scala/index.html</a></p>

<h2 id="sparksession-vs-sparkcontext">SparkSession vs SparkContext</h2>

<p>Spark 2.0之前有3个主要的连接对象：</p>

<ul>
<li>SparkContext: 建立与Spark执行环境相关的连接，用于创建RDD</li>
<li>SqlContext：利用SparkContext背后的SparkSQL建立连接</li>
<li>HiveContext：创建访问hive的接口</li>
</ul>

<p>从Spark 2.0开始，Datasets/Dataframes成为主要的数据访问接口，SparkSession(org.apache.spark.sql.SparkSession)成为主要的访问Spark执行环境的接口。</p>

<h3 id="sparkconf">SparkConf</h3>

<p>Spark 2.0之前需要先创建SparkConf，在创建SparkContext。</p>

<pre><code>
//set up the spark configuration and create contexts
val sparkConf = new SparkConf().setAppName("SparkSessionZipsExample").setMaster("local")
// your handle to SparkContext to access other context like SQLContext
val sc = new SparkContext(sparkConf).set("spark.some.config.option", "some-value")
val sqlContext = new org.apache.spark.sql.SQLContext(sc)
</code></pre>

<p>Spark 2.0之后可以不用显示的创建SparkConf对象就可以创建SparkSession对象。</p>

<pre><code>
// Create a SparkSession. No need to create SparkContext
// You automatically get it as part of the SparkSession
val warehouseLocation = "file:${system:user.dir}/spark-warehouse"
val spark = SparkSession
   .builder()
   .appName("SparkSessionZipsExample")
   .config("spark.sql.warehouse.dir", warehouseLocation)
   .enableHiveSupport()
   .getOrCreate()
</code></pre>

<p>在SparkSession创建完后，Spark的运行时配置属性还可以通过SparkSession.conf()被修改：</p>

<pre><code>
//set new runtime options
spark.conf.set("spark.sql.shuffle.partitions", 6)
spark.conf.set("spark.executor.memory", "2g")
//get all settings
val configMap:Map[String, String] = spark.conf.getAll()
</code></pre>

<ul>
<li><a href="http://blog.javachen.com/2015/06/07/spark-configuration.html">Spark conf参考</a></li>
</ul>

<h3 id="sparksql">SparkSQL</h3>

<p>2.0之前需要通过创建SqlContext来使用SparkSQL。</p>

<pre><code>
val sc = new SparkContext(sparkConf).set("spark.some.config.option", "some-value")
val sqlContext = new org.apache.spark.sql.SQLContext(sc)
</code></pre>

<p>2.0后通过SparkSession可以很方便的访问SparkSession.sql()来使用SparkSQL。</p>

<pre><code>
// Now create an SQL table and issue SQL queries against it without
// using the sqlContext but through the SparkSession object.
// Creates a temporary view of the DataFrame
zipsDF.createOrReplaceTempView("zips_table")
zipsDF.cache()
val resultsDF = spark.sql("SELECT city, pop, state, zip FROM zips_table")
resultsDF.show(10)
</code></pre>

<h3 id="访问catalog-metadata">访问Catalog Metadata</h3>

<p>SparkSession暴露了访问metastore的接口SparkSession.catalog，这个接口可以用来访问catalog metadata信息，比如（Hcatalog）</p>

<pre><code>
//fetch metadata data from the catalog
spark.catalog.listDatabases.show(false)
spark.catalog.listTables.show(false)
</code></pre>

<pre><code>
scala> spark.catalog.listDatabases.show(false)
+-------+---------------------+------------------------------------------+
|name   |description          |locationUri                               |
+-------+---------------------+------------------------------------------+
|default|Default Hive database|hdfs://bdtest-001:8020/apps/hive/warehouse|
+-------+---------------------+------------------------------------------+

scala> spark.catalog.listTables.show(false)
+-------------------------+--------+----------------------------------------+---------+-----------+
|name                     |database|description                             |tableType|isTemporary|
+-------------------------+--------+----------------------------------------+---------+-----------+
|activity_donate_record   |default |Imported by sqoop on 2018/01/08 19:03:33|MANAGED  |false      |
|activity_periods_config  |default |Imported by sqoop on 2018/01/08 19:04:20|MANAGED  |false      |
|activity_result          |default |Imported by sqoop on 2018/01/08 19:05:00|MANAGED  |false      |
|activity_school_info     |default |Imported by sqoop on 2018/01/08 19:05:46|MANAGED  |false      |
|activity_season_game_data|default |Imported by sqoop on 2018/01/08 19:06:23|MANAGED  |false      |
|activity_season_game_log |default |Imported by sqoop on 2018/01/08 19:07:00|MANAGED  |false      |
|ana_tag                  |default |Imported by sqoop on 2018/01/08 19:07:35|MANAGED  |false      |
|ana_user_tag             |default |Imported by sqoop on 2018/01/08 19:08:18|MANAGED  |false      |
|api_invoking_log         |default |Imported by sqoop on 2018/01/08 19:08:58|MANAGED  |false      |
|app_function             |default |Imported by sqoop on 2018/01/08 19:09:34|MANAGED  |false      |
|bank_card                |default |Imported by sqoop on 2018/01/08 19:10:09|MANAGED  |false      |
|bank_card_bin            |default |Imported by sqoop on 2018/01/08 19:10:46|MANAGED  |false      |
|command_invocation       |default |Imported by sqoop on 2018/01/08 19:11:26|MANAGED  |false      |
|coupon_grant_log         |default |Imported by sqoop on 2018/01/08 19:12:05|MANAGED  |false      |
|coupon_user              |default |Imported by sqoop on 2018/01/08 19:12:43|MANAGED  |false      |
|device_command           |default |Imported by sqoop on 2018/01/08 19:13:18|MANAGED  |false      |
|device_preorder          |default |Imported by sqoop on 2018/01/08 19:13:54|MANAGED  |false      |
|dro_dropdetails          |default |null                                    |MANAGED  |false      |
|dro_dropinfo             |default |Imported by sqoop on 2018/01/08 19:15:09|MANAGED  |false      |
|dro_exchange_record      |default |Imported by sqoop on 2018/01/08 19:15:43|MANAGED  |false      |
+-------------------------+--------+----------------------------------------+---------+-----------+
only showing top 20 rows
</code></pre>

<h2 id="dataframe-和-datasets">DataFrame 和 Datasets</h2>

<p><img src="https://databricks.com/wp-content/uploads/2016/06/Unified-Apache-Spark-2.0-API-1.png" alt="DataFrame &amp; Dataset" /></p>

<h3 id="dataset">Dataset：</h3>

<ul>
<li>强类型</li>
<li>支持functional和relational操作</li>
<li>操作分类

<ul>
<li>转换（transformation）：用于产生新的Datasets

<ul>
<li>例如：map，filter，select，aggregate（groupBy）</li>
</ul></li>
<li>操作（actions）：触发计算并返回结果

<ul>
<li>例如：count，show，把数据写回文件系统</li>
</ul></li>
</ul></li>
<li>lazy：计算只有到action触发的时候才进行。Dataset内部可以理解为存储了如何进行计算的计划。当action执行的时候Spark query optimizer生成并优化计算方案后将其执行。</li>

<li><p><a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Encoder">Encoder</a>：把JVM中的类型T跟Spark SQL的数据表现形式进行转换的机制。（marshal/unmarshal?）</p></li>

<li><p>两种创建方法：</p>

<ul>
<li><p>使用SparkSession的read()方法</p>

<pre><code>
val people = spark.read.parquet("...").as[Person]  // Scala
Dataset<Person> people = spark.read().parquet("...").as(Encoders.bean(Person.class)); // Java
</code></pre></li>

<li><p>对现有Dataset做转换（transformation）</p>

<pre><code>
val names = people.map(_.name)  // in Scala; names is a Dataset[String]
Dataset<String> names = people.map((Person p) -> p.name, Encoders.STRING));
</code></pre></li>
</ul></li>

<li><p>Dataset操作也可以是untyped，通过：<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset">Dataset</a>, <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column">Column</a>, <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$">DataFrame的function</a>等。</p></li>

<li><p>列操作</p>

<ul>
<li>选择一列（抛弃其他列）：select(&ldquo;column&rdquo;)</li>
<li>增加一列：withColumn(&ldquo;newColumn&rdquo;, Column)</li>
<li>修改一列: withColumn(&ldquo;column&rdquo;, Column)</li>
<li>删除一列: drop(&ldquo;column&rdquo;)</li>
<li>类型转换：</li>
</ul></li>

<li><p>列高级操作：</p>

<ul>
<li>UDF:</li>
</ul></li>
</ul>

<h3 id="dataframe">DataFrame：</h3>

<ul>
<li>Dataset的无类型view (untyped view)，对应Dataset的Row</li>
<li><a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$">DataFrame操作Functions</a></li>
</ul>

<p>DataFrame是有名列（named columns）组成的数据集合，类似关系数据库中的表或者python/R中的pandas。</p>

<p>可以由多种数据源来构造DataFrame，比如Hive中的table，Spark的RDD（Resilient Distributed Datasets）。</p>

<p><strong>TODO: Datasets</strong></p>

<p>SparkSession有很多种方法创建DataFrame和Datasets。</p>

<table>
<thead>
<tr>
<th></th>
<th>DataFrame</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>创建API</td>
<td>SparkSession.createDataFrame</td>
<td></td>
</tr>

<tr>
<td>访问</td>
<td></td>
<td></td>
</tr>

<tr>
<td>其他</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th></th>
<th>Datasets</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>创建API</td>
<td></td>
<td></td>
</tr>

<tr>
<td>访问</td>
<td></td>
<td></td>
</tr>

<tr>
<td>其他</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<h3 id="row-http-spark-apache-org-docs-latest-api-scala-index-html-org-apache-spark-sql-row"><a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row">Row</a></h3>

<ul>
<li>创建Row</li>

<li><p>访问</p>

<ul>
<li><p>generic访问，使用ordinal序列访问</p>

<p>row(0)：访问列第一个成员</p></li>

<li><p>原始类型访问</p></li>
</ul></li>
</ul>

<h3 id="column-http-spark-apache-org-docs-latest-api-scala-index-html-org-apache-spark-sql-column"><a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column">Column</a></h3>

<ul>
<li>DataSet API:</li>
</ul>

<p><a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset</a></p>

<h3 id="处理时间">处理时间</h3>

<h4 id="ver-1-5">* ver &lt;= 1.5</h4>

<p>使用hiveContext来查询</p>

<h4 id="1-5-ver-2-2">*  1.5 &lt;= ver &lt; 2.2</h4>

<p>Spark 1.5引入了unix_timestamp()，所以在1.5之后到2.2的spark版本中可以这样操作时间信息</p>

<pre><code>
import org.apache.spark.sql.functions.{unix_timestamp, to_date}

val df = Seq((1L, "01-APR-2015")).toDF("id", "ts")

df.select(to_date(unix_timestamp(
  $"ts", "dd-MMM-yyyy"
).cast("timestamp")).alias("timestamp"))
</code></pre>

<h4 id="ver-2-2">* ver &gt;= 2.2</h4>

<pre><code>
import org.apache.spark.sql.functions.{to_date, to_timestamp}

df.select(to_date($"ts", "dd-MMM-yyyy").alias("date"))

df.select(to_timestamp($"ts", "dd-MM-yyyy HH:mm:ss").alias("timestamp"))
</code></pre>

<h3 id="import-spark-implicits">import spark.implicits._</h3>

<p>引入toDF()方法和“$”操作符</p>

<h2 id="编程陷阱">编程陷阱</h2>

<h3 id="陷阱1-dataframe有元素-但通过循环把值放入listbuffer-后listbuffer-却为空列表">陷阱1：dataframe有元素，但通过循环把值放入ListBuffer()后ListBuffer()却为空列表</h3>

<pre><code>
   val valueDF = allData.select("value").distinct()
    valueDF.show()
    //valueDF.foreach(r => valueList.append(r.getAs[Int]("value")))

    for (row <- valueDF) {
      println("value:" + row.getAs[Int]("value"))
      valueList.append(row.getAs[Int]("value"))
    }
    println("Values:" + valueList)
    valueList.foreach(println))

// 程序运行输出

+-------+
|value  |
+-------+
|      1|
|      3|
|      5|
|      4|
|     10|
|      2|
|      0|
+-------+

Values:ListBuffer()
</code></pre>

<p>可以看出两个问题：
* 问题1: 虽然可以知道valueDF不为空，可是&rdquo;println(&hellip;)&ldquo;却没有任何输出内容
* 问题2: 结果valueList为空</p>

<h4 id="原因">原因：</h4>

<p>Spark任务执行是通过Driver/Executor来完成的，Driver控制任务执行，Executor负责任务执行，foreach/for会被Driver分配给Executor来执行（分布式执行），每个Executor创建一个自己的ListBuffer拷贝，因此当任务结束后信息就丢失了。</p>

<p>参考Stackoverflow的讨论：<a href="https://stackoverflow.com/questions/36203299/scala-listbuffer-emptying-itself-after-every-add-in-loop">https://stackoverflow.com/questions/36203299/scala-listbuffer-emptying-itself-after-every-add-in-loop</a></p>

<h4 id="修复方法-使用collect">修复方法：使用collect()</h4>

<p>collect()定义：
<pre><code>
def collect(): Array[T]
Returns an array that contains all rows in this Dataset.
Running collect requires moving all the data into the application&rsquo;s driver
process, and doing so on a very large dataset can crash the driver process with
OutOfMemoryError.
For Java API, use collectAsList.
</code></pre></p>

<p>修复代码如下：
<pre><code>
val valueDF = allData.select(&ldquo;value&rdquo;).distinct()
valueDF.show()
//valueDF.foreach(r =&gt; valueList.append(r.getAs[Int](&ldquo;value&rdquo;)))</p>

<p>for (row &lt;- valueDF.collect()) {
  println(&ldquo;value:&rdquo; + row.getAs[Int](&ldquo;value&rdquo;))
  valueList.append(row.getAs[Int](&ldquo;value&rdquo;))
}
println(&ldquo;getAllChannels:&rdquo; + valueList)</p>

<p>// 程序运行输出如下</p>

<p>+&mdash;&mdash;-+
|value  |
+&mdash;&mdash;-+
|      1|
|      3|
|      5|
|      4|
|     10|
|      2|
|      0|
+&mdash;&mdash;-+</p>

<p>value:1
value:3
value:5
value:4
value:10
value:2
value:0
getAllChannels:ListBuffer(1, 3, 5, 4, 10, 2, 0)
</code></pre></p>

<h1 id="reference">Reference</h1>

<ul>
<li><a href="https://community.hortonworks.com/articles/84071/apache-ambari-workflow-manager-view-for-apache-ooz-2.html">Ambari workflow manager</a></li>
<li><a href="http://docs.scala-lang.org/tour/basics.html">Scala basics</a></li>
<li><a href="https://github.com/foundweekends/giter8/wiki/giter8-templates">Giter8项目模版</a></li>
<li><a href="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.0/bk_spark-component-guide/content/ch_oozie-spark-action.html">Automating Spark job with Oozie</a></li>
<li><a href="https://community.hortonworks.com/articles/104949/using-virtualenv-with-pyspark-1.html">Using VirtualEnv with PySpark</a></li>
</ul>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">标签</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://www.singleye.net/tags/spark/">spark</a>

  <a class="tag tag--primary tag--small" href="https://www.singleye.net/tags/scala/">scala</a>

  <a class="tag tag--primary tag--small" href="https://www.singleye.net/tags/python/">python</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">下一篇</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr">上一篇</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2024 singleye. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="2">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">下一篇</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr">上一篇</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="2">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/images/avatar.png" alt="作者的图片" />
    
    <h4 id="about-card-name">singleye</h4>
    
      <div id="about-card-bio"><strong>Email:</strong> <a href="mailto:singleye512@gmail.com">singleye512@gmail.com</a></div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Product &amp; Engineering
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Shanghai, China
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="搜索" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center"></div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2024/06/%E5%9F%BA%E4%BA%8E-kalman-filter-%E7%9A%84%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">
                <h3 class="media-heading">基于 Kalman filter 的目标跟踪</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2024
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><!--toc-->

<p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2024/04/%E5%9C%A8-apple-silicon-m3-max-%E4%B8%8A%E5%AF%B9-llama2-%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83/">
                <h3 class="media-heading">在 Apple silicon (M3 Max) 上对 Llama2 进行微调</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2024
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><!--toc-->

<p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2024/04/tmux-ai-%E5%8A%A9%E6%89%8B/">
                <h3 class="media-heading">tmux AI 助手</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2024
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">日产开发时很喜欢用 tmux，最近写了一个 tmux 的 AI 插件，这个插件可以使用 ollama 支持的 LLM 生成 shell / 编程相关的内容，会对日常使用 CLI 的同学们带来一些帮助。
使用方法：  + Q 调出命令输入栏，在输入栏中写好问题回车，之后 tmux 会把生成的答案在新的窗口中显示出来。
项目链接： https://github.com/singleye/tmux-ai-helper</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2024/03/%E4%BD%BF%E7%94%A8-roswaitforshutdown-%E5%AF%BC%E8%87%B4-dynamic_reconfigureserver-%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E8%8E%B7%E5%8F%96%E9%85%8D%E7%BD%AE%E6%9B%B4%E6%96%B0%E7%9A%84%E9%97%AE%E9%A2%98/">
                <h3 class="media-heading">使用 ros::waitForShutdown() 导致 dynamic_reconfigure::Server 无法正常获取配置更新的问题</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2024
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><!--toc-->

<p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2023/12/pcl-3d-%E7%A9%BA%E9%97%B4%E6%A3%80%E6%B5%8B%E5%B9%B3%E8%A1%8C%E5%9B%9B%E8%BE%B9%E5%BD%A2/">
                <h3 class="media-heading">PCL 3D 空间检测平行四边形</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2023
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><!--toc-->

<p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2023/12/javascript-var/let/const-%E6%AF%94%E8%BE%83/">
                <h3 class="media-heading">javascript var/let/const 比较</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2023
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><!--toc-->

<p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2023/12/django-rest-framework-%E5%92%8C-simplejwt-%E7%9A%84%E7%B1%BB%E5%85%B3%E7%B3%BB/">
                <h3 class="media-heading">django-rest-framework 和 simplejwt 的类关系</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2023
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2023/11/python-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">
                <h3 class="media-heading">Python 内存管理</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2023
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2023/10/%E5%B7%A6%E4%B9%98/%E5%8F%B3%E4%B9%98%E6%97%8B%E8%BD%AC/">
                <h3 class="media-heading">左乘/右乘旋转</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2023
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="https://www.singleye.net/2023/08/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%A0%BC%E5%BC%8F%E6%A0%87%E5%87%86h264-%E7%BC%96%E7%A0%81%E4%B8%8E-mp4-%E6%A0%BC%E5%BC%8F%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D/">
                <h3 class="media-heading">多媒体格式标准、H264 编码与 MP4 格式简要介绍</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2023
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero=""
         data-message-one=""
         data-message-other="">
         79 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/images/cover.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://www.singleye.net/js/script-id5yjczimn7hvkl7hmhqf7f2rihleozgxiext4jwyj7u507rwphg9wvfbks4.min.js"></script>




  
    
      <script>
        var disqus_config = function () {
          this.page.url = 'https:\/\/www.singleye.net\/2018\/01\/spark%E5%BC%80%E5%8F%91\/';
          
            this.page.identifier = '\/2018\/01\/spark%E5%BC%80%E5%8F%91\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'singleye';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>


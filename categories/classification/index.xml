<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Classification on singleye</title>
    <link>/categories/classification/</link>
    <description>singleye (Classification)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <managingEditor>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</managingEditor>
    <webMaster>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</webMaster>
    <lastBuildDate>Fri, 09 Aug 2019 10:57:50 +0800</lastBuildDate>
    
    <atom:link href="/categories/classification/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>机器学习笔记 - 贝叶斯分类法推导</title>
      <link>/2019/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E6%B3%95%E6%8E%A8%E5%AF%BC/</link>
      <pubDate>Fri, 09 Aug 2019 10:57:50 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E6%B3%95%E6%8E%A8%E5%AF%BC/</guid>
      <description>&lt;!--toc--&gt;
&lt;p&gt;这篇笔记记录了最近对贝叶斯分类法的学习和理解。&lt;/p&gt;
&lt;h1 id=&#34;1概率基本概念回顾&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#1%e6%a6%82%e7%8e%87%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5%e5%9b%9e%e9%a1%be&#34;&gt;
        ##
    &lt;/a&gt;
    1.概率基本概念回顾
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;11概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#11%e6%a6%82%e7%8e%87&#34;&gt;
        #
    &lt;/a&gt;
    1.1.概率：
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;事件发生的概率 = $ \dfrac{事件可能发生的个数} {结果的总数} $&lt;/p&gt;
&lt;h2 id=&#34;12事件的分类&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#12%e4%ba%8b%e4%bb%b6%e7%9a%84%e5%88%86%e7%b1%bb&#34;&gt;
        #
    &lt;/a&gt;
    1.2.事件的分类：
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;独立事件：每个事件的发生是独立的，不受其他事件的影响，例如：抛硬币，掷骰子。&lt;/li&gt;
&lt;li&gt;相关事件：当前事件受之前发生事件的影响，例如：抽扑克牌。&lt;/li&gt;
&lt;li&gt;互斥事件：事件发生只能是其一，不能同时发生，例如：一枚硬币不能同时为正面和反面。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;13独立事件的概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#13%e7%8b%ac%e7%ab%8b%e4%ba%8b%e4%bb%b6%e7%9a%84%e6%a6%82%e7%8e%87&#34;&gt;
        #
    &lt;/a&gt;
    1.3.独立事件的概率：
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;单个独立事件的概率： P(A) = $ \dfrac{事件可能发生的个数} {结果的总数} $&lt;/li&gt;
&lt;li&gt;事件A和B发生的概率（多个独立事件的概率）： P(A B) = P(A) * P(B)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;14条件概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#14%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87&#34;&gt;
        #
    &lt;/a&gt;
    1.4.条件概率：
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;在相关事件的情况中应用条件概率，用 P(B|A) 表示在事件 A 发生的条件下事件 B 发生的概率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;事件A和B发生的概率： P(A B) = P(A) * P(B|A)&lt;/p&gt;
&lt;p&gt;另外一个有用的公式转换： P(B|A) = $ \dfrac{P(A B)} {P(A)} $&lt;/p&gt;
&lt;p&gt;在事件 A 发生的情况下 B 发生的概率等于事件 A 和 B 的概率除以事件 A 的概率&lt;/p&gt;
&lt;p&gt;例子：冰淇淋&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  在你的社交群组里，70% 喜欢巧克力冰淇淋，35% 喜欢巧克力和草莓。

  在喜欢巧克力的人里，也喜欢草莓的百分比是多少？

  P(草莓|巧克力) = P(巧克力 与 草莓) / P(巧克力)

  0.35 / 0.7 = 50%

  在喜欢巧克力的人里，50% 也喜欢草莓
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;141-尝试计算下面的概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#141-%e5%b0%9d%e8%af%95%e8%ae%a1%e7%ae%97%e4%b8%8b%e9%9d%a2%e7%9a%84%e6%a6%82%e7%8e%87&#34;&gt;
        ##
    &lt;/a&gt;
    1.4.1. 尝试计算下面的概率
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;4个人在5个数字中各选一个数字，请问任何两个人选重的概率是多少？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/08/bayes-classification/events-dependent-ex-3.svg&#34; alt=&#34;events-dependent-ex-3.svg&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;2贝叶斯定理&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2%e8%b4%9d%e5%8f%b6%e6%96%af%e5%ae%9a%e7%90%86&#34;&gt;
        ##
    &lt;/a&gt;
    2.贝叶斯定理
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;$ P(A|B) = \dfrac {P(A)*P(B|A)} {P(B)} $&lt;/p&gt;
&lt;p&gt;在 B 发生的情况下发生 A 事件的概率 P(A|B) 可以通过已知 A 发生情况下 B 发生的概率和 A 与 B 的独自发生的概率求出来。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(A|B)：在 B 发生的情况下 A 发生的概率&lt;/li&gt;
&lt;li&gt;P(A)：A 发生的概率&lt;/li&gt;
&lt;li&gt;P(B)：B 发生的概率&lt;/li&gt;
&lt;li&gt;P(B|A)：在 A 发生的情况下 B 发生的概率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**例子1：**计算天气有云时下雨的概率：&lt;/p&gt;
&lt;p&gt;$ P(雨|云) = \dfrac {P(雨)*P(云|雨)} {P(云)} $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(雨)：下雨的概率 = 10%&lt;/li&gt;
&lt;li&gt;P(云|雨)：下雨时有云的概率 = 50%&lt;/li&gt;
&lt;li&gt;P(云)：有云的概率 = 40%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$ P(雨|云) = \dfrac {0.1 * 0.5} {0.4} = 0.125 $&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例子2：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有一种疾病检测手段，但是这种检测手段并不准确&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在真正有这种疾病的人中有 80% 的人可以被检测出&lt;/li&gt;
&lt;li&gt;对于没有这种疾病的人有 10% 的概率会被错误检测出&lt;/li&gt;
&lt;li&gt;以往的统计数据表明人群中有 1% 的人得了这种疾病，99% 的人没有得过&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;请问，当有一个人被检测出有该疾病时他真正有这种病的概率是多少？&lt;/p&gt;
&lt;p&gt;$ P(真有病|检测有病) = \dfrac {P(真有病) * P(检测有病|真有病)} {P(检测有病)} $&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;真实情况 \ 检测结果&lt;/th&gt;
&lt;th&gt;检测有病&lt;/th&gt;
&lt;th&gt;检测没病&lt;/th&gt;
&lt;th&gt;得病统计&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;真有病&lt;/td&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;td&gt;1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;真没病&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;td&gt;90%&lt;/td&gt;
&lt;td&gt;99%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;P(真有病)：1%&lt;/li&gt;
&lt;li&gt;P(检测有病|真有病)：80%&lt;/li&gt;
&lt;li&gt;P(检测有病)：P(没有病的人被检测出有病的概率) + P(真有病的人被检测出有病的概率)
&lt;ul&gt;
&lt;li&gt;P(没有病的人被检测出有病的概率) = P(真没病) * P(检测有病|真没病) = 99% * 10% = 0.099&lt;/li&gt;
&lt;li&gt;P(真有病的人被检测出有病的概率) = P(真有病) * P(检测有病|真有病) = 1% * 80% = 0.008&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$ P(真有病|检测有病) = \dfrac {1% * 80%} { 99% * 10% + 1% * 80%} =  7.48% $&lt;/p&gt;
&lt;p&gt;示意图：&lt;/p&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/08/bayes-classification/disease_1.jpeg&#34; style=&#34;width:400px&#34;/&gt;
&lt;p&gt;计算方法：&lt;/p&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/08/bayes-classification/disease_2.jpeg&#34; style=&#34;width:600px&#34;/&gt;
&lt;p&gt;那么怎么评估这个方法是否有效呢？可以使用准确度（Precision）和召回（Recall）两个指标来评估。&lt;/p&gt;
&lt;p&gt;$ Precision = \dfrac {TP} {TP + FP} = \dfrac {P(真有病) * P(检测有病|真有病)} {P(检测有病)} = \dfrac {1% * 80%} {1% * 80% + 99% * 10%} = 7.48%$&lt;/p&gt;
&lt;p&gt;$ Recall = \dfrac {TP} {TP + FN} = \dfrac {P(真有病) * P(检测有病|真有病)} {P(真有病)} = \dfrac {1% * 80%} {1%} = 80% $&lt;/p&gt;
&lt;h1 id=&#34;3贝叶斯定理在机器学习中的应用---文本分类&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#3%e8%b4%9d%e5%8f%b6%e6%96%af%e5%ae%9a%e7%90%86%e5%9c%a8%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8---%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb&#34;&gt;
        ##
    &lt;/a&gt;
    3.贝叶斯定理在机器学习中的应用 - 文本分类
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;**任务目标：**通过利用一批分好类（2类：正常/非正常）的文本信息，训练一个模型来识别一段给定文字，判断是不是正常言论。&lt;/p&gt;
&lt;p&gt;$ P(类别|数据) = \dfrac {P(类别) * P(数据|类别)} {P(数据)} $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当 P(正常|数据) &amp;gt; P(不正常|数据) 时认为文本为“正常”&lt;/li&gt;
&lt;li&gt;当 P(正常|数据) &amp;lt; P(不正常|数据) 时认为文本为“不正常”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;算法推导：&lt;/p&gt;
&lt;p&gt;进一步把问题转换成下面的表达方式：&lt;/p&gt;
&lt;p&gt;$ P(class|words) = \dfrac {P(words|class) * P(class)} {P(words)} $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;class：代表类别&lt;/li&gt;
&lt;li&gt;words：代表一句话，它是由一组单词构成的，记做：w0, w1, w2, &amp;hellip;, wn&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$ P(class|w0, w0, w1, w2, &amp;hellip;, wn) = \dfrac {P(w0, w1, w2, &amp;hellip;, wn|class) * P(class)} {P(w0, w1, w2, &amp;hellip;, wn)} $&lt;/p&gt;
&lt;p&gt;由于 P(w0, w1, w2, &amp;hellip;, wn|class) 非常难于计算因此通过条件独立性假设把这个概率进行简化计算，最终转换成计算 P(w0|class)P(w1|class)P(w2|class)&amp;hellip;P(wn|class)。&lt;/p&gt;
&lt;p&gt;$ P(class|w0, w0, w1, w2, &amp;hellip;, wn) = \dfrac {P(w0|class)*P(w1|class)*P(w2|class)&amp;hellip;P(wn|class) * P(class)} {P(w0, w1, w2, &amp;hellip;, wn)} $&lt;/p&gt;
&lt;p&gt;训练方法就转换成根据已提供的数据计算下列概率值得过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个类别中出现某个单词的概率 P(w0|class), P(w1|class), P(w2|class)&amp;hellip;P(wn|class)&lt;/li&gt;
&lt;li&gt;训练数据中某个类别的概率 P(class)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比较 P(class1|w0, w0, w1, w2, &amp;hellip;, wn) P(class2|w0, w0, w1, w2, &amp;hellip;, wn) 可以简化成比较&lt;/p&gt;
&lt;p&gt;$ P(w0|class1)*P(w1|class1)*P(w2|class1)&amp;hellip;P(wn|class1) * P(class1) $&lt;/p&gt;
&lt;p&gt;$ P(w0|class2)*P(w1|class2)*P(w2|class2)&amp;hellip;P(wn|class2) * P(class2) $&lt;/p&gt;
&lt;p&gt;**注意：**实际计算中很少直接使用这样的乘法进行计算，主要原因是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;乘法运算计算量相对加法来说是复杂很多的&lt;/li&gt;
&lt;li&gt;由于每一项 P(wn|class1) 值很小或者为0（有时为了避免所有项为0会把每一项给一个初始化很小的数字），因此容易导致计算结果直接为0或者由于太小造成下溢出&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以，在实际情况下多使用 log 运算，根据 log 的性质可以进一步简化成比较：&lt;/p&gt;
&lt;p&gt;$ log(P(w0|class1)*P(w1|class1)*P(w2|class1)&amp;hellip;P(wn|class1) * P(class1)) = log(P(w0|class1) + log(P(w1|class1) + log(P(w2|class1) + &amp;hellip;  + log(P(wn|class1) + log(class1)$&lt;/p&gt;
&lt;p&gt;$ log(P(w0|class2)*P(w1|class2)*P(w2|class2)&amp;hellip;P(wn|class2) * P(class2)) = log(P(w0|class2) + log(P(w1|class2) + log(P(w2|class2) + &amp;hellip;  + log(P(wn|class2) + log(class2)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;另外使用 log 进行计算还有额外的好处：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先是直接将乘法运算转换成了加法，计算速度得到提升&lt;/li&gt;
&lt;li&gt;每一项 log(P(wn|class) 都可以在训练阶段固化，操作中可以直接用查表法解决进一步减少运算量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最后，引用一下来自《机器学习实战》的例子：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;from&lt;/span&gt; numpy &lt;span style=&#34;color:#ff6ac1&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;loadDataSet&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    postingList&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;[[&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;has&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;flea&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;problems&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;help&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;please&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;maybe&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;not&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;take&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;him&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;to&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;park&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dalmation&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;is&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;so&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cute&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;I&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;love&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;him&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stop&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;posting&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;worthless&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;garbage&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;mr&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;licks&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;ate&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;steak&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;how&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;to&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stop&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;him&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;quit&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;buying&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;worthless&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;food&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    classVec &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;]    &lt;span style=&#34;color:#78787e&#34;&gt;#1 is abusive, 0 not&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; postingList,classVec
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;createVocabList&lt;/span&gt;(dataSet):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vocabSet &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;set&lt;/span&gt;([])  &lt;span style=&#34;color:#78787e&#34;&gt;#create empty set&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; document &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataSet:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        vocabSet &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; vocabSet &lt;span style=&#34;color:#ff6ac1&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;set&lt;/span&gt;(document) &lt;span style=&#34;color:#78787e&#34;&gt;#union of the two sets&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;list&lt;/span&gt;(vocabSet)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;setOfWords2Vec&lt;/span&gt;(vocabList, inputSet):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    returnVec &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(vocabList)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; inputSet:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; word &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; vocabList:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            returnVec[vocabList&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;index(word)] &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;else&lt;/span&gt;: &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;the word: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt; is not in my Vocabulary!&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;%&lt;/span&gt; word)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; returnVec
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;trainNB0&lt;/span&gt;(trainMatrix,trainCategory):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    numTrainDocs &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(trainMatrix)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    numWords &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(trainMatrix[&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pAbusive &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(trainCategory)&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;float&lt;/span&gt;(numTrainDocs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; ones(numWords); p1Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; ones(numWords)      &lt;span style=&#34;color:#78787e&#34;&gt;#change to ones()，备注：初始化成1避免该项为0的情况发生&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;2.0&lt;/span&gt;; p1Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;2.0&lt;/span&gt;                        &lt;span style=&#34;color:#78787e&#34;&gt;#change to 2.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;range&lt;/span&gt;(numTrainDocs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; trainCategory[i] &lt;span style=&#34;color:#ff6ac1&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p1Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; trainMatrix[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p1Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(trainMatrix[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p0Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; trainMatrix[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p0Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(trainMatrix[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p1Vect &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; log(p1Num&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;p1Denom)          &lt;span style=&#34;color:#78787e&#34;&gt;#change to log()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0Vect &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; log(p0Num&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;p0Denom)          &lt;span style=&#34;color:#78787e&#34;&gt;#change to log()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; p0Vect,p1Vect,pAbusive
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;classifyNB&lt;/span&gt;(vec2Classify, p0Vec, p1Vec, pClass1):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p1 &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(vec2Classify &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; p1Vec) &lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt; log(pClass1)    &lt;span style=&#34;color:#78787e&#34;&gt;#element-wise mult&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0 &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(vec2Classify &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; p0Vec) &lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt; log(&lt;span style=&#34;color:#ff9f43&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt; pClass1)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; p1 &lt;span style=&#34;color:#ff6ac1&#34;&gt;&amp;gt;&lt;/span&gt; p0:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;testingNB&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    listOPosts,listClasses &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; loadDataSet()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    myVocabList &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; createVocabList(listOPosts)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;[]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; postinDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; listOPosts:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;append(setOfWords2Vec(myVocabList, postinDoc))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0V,p1V,pAb &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; trainNB0(array(trainMat),array(listClasses))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;love&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dalmation&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;garbage&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;第一步加载已分类数据并创建词典&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ac%ac%e4%b8%80%e6%ad%a5%e5%8a%a0%e8%bd%bd%e5%b7%b2%e5%88%86%e7%b1%bb%e6%95%b0%e6%8d%ae%e5%b9%b6%e5%88%9b%e5%bb%ba%e8%af%8d%e5%85%b8&#34;&gt;
        #
    &lt;/a&gt;
    第一步：加载已分类数据，并创建词典
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;listOPosts,listClasses &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; loadDataSet()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;myVocabList &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; createVocabList(listOPosts)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;All posts:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;80&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(listOPosts)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Vocabulary:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;80&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(myVocabList)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;All posts:
--------------------------------------------------------------------------------
[[&#39;my&#39;, &#39;dog&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;problems&#39;, &#39;help&#39;, &#39;please&#39;], [&#39;maybe&#39;, &#39;not&#39;, &#39;take&#39;, &#39;him&#39;, &#39;to&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;stupid&#39;], [&#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;so&#39;, &#39;cute&#39;, &#39;I&#39;, &#39;love&#39;, &#39;him&#39;], [&#39;stop&#39;, &#39;posting&#39;, &#39;stupid&#39;, &#39;worthless&#39;, &#39;garbage&#39;], [&#39;mr&#39;, &#39;licks&#39;, &#39;ate&#39;, &#39;my&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;to&#39;, &#39;stop&#39;, &#39;him&#39;], [&#39;quit&#39;, &#39;buying&#39;, &#39;worthless&#39;, &#39;dog&#39;, &#39;food&#39;, &#39;stupid&#39;]]


Vocabulary:
--------------------------------------------------------------------------------
[&#39;to&#39;, &#39;mr&#39;, &#39;quit&#39;, &#39;take&#39;, &#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;stop&#39;, &#39;worthless&#39;, &#39;him&#39;, &#39;problems&#39;, &#39;cute&#39;, &#39;maybe&#39;, &#39;I&#39;, &#39;so&#39;, &#39;not&#39;, &#39;buying&#39;, &#39;help&#39;, &#39;how&#39;, &#39;park&#39;, &#39;food&#39;, &#39;garbage&#39;, &#39;steak&#39;, &#39;please&#39;, &#39;dog&#39;, &#39;ate&#39;, &#39;licks&#39;, &#39;posting&#39;, &#39;love&#39;, &#39;stupid&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;第二步将词典数据转换成可计算的向量&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ac%ac%e4%ba%8c%e6%ad%a5%e5%b0%86%e8%af%8d%e5%85%b8%e6%95%b0%e6%8d%ae%e8%bd%ac%e6%8d%a2%e6%88%90%e5%8f%af%e8%ae%a1%e7%ae%97%e7%9a%84%e5%90%91%e9%87%8f&#34;&gt;
        #
    &lt;/a&gt;
    第二步：将词典数据转换成可计算的向量
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;[]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; postinDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; listOPosts:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;append(setOfWords2Vec(myVocabList, postinDoc))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;第三步训练模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ac%ac%e4%b8%89%e6%ad%a5%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b&#34;&gt;
        #
    &lt;/a&gt;
    第三步：训练模型
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p0V,p1V,pAb &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; trainNB0(array(trainMat),array(listClasses))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;最后测试模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%9c%80%e5%90%8e%e6%b5%8b%e8%af%95%e6%a8%a1%e5%9e%8b&#34;&gt;
        #
    &lt;/a&gt;
    最后：测试模型
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;love&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dalmation&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;garbage&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;] classified as:  0
[&#39;stupid&#39;, &#39;garbage&#39;] classified as:  1&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>机器学习 - 决策树</title>
      <link>/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</link>
      <pubDate>Mon, 15 Apr 2019 17:04:37 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</guid>
      <description>&lt;!--toc--&gt;
&lt;h1 id=&#34;机器学习-决策树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0-%e5%86%b3%e7%ad%96%e6%a0%91&#34;&gt;
        ##
    &lt;/a&gt;
    机器学习-决策树
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;1什么是问题树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#1%e4%bb%80%e4%b9%88%e6%98%af%e9%97%ae%e9%a2%98%e6%a0%91&#34;&gt;
        #
    &lt;/a&gt;
    1.什么是问题树？
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;请思考以下场景&lt;/p&gt;
&lt;h3 id=&#34;11玩过猜字游戏吗&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#11%e7%8e%a9%e8%bf%87%e7%8c%9c%e5%ad%97%e6%b8%b8%e6%88%8f%e5%90%97&#34;&gt;
        ##
    &lt;/a&gt;
    1.1.玩过猜字游戏吗？
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;12如何通过几个问题区分猫狗鸡鸭&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#12%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e5%87%a0%e4%b8%aa%e9%97%ae%e9%a2%98%e5%8c%ba%e5%88%86%e7%8c%ab%e7%8b%97%e9%b8%a1%e9%b8%ad&#34;&gt;
        ##
    &lt;/a&gt;
    1.2.如何通过几个问题区分“猫狗鸡鸭”？
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/2.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;121他们的特征是什么&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#121%e4%bb%96%e4%bb%ac%e7%9a%84%e7%89%b9%e5%be%81%e6%98%af%e4%bb%80%e4%b9%88&#34;&gt;
        ###
    &lt;/a&gt;
    1.2.1.他们的特征是什么？
&lt;/div&gt;
&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;物种&lt;/th&gt;
&lt;th&gt;腿的数量&lt;/th&gt;
&lt;th&gt;有没有脚蹼&lt;/th&gt;
&lt;th&gt;喙的形状&lt;/th&gt;
&lt;th&gt;会不会游泳&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;猫&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;不会&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;狗&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;会&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸡&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;尖&lt;/td&gt;
&lt;td&gt;不会&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸭&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;扁&lt;/td&gt;
&lt;td&gt;会&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;数据的表示方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;类别：猫、狗、鸡、鸭&lt;/li&gt;
&lt;li&gt;特征：腿的数量、有没有脚蹼、喙的形状，会不会游泳&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;122以下是一种区分方法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#122%e4%bb%a5%e4%b8%8b%e6%98%af%e4%b8%80%e7%a7%8d%e5%8c%ba%e5%88%86%e6%96%b9%e6%b3%95&#34;&gt;
        ###
    &lt;/a&gt;
    1.2.2.以下是一种区分方法
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/6.png&#34; alt=&#34;6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考1：以上是不是唯一的方法？&lt;/strong&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/7.png&#34; alt=&#34;7&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考2：哪种判定方式更好？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考3：如何更有效的区分？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果某个特征区分问题更有效？&lt;/li&gt;
&lt;li&gt;怎么判断问题更有效？&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2为什么需要决策树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%86%b3%e7%ad%96%e6%a0%91&#34;&gt;
        #
    &lt;/a&gt;
    2.为什么需要决策树
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;此刻你可能会想到：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 寻找关键性问题！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 什么是关键性问题？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 怎么寻找关键性问题？&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;21理论依据是什么&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#21%e7%90%86%e8%ae%ba%e4%be%9d%e6%8d%ae%e6%98%af%e4%bb%80%e4%b9%88&#34;&gt;
        ##
    &lt;/a&gt;
    2.1.理论依据是什么？
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;香农&amp;quot;提出信息论，其中对信息的度量成为香农熵，简称“熵(Entropy)”&lt;/p&gt;
&lt;p&gt;在分类问题中，假设存在类别集合为  $ (X_1, X_2, &amp;hellip; X_n) $ ，将类别 $ X_i $ 的信息定义为:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$ l(X_i) = -log(P(X_i))$ , 其中 $ P(X_i)$为 $X_i $的概率&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;熵：信息的数学期望值： $ H= -\sum_{i=1}^n P(X_i) log(P(X_i))$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;思考4：怎么理解熵？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;信息量越大，熵越小&lt;/li&gt;
&lt;li&gt;信息量越小，熵越大&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/5.png&#34; alt=&#34;5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考5：为什么使用对数表示信息？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;概率 vs 信息&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;概率越大，信息量越小&lt;/li&gt;
&lt;li&gt;概率越小，信息量越大&lt;/li&gt;
&lt;li&gt;多个事件同时发生的概率是多个事件发生概率相乘，总信息量是多个事件信息量相加&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;练习1：给定以下数据集，写出熵的计算方法&lt;/strong&gt;&lt;/p&gt;
$$ H= -\sum_{i=1}^n P(X_i) log(P(X_i)) $$
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;from&lt;/span&gt; math &lt;span style=&#34;color:#ff6ac1&#34;&gt;import&lt;/span&gt; log
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;create_dataset&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;legs&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;flippers&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;beak&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;swim&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Yes&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Yes&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sharp&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;chicken&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sharp&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;chicken&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Flat&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;duck&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; dataset, features
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;calc_entropy&lt;/span&gt;(dataset):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    count &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    class_counter &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; vector &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataset:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        cls &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; vector[&lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        class_counter[cls] &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; class_counter&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;get(cls, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; key &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; class_counter&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;keys():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;float&lt;/span&gt;(class_counter[key])&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;count
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;-=&lt;/span&gt; prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; log(prob)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; entropy
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset, features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; create_dataset()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; calc_entropy(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Entropy: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(entropy))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Entropy: 1.3208883431493221
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3怎么构建决策树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#3%e6%80%8e%e4%b9%88%e6%9e%84%e5%bb%ba%e5%86%b3%e7%ad%96%e6%a0%91&#34;&gt;
        #
    &lt;/a&gt;
    3.怎么构建决策树
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;核心问题：如何通过划分数据集计算信息量的提升来找到最有效的数据特征&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;练习2：重新划分数据集，将符合指定特征值的数据提取出来组合新的数据集合&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;split_dataset&lt;/span&gt;(dataset, feature, value):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; data &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataset:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; data[feature] &lt;span style=&#34;color:#ff6ac1&#34;&gt;==&lt;/span&gt; value:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            new_data &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; data[:feature]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            new_data&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;extend(data[feature&lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;:])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            new_dataset&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;append(new_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; new_dataset
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;小实验1：以下将有脚蹼和没有脚蹼的数据集划分出来&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;feature &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; features&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;index(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;flippers&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;with_flipper_dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; split_dataset(dataset, feature, &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Dataset with flippers:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(with_flipper_dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Dataset without flippers:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;with_flipper_dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; split_dataset(dataset, feature, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(with_flipper_dataset)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Dataset with flippers:
[[2, &#39;Flat&#39;, &#39;No&#39;, &#39;duck&#39;]]
Dataset without flippers:
[[4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;思考6：怎么表示最好的特征？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;信息增益：通过观察信息熵的变化求得&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;select_best_feature&lt;/span&gt;(dataset, features):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    feature_count &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(dataset[&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;])&lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    current_entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; calc_entropy(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    feature_selected &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    best_entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dataset_size &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sub_datasets &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sub_features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;range&lt;/span&gt;(feature_count):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        feature_values &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;set&lt;/span&gt;([vector[i] &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; vector &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataset])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        subset_entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;  Calculating entropy by splitting dataset with feature[&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{0}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;]&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(features[i]))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        subsets &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; value &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; feature_values:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;    Splitting dataset with feature[&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{0}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;]==&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{1}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(features[i], value))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            subset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; split_dataset(dataset, i, value)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            subsets[value] &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; subset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(subset)&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1.0&lt;/span&gt;)&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;dataset_size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            subset_entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; calc_entropy(subset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;      Subset:&amp;#39;&lt;/span&gt;, subset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;      Entropy:&amp;#39;&lt;/span&gt;, subset_entropy)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; current_entropy&lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt;subset_entropy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;    Entropy gain: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(entropy_gain))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; best_entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;&amp;lt;&lt;/span&gt; entropy_gain:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            best_entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; entropy_gain
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            feature_selected &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; i
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            sub_datasets &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; subsets
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            sub_features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; features[:feature_selected]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            sub_features&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;extend(features[feature_selected&lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;:])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; feature_selected, sub_datasets, sub_features
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;小实验2：请在数据全集上运行计算出最优数据特征&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;best_feature, sub_datasets, sub_features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; select_best_feature(dataset, features)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Best feature: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;, name: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(best_feature, features[best_feature]))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; feature_value &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; sub_datasets&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;keys():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sub dataset with feature[&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;]==&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(features[best_feature], feature_value))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(sub_datasets[feature_value])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sub features: &amp;#39;&lt;/span&gt;, sub_features)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;  Calculating entropy by splitting dataset with feature[legs]
    Splitting dataset with feature[legs]==2
      Subset: [[0, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [0, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [1, &#39;Flat&#39;, &#39;No&#39;, &#39;duck&#39;]]
      Entropy: 0.2386928131105548
    Splitting dataset with feature[legs]==4
      Subset: [[0, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [0, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [0, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [0, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [0, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;]]
      Entropy: 0.6593251049913401
    Entropy gain: 0.661563238157982
  Calculating entropy by splitting dataset with feature[flippers]
    Splitting dataset with feature[flippers]==0
      Subset: [[4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;]]
      Entropy: 0.9441181818928854
    Splitting dataset with feature[flippers]==1
      Subset: [[2, &#39;Flat&#39;, &#39;No&#39;, &#39;duck&#39;]]
      Entropy: 0.9441181818928854
    Entropy gain: 0.3767701612564367
  Calculating entropy by splitting dataset with feature[beak]
    Splitting dataset with feature[beak]==No
      Subset: [[4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;]]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Flat
      Subset: [[2, 1, &#39;No&#39;, &#39;duck&#39;]]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Sharp
      Subset: [[2, 0, &#39;No&#39;, &#39;chicken&#39;], [2, 0, &#39;No&#39;, &#39;chicken&#39;]]
      Entropy: 0.4206322918807853
    Entropy gain: 0.9002560512685368
  Calculating entropy by splitting dataset with feature[swim]
    Splitting dataset with feature[swim]==No
      Subset: [[4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [2, 0, &#39;Sharp&#39;, &#39;chicken&#39;], [2, 0, &#39;Sharp&#39;, &#39;chicken&#39;], [2, 1, &#39;Flat&#39;, &#39;duck&#39;]]
      Entropy: 0.7585531985305136
    Splitting dataset with feature[swim]==Yes
      Subset: [[4, 0, &#39;No&#39;, &#39;dog&#39;], [4, 0, &#39;No&#39;, &#39;dog&#39;]]
      Entropy: 0.7585531985305136
    Entropy gain: 0.5623351446188085
Best feature: 2, name: beak
Sub dataset with feature[beak]==No
[[4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;]]
Sub features:  [&#39;legs&#39;, &#39;flippers&#39;, &#39;swim&#39;]
Sub dataset with feature[beak]==Flat
[[2, 1, &#39;No&#39;, &#39;duck&#39;]]
Sub features:  [&#39;legs&#39;, &#39;flippers&#39;, &#39;swim&#39;]
Sub dataset with feature[beak]==Sharp
[[2, 0, &#39;No&#39;, &#39;chicken&#39;], [2, 0, &#39;No&#39;, &#39;chicken&#39;]]
Sub features:  [&#39;legs&#39;, &#39;flippers&#39;, &#39;swim&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;思考7：如果改动数据集会出现什么情况？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;决策树算法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%86%b3%e7%ad%96%e6%a0%91%e7%ae%97%e6%b3%95&#34;&gt;
        #
    &lt;/a&gt;
    决策树算法
&lt;/div&gt;
&lt;/h2&gt;
&lt;h4 id=&#34;算法描述&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0&#34;&gt;
        ###
    &lt;/a&gt;
    算法描述：
&lt;/div&gt;
&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;当前数据集是否是确定的某个类型的数据，如果是则不用再对该数据集进行分类&lt;/li&gt;
&lt;li&gt;在当前数据集上选择最好的特征，通过使用这个特征区分的子数据集拥有最好的信息&lt;/li&gt;
&lt;li&gt;对各子数据集重复进行上述计算&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;伪代码&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%bc%aa%e4%bb%a3%e7%a0%81&#34;&gt;
        ###
    &lt;/a&gt;
    伪代码：
&lt;/div&gt;
&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Function CreateTree
    IF 数据集不用再分割 THEN return 该数据集类别
    ELSE
        寻找待分类数据的最好特征
        划分子数据集
        创建分支节点
        for 每个划分的子数据集
            branchPoint = CreateTree
        return 分支节点
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;大家动手实现上面的算法，输出一棵树&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;4其他思考&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#4%e5%85%b6%e4%bb%96%e6%80%9d%e8%80%83&#34;&gt;
        ##
    &lt;/a&gt;
    4.其他思考
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;思考8：数据集有什么样的影响？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考9：数据特征有什么样的影响？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# &amp;#39;meow&amp;#39;:0, &amp;#39;wong&amp;#39;:1, &amp;#39;googooda&amp;#39;:2, &amp;#39;ga&amp;#39;:3

def create_dataset():
    features = [&amp;#39;legs&amp;#39;, &amp;#39;flippers&amp;#39;, &amp;#39;voice&amp;#39;]
    dataset = [
        [4, 0, 0, &amp;#39;cat&amp;#39;],
        [4, 0, 0, &amp;#39;cat&amp;#39;],
        [4, 0, 0, &amp;#39;cat&amp;#39;],
        [4, 0, 1, &amp;#39;dog&amp;#39;],
        [4, 0, 1, &amp;#39;dog&amp;#39;],
        [2, 0, 2, &amp;#39;chicken&amp;#39;],
        [2, 0, 2, &amp;#39;chicken&amp;#39;],
        [2, 1, 3, &amp;#39;duck&amp;#39;]
    ]
    return dataset, features
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;物种&lt;/th&gt;
&lt;th&gt;腿的数量&lt;/th&gt;
&lt;th&gt;有没有脚蹼&lt;/th&gt;
&lt;th&gt;叫声&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;猫&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;喵喵&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;狗&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;旺旺&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸡&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;咯咯哒&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸭&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;嘎嘎&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;一种区分方法&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/3.png&#34; alt=&#34;3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考10：有没有其他方法？&lt;/strong&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/4.png&#34; alt=&#34;4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考11：如果使用前面的算法会得出什么样的结果呢？&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>

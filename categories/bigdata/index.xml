<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bigdata on 好奇心是探索未知世界的钥匙</title>
    <link>https://www.singleye.net/categories/bigdata/</link>
    <description>Recent content in Bigdata on 好奇心是探索未知世界的钥匙</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 11 Jan 2018 23:10:50 +0800</lastBuildDate>
    
	<atom:link href="https://www.singleye.net/categories/bigdata/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Spark开发</title>
      <link>https://www.singleye.net/2018/01/spark%E5%BC%80%E5%8F%91/</link>
      <pubDate>Thu, 11 Jan 2018 23:10:50 +0800</pubDate>
      
      <guid>https://www.singleye.net/2018/01/spark%E5%BC%80%E5%8F%91/</guid>
      <description>使用scala进行开发 Step1: 安装sbt  $ curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo $ sudo yum install sbt  配置源：
 # cat ~/.sbt/repositories [repositories] # 本地源 local # 阿里源 aliyun: http://maven.aliyun.com/nexus/content/groups/public/ typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly sonatype-oss-releases maven-central sonatype-oss-snapshots  Step2: 创建项目 可以使用Giter8模版创建项目。
 $ sbt new imarios/frameless.g8  spark相关的几个模版：
 holdenk/sparkProjectTemplate.g8 (Template for Scala Apache Spark project). imarios/frameless.g8 (A simple frameless template to start with more expressive types for Spark) nttdata-oss/basic-spark-project.</description>
    </item>
    
    <item>
      <title>Hive Intro</title>
      <link>https://www.singleye.net/2018/01/hive-intro/</link>
      <pubDate>Thu, 11 Jan 2018 22:25:07 +0800</pubDate>
      
      <guid>https://www.singleye.net/2018/01/hive-intro/</guid>
      <description> Reference * Hive document </description>
    </item>
    
    <item>
      <title>Hcatalog简介</title>
      <link>https://www.singleye.net/2018/01/hcatalog%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Thu, 11 Jan 2018 19:51:16 +0800</pubDate>
      
      <guid>https://www.singleye.net/2018/01/hcatalog%E7%AE%80%E4%BB%8B/</guid>
      <description>HCatalog是Hadoop生态链中的一个有趣的组件。HCatalog构建于Hive的metastore之上并结合了Hive的DDL，通过服务的形式开放给Hadoop生态链中的其他组件，这样即可用一种统一的形式将Hive数据仓库中的数据的metadata开放给需要的服务，这样的话需要的服务就可以通过HCatalog来了解到所使用的数据的内容以及格式等等元信息。
下图展示了HCatalog在Hadoop生态系统中的定位：
可以看出HCatalog内置可以支持多种数据格式：
 ORC RC Text SequenceFile  另外用户还可以自定义格式，不过需要编写InputFormat, OutputFormat, SerDe(Serializer/Deserializer):
HCatalog提供了&amp;rsquo;hcat&amp;rsquo;
 $ hcat usage: hcat { -e &#34;&#34; | -f &#34;&#34; } [ -g &#34;&#34; ] [ -p &#34;&#34; ] [ -D&#34;=&#34; ] -D  use hadoop value for given property -e  hcat command given from command line -f  hcat commands in file -g  group for the db/table specified in CREATE statement -h,--help Print help information -p  permissions for the db/table specified in CREATE statement  参数-e提供了使用Hive &amp;lsquo;DDL&amp;rsquo;命令的接口</description>
    </item>
    
    <item>
      <title>Yarn Config</title>
      <link>https://www.singleye.net/2017/12/yarn-config/</link>
      <pubDate>Fri, 29 Dec 2017 11:44:51 +0800</pubDate>
      
      <guid>https://www.singleye.net/2017/12/yarn-config/</guid>
      <description>Resource manager Node manager Application master
 资源
 Container
 container所需资源，minimum/maximum memory/vcores  Scheduler
 FIFO CapacityScheduler FairScheduler  Queue
  Application &amp;mdash; scheduler &amp;mdash;&amp;gt; Queue
yarn-site.xml中配置。
下文引用自http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/
Node manager Node manager architecture
ResourceManager相关配置参数  （1） yarn.resourcemanager.address  参数解释：ResourceManager 对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等。
默认值：${yarn.resourcemanager.hostname}:8032
 （2） yarn.resourcemanager.scheduler.address  参数解释：ResourceManager 对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等。
默认值：${yarn.resourcemanager.hostname}:8030
 （3） yarn.resourcemanager.resource-tracker.address 参数解释：ResourceManager 对NodeManager暴露的地址.。NodeManager通过该地址向RM汇报心跳，领取任务等。 默认值：${yarn.resourcemanager.hostname}:8031
 （4） yarn.resourcemanager.admin.address
  参数解释：ResourceManager 对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等。
默认值：${yarn.resourcemanager.hostname}:8033
 （5） yarn.resourcemanager.webapp.address  参数解释：ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息。</description>
    </item>
    
    <item>
      <title>Sqoop介绍及使用</title>
      <link>https://www.singleye.net/2017/12/sqoop%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 25 Dec 2017 18:11:29 +0800</pubDate>
      
      <guid>https://www.singleye.net/2017/12/sqoop%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/</guid>
      <description>1. HDP中使用sqoop进行工作流处理准备工作 1.1 准备hdfs中的用户目录  在进行hdfs操作前需要切换用户到&amp;rsquo;hdfs&amp;rsquo;
# su - hdfs  为操作用户创建hdfs环境
  此处为ambari的admin用户准备环境：
 $ hdfs dfs -mkdir /user/admin $ hdfs dfs -chown admin:hdfs /user/admin $ hdfs dfs -ls /user $ hdfs dfs -chmod -R 770 /user/admin  1.2 配置ozzie  设置ozzie进程在hdfs中的proxy user
配置项：hadoop.proxyuser.oozie.groups 值：$USER_GROUPS_THAT_ALLOW_IMPERSONATION 配置项: hadoop.proxyuser.oozie.hosts 值：$OOZIE_SERVER_HOSTNAME   PS. 代理机制 ：http://dongxicheng.org/mapreduce-nextgen/hadoop-secure-impersonation/
主备namenode和resoucemanager（hadoop 2.0）上的core-site.xml中增加以下配置:
 &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;hadoop.proxyuser.oozie.groups&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;group1,group2&amp;lt;value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;hadoop.proxyuser.oozie.hosts&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;host1,host2&amp;lt;value&amp;gt; &amp;lt;/property&amp;gt;  这里，假设用户user1属于group1（注意，这里的user1和group1都是linux用户和用户组，需要在namenode和jobtracker上进行添加），此外，为了限制客户端随意部署，超级用户代理功能只支持host1和host2两个节点。经过以上配置后，在host1和host2上的客户端上，属于group1和group2的用户可以sudo成oozie用户，执行作业流。
 拷贝mysql-connector及配置  切换到oozie用户后执行：</description>
    </item>
    
    <item>
      <title>Horwonworks HDP 2.6安装过程</title>
      <link>https://www.singleye.net/2017/12/horwonworks-hdp-2.6%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Sat, 23 Dec 2017 15:38:37 +0800</pubDate>
      
      <guid>https://www.singleye.net/2017/12/horwonworks-hdp-2.6%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</guid>
      <description> 安装ambari-server # yum install ambari-server  配置ambari cluster # ambari-server setup # ambari-server start  配置cluster 步骤1:
将clsuter中的所有node设置成ssh免密码登录了的方式。
步骤2:
访问 http://&amp;lt;ambari-server&amp;gt;:8080
步骤3:
设置cluster名称
步骤4:
配置安装源，可以使用私有源：
HDP私有源：
http://hdp-repo.iwaterdata.com:7300/HDP/centos7/2.x/updates/2.6.3.0  HDP-UTILS私有源：
http://hdp-repo.iwaterdata.com:7300/HDP-UTILS-1.1.0.21/repos/centos7  步骤5:
安装程序检查配置节点
步骤6:
选择安装软件列表
步骤7:
设置各软件的配置信息
步骤8:
安装完成后程序会尝试启动各服务，有可能启动会失败（比如内存不足无法启动所有程序），只要确定程序正确安装可以继续
misc 设置JDBC driver(Customize service中 oozie需要)
# ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar  </description>
    </item>
    
  </channel>
</rss>
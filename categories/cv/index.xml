<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CV on singleye</title>
    <link>/categories/cv/</link>
    <description>singleye (CV)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <managingEditor>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</managingEditor>
    <webMaster>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</webMaster>
    <lastBuildDate>Sat, 07 May 2022 01:05:50 +0800</lastBuildDate>
    
    <atom:link href="/categories/cv/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>摄像机模型及实现</title>
      <link>/2022/05/%E6%91%84%E5%83%8F%E6%9C%BA%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 07 May 2022 01:05:50 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2022/05/%E6%91%84%E5%83%8F%E6%9C%BA%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AE%9E%E7%8E%B0/</guid>
      <description>&lt;!--toc--&gt;
&lt;p&gt;3D 设计软件和游戏中的图像经常是以一个观测者的角度展示的，可以把这个过程想象成一个人拿着一台摄像机在拍摄，在机器视觉中叫摄像机模型。&lt;/p&gt;
&lt;p&gt;研究过程中基于 OpenCV 做了一个简单实现，项目代码可以在这里下载到 &lt;a href=&#34;https://github.com/singleye/camera-model&#34;&gt;“github 代码下载”&lt;/a&gt;，欢迎大家下载交流。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.singleye.net/media/2022/05/camera-model-1.png&#34; alt=&#34;camera&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;摄像机模型的数学模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%91%84%e5%83%8f%e6%9c%ba%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%95%b0%e5%ad%a6%e6%a8%a1%e5%9e%8b&#34;&gt;
        ##
    &lt;/a&gt;
    摄像机模型的数学模型
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;座标系&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ba%a7%e6%a0%87%e7%b3%bb&#34;&gt;
        #
    &lt;/a&gt;
    座标系
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;理解摄像机模型需要建立对应的座标系，在这个模型里面涉及到了下面 3 个座标系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;世界座标系 (World frame)&lt;/p&gt;
&lt;p&gt;被观测目标存在于世界座标系中，使用世界座标系座标表示位置，是个 3 维座标系，可以使用常用的单位，比如‘米’。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;相机座标系 (Camera frame)&lt;/p&gt;
&lt;p&gt;通常使用摄像机的光学中心为原点，是一个 3 维座标系，表示从相机的光学中心原点来衡量各个目标的位置，尺度可以保持和世界座标系统一，比如都使用‘米’；相机可以移动到世界座标系中的任意位置和任意角度（姿态）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;像平面座标系 (Image plane frame)&lt;/p&gt;
&lt;p&gt;这是最终观测的图像座标系，是一个 3 维座标系，在相机中是 CCD 的座标系，例如以左上角为原点，尺度为‘像素’。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.singleye.net/media/2022/05/camera-model-2.png&#34; alt=&#34;coordinate&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;座标转换&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ba%a7%e6%a0%87%e8%bd%ac%e6%8d%a2&#34;&gt;
        #
    &lt;/a&gt;
    座标转换
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;当移动摄像机时，摄像机成像的结果可以通过座标转换来完成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把世界座标系中的物体座标进行&amp;rsquo;座标系变换&amp;rsquo;，转换成相机座标系中的座标&lt;/li&gt;
&lt;li&gt;通过相机内参转换到像平面座标系&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;座标系变换过程&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ba%a7%e6%a0%87%e7%b3%bb%e5%8f%98%e6%8d%a2%e8%bf%87%e7%a8%8b&#34;&gt;
        ##
    &lt;/a&gt;
    座标系变换过程
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;世界座标 $O_w$ 用下面形式表示:&lt;/p&gt;
$$
\left(
	\begin{matrix}
		X_w \\
		Y_w \\
		Z_w
	\end{matrix}
\right)
$$
&lt;p&gt;摄像机在世界座标系中被移动到 $t$ 位置：&lt;/p&gt;
$$
\left(
	\begin{matrix}
		x_t \\
		y_t \\
		z_t
	\end{matrix}
\right)
$$
&lt;p&gt;&lt;strong&gt;第一步&lt;/strong&gt;：先抵消掉摄像机的空间移动 $t$，也就是 $O_w - t$。这一步后新的座标系与摄像机座标系原点重叠。&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		O_w - t
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		X_w - t_x \\\
		Y_w - t_y \\\
		Z_w - t_z
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://www.singleye.net/media/2022/05/camera-model-3.png&#34; alt=&#34;Step1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二步&lt;/strong&gt;：旋转座标系第一步后的新座标系到摄像机座标座标系，旋转矩阵 $R$ ，关于座标旋转参见&lt;a href=&#34;https://www.singleye.net/2021/01/%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5/&#34;&gt;旋转矩阵&lt;/a&gt;，完成旋转后得到了摄像机座标系下的座标 $O_c$&lt;/p&gt;
&lt;div&gt;
$$
O_c =
R*
\left(
		O_w - t
\right)=
R*
\left(
	\begin{matrix}
		X_w - t_x \\\
		Y_w - t_y \\\
		Z_w - t_z
	\end{matrix}
\right)
=
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://www.singleye.net/media/2022/05/camera-model-4.png&#34; alt=&#34;Step2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;相机座标转化到像平面座标&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%9b%b8%e6%9c%ba%e5%ba%a7%e6%a0%87%e8%bd%ac%e5%8c%96%e5%88%b0%e5%83%8f%e5%b9%b3%e9%9d%a2%e5%ba%a7%e6%a0%87&#34;&gt;
        ##
    &lt;/a&gt;
    相机座标转化到像平面座标
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;先看一下小孔成像模型，使用虚拟像平面可以把座标转换简化。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.singleye.net/media/2022/05/camera-model-6.png&#34; alt=&#34;虚拟像平面&#34;&gt;&lt;/p&gt;
&lt;p&gt;简化后的模型如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.singleye.net/media/2022/05/camera-model-5.png&#34; alt=&#34;Step3&#34;&gt;&lt;/p&gt;
&lt;p&gt;摄像机座标系与虚拟像平面交于点 $(x_o, y_o)$，摄像机座标系下的点 $O_c$ 在虚拟像平面上的投影点是 $(x&amp;rsquo;, y&amp;rsquo;)$&lt;/p&gt;
&lt;p&gt;通过相似三角形可以容易得到：$ x&amp;rsquo; \over X_c $ = $ y&amp;rsquo; \over Y_c $ = $ f \over Z_c $，也就是：&lt;/p&gt;
$$ x‘ = f \frac {X_c} {Z_c} $$
$$ y’ = f \frac {Y_c} {Z_c} $$
$$ z‘ = f \frac {Z_c} {Z_c} $$
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x&#39; \\\
		y&#39; \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;在摄像机虚拟像平面座标系下（左上角为原点，像素为单位），摄像机座标系与虚拟像平面的交点像素座标为 $(x_o, y_o)$，摄像机座标系下的点 $O_c$ 在虚拟像平面上投影点像素级座标是 $(x, y)$，摄像机 CCD 的像素点在 x 和 y 轴方向上的排列密度为 $\sigma_x$ （单位：pixels/meter）和 $\sigma_y$ （单位：pixels/meter），那么：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x&#39; \\\
		y&#39; \\\
		f
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		\frac {x - x_o} {\sigma_x} \\\
		\frac {y - x_o} {\sigma_y} \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;中间式子可以写成下面形式：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		\frac {x - x_o} {\sigma_x} \\\
		\frac {y - x_o} {\sigma_y} \\\
		f
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		\frac 1 {\sigma_x}		&amp;	0	&amp;	0 \\\
		0	&amp;	\frac 1 {\sigma_y}	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		x - x_o \\\
		y - y_o \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;通过逆矩阵运算得到：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x - x_o \\\
		y - y_o \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		\sigma_x		&amp;	0	&amp;	0 \\\
		0	&amp;	\sigma_y	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;再把第一个矩阵拆成下面的形式：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x - x_o \\\
		y - y_o \\\
		f
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		1	&amp;	0	&amp;	-\frac {x_o} f 	\\\
		0	&amp;	1	&amp;	-\frac {y_o} f	\\\
		0	&amp;	0	&amp;	1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		x \\\
		y \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		\sigma_x		&amp;	0	&amp;	0 \\\
		0	&amp;	\sigma_y	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;再做矩阵逆运算得到：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x \\\
		y \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		1	&amp;	0	&amp;	\frac {x_o} f 	\\\
		0	&amp;	1	&amp;	\frac {y_o} f	\\\
		0	&amp;	0	&amp;	1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		\sigma_x		&amp;	0	&amp;	0 \\\
		0	&amp;	\sigma_y	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)=
1/Z
\left(
	\begin{matrix}
		f \sigma_x	&amp;	0				&amp;	x_o \\\
		0				&amp;	f \sigma_y	&amp;	y_o \\\
		0				&amp;	0				&amp;	1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;h2 id=&#34;摄像机数学模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%91%84%e5%83%8f%e6%9c%ba%e6%95%b0%e5%ad%a6%e6%a8%a1%e5%9e%8b&#34;&gt;
        #
    &lt;/a&gt;
    摄像机数学模型
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;现在已经有了一个摄像机的数学模型：&lt;/p&gt;
&lt;p&gt;**第一步：**把观察目标从世界坐标旋转到摄像机坐标&lt;/p&gt;
&lt;div&gt;
$$
O_c =
R*
\left(
		O_w - t
\right)=
R*
\left(
	\begin{matrix}
		X_w - t_x \\\
		Y_w - t_y \\\
		Z_w - t_z
	\end{matrix}
\right)
=
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;**第二步：**把摄像机坐标转换到摄像机虚拟像平面像素坐标&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x \\\
		y \\\
		f
	\end{matrix}
\right)=
&lt;p&gt;1/Z
\left(
\begin{matrix}
f \sigma_x	&amp;amp;	0				&amp;amp;	x_o \\
0				&amp;amp;	f \sigma_y	&amp;amp;	y_o \\
0				&amp;amp;	0				&amp;amp;	1
\end{matrix}
\right)
\left(
\begin{matrix}
X_c \\
Y_c \\
Z_c
\end{matrix}
\right)
$$&lt;/p&gt;
&lt;/div&gt;
&lt;h1 id=&#34;实现一个摄像机模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ae%9e%e7%8e%b0%e4%b8%80%e4%b8%aa%e6%91%84%e5%83%8f%e6%9c%ba%e6%a8%a1%e5%9e%8b&#34;&gt;
        ##
    &lt;/a&gt;
    实现一个摄像机模型
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;**第一步：**世界坐标系到相机坐标系转换&lt;/p&gt;
&lt;p&gt;根据摄像机旋转角度计算出旋转矩阵 R：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      def rotate(self, roll, pitch, yaw):
          &amp;#39;&amp;#39;&amp;#39;
          Rotate camera by roll, pitch, yaw
          &amp;#39;&amp;#39;&amp;#39;
          rx, _ = cv2.Rodrigues((pitch, 0, 0))
 Rodrigues(src, dst=None, jacobian=None, /) -&amp;gt; dst, jacobian                                                                            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;被观测物体的世界坐标转换到相机坐标：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      def trans_to_cam(self, v):
          &amp;#39;&amp;#39;&amp;#39;
          Transform the world coordinate vertices to camera coordinate vertices
              v: vertices in world coordinate frame
          &amp;#39;&amp;#39;&amp;#39;
          vc = np.dot(self.R, (v.T - np.array([[self._x], [self._y], [self._z]])))
          return vc.T
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;**第二步：**把相机坐标投影到相机虚拟像平面上&lt;/p&gt;
&lt;p&gt;定义相机内参：包括焦距、CCD像素密度参数，写出相机内参矩阵&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;          # camera focus length in meter
          self._f = 1

          # scale factor: pixels/meter
          self._s = 800
          
          # camera intrinsic matrix
          self.intrinsic = np.array([[self._f*self._s,    0,                  self._canvas_width/2.0],
                                     [0,                  self._f*self._s,    self._canvas_height/2.0],
                                     [0,                  0,                  1]])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;进行投影转换计算。**注：**由于程序实现时世界/相机坐标系采用的是右手Z轴向前的形式，因此计算结果多了一步转换的运算。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      def project(self, v):
          &amp;#39;&amp;#39;&amp;#39;
          Project the vertices of camera coordinate to camera image plane coordinate
              v: vertices in camera coordinate frame
                  u = width - f*(Y/X)
                  v = height - f*(Z/X)
          &amp;#39;&amp;#39;&amp;#39;
          Z = np.expand_dims(v[:, -1], axis=1)
          proj_v = np.dot(self.intrinsic, v.T) / Z
          proj_v = proj_v.T
          proj_v[:, 0:2] = [self._canvas_width, self._canvas_height] - proj_v[:, 0:2]
          return proj_v[:, :2]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Demo：&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&#34;video_container&#34;&gt;
  &lt;video controls=&#34;true&#34; allowfullscreen=&#34;true&#34; poster=&#34;https://raw.githubusercontent.com/singleye/camera-model/master/examples/camera-model-1.png&#34; width=&#34;400&#34; height=&#34;300&#34;&gt;
    &lt;source src=&#34;https://raw.githubusercontent.com/singleye/camera-model/master/examples/demo.m4v&#34; type=&#34;video/mp4&#34;&gt;
  &lt;/video&gt;
&lt;/figure&gt;
&lt;h1 id=&#34;参考&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;
        ##
    &lt;/a&gt;
    参考
&lt;/div&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CV-xueba/A01_cvclass_basic&#34;&gt;CS231A 鲁鹏&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kth.instructure.com/courses/6163&#34;&gt;DD2429 from KTH&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>哈希计算图片相似性</title>
      <link>/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</link>
      <pubDate>Mon, 03 Jun 2019 15:19:04 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</guid>
      <description>&lt;!--toc--&gt;
&lt;h1 id=&#34;ahash平均哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#ahash%e5%b9%b3%e5%9d%87%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    aHash（平均哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;将图片缩小到8x8的尺寸&lt;/li&gt;
&lt;li&gt;将缩小后的图片转换成灰度图&lt;/li&gt;
&lt;li&gt;计算8x8图片所有像素灰度值的平均值&lt;/li&gt;
&lt;li&gt;创建一个新的8x8矩阵，矩阵的每个值取值为0或1，计算方法是将原矩阵中对应像素的的灰度值与平均值进行对比，当大于等于平均值时记1，小于平均值时记0&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def ahash(filepath):
    img = cv2.imread(filepath)
    small = cv2.resize(img, (8, 8), interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    fp = 0
    mean = gray.mean()
    w, h = gray.shape
    for x in range(w):
        for y in range(h):
            if gray[x][y] &amp;gt;= mean:
                fp += ((fp &amp;lt;&amp;lt; 1) + 1)
            else:
                fp += ((fp &amp;lt;&amp;lt; 1) + 0)
    return fp
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;dhash差值哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#dhash%e5%b7%ae%e5%80%bc%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    dHash（差值哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def dhash(filepath):
    img = cv2.imread(filepath)
    small = cv2.resize(img, (9, 8), interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    fp = 0
    mean = gray.mean()
    w, h = gray.shape
    for x in range(w-1):
        for y in range(h):
            # if the pixel on the left is brighter mark it as 1
            if gray[x][y] &amp;gt; gray[x+1][y]:
                fp += ((fp &amp;lt;&amp;lt; 1) + 1)
            else:
                fp += ((fp &amp;lt;&amp;lt; 1) + 0)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;phash感知哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#phash%e6%84%9f%e7%9f%a5%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    pHash（感知哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;pHash算法主要是使用了离散余弦变换（DCT）进行转换。&lt;/p&gt;
&lt;p&gt;利用感知哈希算法计算图片相似度
计算步骤：&lt;/p&gt;
&lt;p&gt;缩放图片：一般大小为32*32，这样方便DCT计算&lt;/p&gt;
&lt;p&gt;简化色彩，转化为灰度图：可以使用Image的convert(&amp;lsquo;L&amp;rsquo;)方法&lt;/p&gt;
&lt;p&gt;计算DCT（离散余弦变换）:&lt;/p&gt;
&lt;p&gt;获得图像的二维数据矩阵f(x,y)&lt;/p&gt;
&lt;p&gt;求离散余弦变换的系数矩阵[A]&lt;/p&gt;
&lt;p&gt;求系数矩阵对应的转置矩阵[A]T&lt;/p&gt;
&lt;p&gt;根据公式[F(u,v)]=[A][f(x,y)][A]T 计算离散余弦变换
缩小DCT：DCT计算后的矩阵是32&lt;em&gt;32，保留左上角的8&lt;/em&gt;8，这些代表的图片的最低频率&lt;/p&gt;
&lt;p&gt;计算平均值：计算缩小DCT后的所有像素点的平均&lt;/p&gt;
&lt;p&gt;进一步减小DCT：大于平均值记录为1，否则为0&lt;/p&gt;
&lt;p&gt;得到64位信息指纹&lt;/p&gt;
&lt;p&gt;记录两张图片的图像指纹的汉明距离，计算图片相似度&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def phash(filepath, shape=(1, 1)):
    fp = np.zeros(shape, dtype=np.ulonglong)
    try:
        img = cv2.imread(filepath)
        resize = cv2.resize(img, (32, 32))
        gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)
    except Exception as e:
        print(&amp;#39;-&amp;#39;*80)
        print(&amp;#39;Exception: image [%s]&amp;#39; % filepath)
        print(e)
        print(&amp;#39;-&amp;#39;*80)
        return fp

    left_upper = cv2.dct(gray.astype(float))[:8, :8]
    mean = left_upper.mean()
    h, w = left_upper.shape
    for x in range(w):
        for y in range(h):
            val = int(fp[y//8, x//8])
            if left_upper[y, x] &amp;gt;= mean:
                fp[y//8, x//8] = ((val &amp;lt;&amp;lt; 1) | 1)
            else:
                fp[y//8, x//8] = ((val &amp;lt;&amp;lt; 1) | 0)
    return fp
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;直方图&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%9b%b4%e6%96%b9%e5%9b%be&#34;&gt;
        ##
    &lt;/a&gt;
    直方图
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nivance/image-similarity&#34;&gt;https://github.com/nivance/image-similarity&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nivance/image-similarity/blob/master/src/main/java/image/similarity/ImageHistogram.java&#34;&gt;https://github.com/nivance/image-similarity/blob/master/src/main/java/image/similarity/ImageHistogram.java&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;直方图算法是对源图像与要筛选的图像进行直方图数据采集，对采集的各自图像直方图进行归一化再使用巴氏系数算法对直方图数据进行计算，最终得出图像相似度值，其值范围在[0, 1]之间0表示极其不同，1表示极其相似（相同）。&lt;/p&gt;
&lt;p&gt;算法步骤大致可以分为两步，根据源图像与候选图像的像素数据，生成各自直方图数据。第二步：使用第一步输出的直方图结果，运用巴氏系数（Bhattacharyya coefficient）算法，计算出相似程度值。&lt;/p&gt;
&lt;p&gt;第一步：直方图计算 直方图分为灰度直方图与RGB直方图，对于灰度图像直方图计算十分简单，只要初始化一个大小为256的直方图数组H，然后根据像素值完成频率分布统计，假设像素值为124，则H[124] += 1, 而对于彩色RGB像素来说直方图表达有两种方式，一种是单一直方图，另外一种是三维直方图，三维直方图比较简单明了，分别对应RGB三种颜色，定义三个直方图HR,HG, HB, 假设某一个像素点P的RGB值为(4, 231,129), 则对于的直方图计算为HR[4] += 1,HG[231] += 1, HB[129] += 1, 如此对每个像素点完成统计以后，RGB彩色直方图数据就生成了。 而RGB像素的单一直方图SH表示稍微复杂点，每个颜色的值范围为0 ~ 255之间的，假设可以分为一定范围等份，当8等份时，每个等份的值范围为32， 16等份时，每个等份值范围为16，当4等份时候，每个等份值的范围为64，假设RGB值为(14, 68, 221), 16等份之后，它对应直方图索引值(index)分别为: (0, 4, 13), 根据计算索引值公式:index = R + G * 16 + B * 16 * 16 对应的直方图index = 0 + 4 * 16 + 13 * 16 * 16， SH[3392] += 1如此遍历所有RGB像素值，完成直方图数据计算。&lt;/p&gt;
&lt;p&gt;第二步：巴氏系数计算，计算公式如下：$\sum_{i=1}^N\sqrt{p(i)p^{&amp;rsquo;}(i)}$ 。其中p, p&amp;rsquo;分别代表源与候选的图像直方图数据，对每个相同i的数据点乘积开平方以后相加得出的结果即为图像相似度值（巴氏系数因子值），范围为0到1之间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cse.yorku.ca/~kosta/CompVis_Notes/bhattacharyya.pdf&#34;&gt;Bhattacharyya Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;其他思想&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%85%b6%e4%bb%96%e6%80%9d%e6%83%b3&#34;&gt;
        ##
    &lt;/a&gt;
    其他思想
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;大津法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%a4%a7%e6%b4%a5%e6%b3%95&#34;&gt;
        #
    &lt;/a&gt;
    大津法
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html&#34;&gt;Otsu Thresholding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html&#34;&gt;阮一峰blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1979年，日本学者大津展之证明了，&amp;ldquo;类内差异最小&amp;quot;与&amp;quot;类间差异最大&amp;quot;是同一件事，即对应同一个阈值。他提出一种简单的算法，可以求出这个阈值，这被称为&amp;quot;大津法&amp;rdquo;（Otsu&amp;rsquo;s method）。下面就是他的计算方法。&lt;/p&gt;
&lt;p&gt;假定一张图片共有n个像素，其中灰度值小于阈值的像素为 n1 个，大于等于阈值的像素为 n2 个（ n1 + n2 = n ）。w1 和 w2 表示这两种像素各自的比重。
　　w1 = n1 / n
　　w2 = n2 / n
再假定，所有灰度值小于阈值的像素的平均值和方差分别为 μ1 和 σ1，所有灰度值大于等于阈值的像素的平均值和方差分别为 μ2 和 σ2。于是，可以得到
　　类内差异 = w1(σ1的平方) + w2(σ2的平方)
　　类间差异 = w1w2(μ1-μ2)^2
可以证明，这两个式子是等价的：得到&amp;quot;类内差异&amp;quot;的最小值，等同于得到&amp;quot;类间差异&amp;quot;的最大值。不过，从计算难度看，后者的计算要容易一些。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on 好奇心是探索未知世界的钥匙</title>
    <link>https://www.singleye.net/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on 好奇心是探索未知世界的钥匙</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 09 Aug 2019 10:57:50 +0800</lastBuildDate>
    
	<atom:link href="https://www.singleye.net/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>机器学习笔记 - 贝叶斯分类法推导</title>
      <link>https://www.singleye.net/2019/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0---%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E6%B3%95%E6%8E%A8%E5%AF%BC/</link>
      <pubDate>Fri, 09 Aug 2019 10:57:50 +0800</pubDate>
      
      <guid>https://www.singleye.net/2019/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0---%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E6%B3%95%E6%8E%A8%E5%AF%BC/</guid>
      <description>&lt;!--toc--&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>哈希计算图片相似性</title>
      <link>https://www.singleye.net/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</link>
      <pubDate>Mon, 03 Jun 2019 15:19:04 +0800</pubDate>
      
      <guid>https://www.singleye.net/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</guid>
      <description>&lt;!--toc--&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习 - 决策树</title>
      <link>https://www.singleye.net/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0---%E5%86%B3%E7%AD%96%E6%A0%91/</link>
      <pubDate>Mon, 15 Apr 2019 17:04:37 +0800</pubDate>
      
      <guid>https://www.singleye.net/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0---%E5%86%B3%E7%AD%96%E6%A0%91/</guid>
      <description>&lt;!--toc--&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>模型评估指标</title>
      <link>https://www.singleye.net/2019/03/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</link>
      <pubDate>Thu, 28 Mar 2019 15:49:48 +0800</pubDate>
      
      <guid>https://www.singleye.net/2019/03/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</guid>
      <description>&lt;!--toc--&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习资料收集</title>
      <link>https://www.singleye.net/2019/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86/</link>
      <pubDate>Sat, 23 Mar 2019 23:23:28 +0800</pubDate>
      
      <guid>https://www.singleye.net/2019/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86/</guid>
      <description>&lt;!--toc--&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Build Tensorflow v1.7 on NVIDIA Jetson tx2</title>
      <link>https://www.singleye.net/2018/04/build-tensorflow-v1.7-on-nvidia-jetson-tx2/</link>
      <pubDate>Thu, 12 Apr 2018 11:06:51 +0800</pubDate>
      
      <guid>https://www.singleye.net/2018/04/build-tensorflow-v1.7-on-nvidia-jetson-tx2/</guid>
      <description>&lt;!--toc--&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>softmax输出层公式推导及代码实验</title>
      <link>https://www.singleye.net/2017/10/softmax%E8%BE%93%E5%87%BA%E5%B1%82%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E9%AA%8C/</link>
      <pubDate>Mon, 02 Oct 2017 02:11:00 +0000</pubDate>
      
      <guid>https://www.singleye.net/2017/10/softmax%E8%BE%93%E5%87%BA%E5%B1%82%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E9%AA%8C/</guid>
      <description>sigmoid激活函数在神经网络中有着强大的通用性，但也存在这一些问题，比如：
 在w/b参数还没有训练成熟时，训练预测偏差较大，此时的训练速度会较慢。这个问题的解决方法有两种：  使用交叉熵代价函数: $ C = -{1\over n} \sum_{i=1}^n [y_i \ln a_i + (1-y_i) \ln (1-a_i)] $ 使用softmax和log-likelyhood代价函数作为输出层  sigmoid的输出结果是伯努利分布 $ P(y_1|X), P(y_2|X), &amp;hellip; P(y_n|X) $，说明每一个输出项之间是相互独立的，这在预测一种输出结果的情形时不太符合人们的直观感受。这个问题也可以用softmax输出层解决，因为softmax的输出是多项分布：$ P(y_1, y_2, &amp;hellip; y_n | X) $，其中y1, &amp;hellip; yn之间相互关联，且总和为1。  这样看起来softmax是个很有效的方法，下面就对这个方法进行一些研究。
softmax定义：  $$ softmax(z_j) = {e^{z_j} \over {\sum_{i=1}^m e^{z_i} }} , j=1, ... m $$  将softmax层应用在网络输出层时，每一个神经元的softmax激活输出可以理解为该神经元对应结果的预测概率，这里有几个基本事实：
 每个神经元的输出为正数，并且输出数值介于0-1之间。 所有神经元的输出总和为1。 某一项输入（Z值）增大时，其对应的输出概率增大；同时其他输出概率同时减小（总和总是1）。该结论可以从$ \frac {\partial a_i} {\partial {z_i}} $（总为正数）以及$ \frac {\partial a_i} {\partial {z_j}}$（总为负数）推算出来，这两个数字也说明了softmax的输入／输出单调性。 softmax的每个激活输出值之间相互关联，表现出了输出非局部性特征。直观的理解就是因为所有激活输出的总和总是为1，那么其中一个激活输出的值发生变动的时候其他的激活输出也必将变化。这一点也是跟sigmoid激活函数的很不同的一点，也说明了$ \frac {\partial a_i} {\partial {z_j}}$值存在的意义。  下图展示了softmax层工作的基本原理。</description>
    </item>
    
    <item>
      <title>神经网络之反向传播算法</title>
      <link>https://www.singleye.net/2017/09/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 25 Sep 2017 15:44:00 +0000</pubDate>
      
      <guid>https://www.singleye.net/2017/09/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/</guid>
      <description>之前使用神经网络算法的时候并没有认真总结关键的算法，虽然可以用但总觉得不爽，于是这两天对神经网络算法中的反向传播（Back Propagation）进行了推导。即理解了算法的数学本质，也对神经网络算法的工程特性有了深刻体会，工程算法真的是以解决问题为驱动的，追求的是解决问题的实用性。
神经网络 网络拓扑 神经元 神经元是神经网络的基本构成，上图的每一个圆圈代表了一个神经元。每一个神经元有一个输入和一个输出，神经元的作用是对输入值进行计算。下图是一个神经元的简单示意图：
 该神经元的输出：$ a=f(z)=sigmoid(z) $  神经元输入 在一个复杂点的神经网络中，一个神经元接收来自多个前级神经元的激活输出，并进行加权相加后产生该神经元的输入值，这个过程示意图如下：
定义第 $ l^{th} $ 层第 $ j^{th} $ 个神经元的输入：
神经元加权 神经元的加权结构可以看下面的示意图：
注，第一层神经元的输入就是采样数据，不需要计算z值，这层采样数据直接通过权重计算输入到第二层的神经元。
反向传播算法 代价函数 定义代价函数：$ cost = {1 \over 2} \sum (y^{(i)} - a^{(i)})^2 $
神经元错误量 $ \delta_j^{(l)} $ 每个神经元的输入记为&amp;rsquo;z&amp;rsquo;，经过激活函数&amp;rsquo;f(z)&amp;lsquo;生成激活值&amp;rsquo;a&amp;rsquo;，通常情况下激活函数使用sigmoid()。那么假设对于每个神经元的输入&amp;rsquo;z&amp;rsquo;做一点微小的改变记为 $ \Delta z $，由这个改变引起的代价变化记为这个神经元的错误量 $ \delta_j^{(l)} $，从这个定义可以看出来这是一个代价函数相对于神经元的输入&amp;rsquo;z&amp;rsquo;的偏导数。
定义 $ \delta_j^{(l)} $ 为 $ l^{th} $ 层中的第 $ j^{th} $ 个神经元的错误量，记作：$ \delta_j^{(l)} =\frac{\partial C}{\partial z_j^{(l)}} $
经过数学推导可以得出结论：</description>
    </item>
    
    <item>
      <title>在 Nvidia Jetson TX2 上编译安装tensorflow</title>
      <link>https://www.singleye.net/2017/09/%E5%9C%A8-nvidia-jetson-tx2-%E4%B8%8A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85tensorflow/</link>
      <pubDate>Thu, 14 Sep 2017 00:22:00 +0000</pubDate>
      
      <guid>https://www.singleye.net/2017/09/%E5%9C%A8-nvidia-jetson-tx2-%E4%B8%8A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85tensorflow/</guid>
      <description>系统环境  Jetpack：v3.0 CUDA：8.0 cuDNN：5.1.10  编译安装bazel bazel是google开发的一套开发管理工具，功能类似makefile和maven，特点是速度快，编译tensorflow时需要用到这个工具。
在TX2上安装bazel需要对bazel源代码做一点修改以支持该平台。下载代码后修改文件 &amp;ldquo;bazel/src/main/java/com/google/devtools/build/lib/util/CPU.java&amp;rdquo;，修改如下：
public enum CPU { X86_32(&amp;quot;x86_32&amp;quot;, ImmutableSet.of(&amp;quot;i386&amp;quot;, &amp;quot;i486&amp;quot;, &amp;quot;i586&amp;quot;, &amp;quot;i686&amp;quot;, &amp;quot;i786&amp;quot;, &amp;quot;x86&amp;quot;)), X86_64(&amp;quot;x86_64&amp;quot;, ImmutableSet.of(&amp;quot;amd64&amp;quot;, &amp;quot;x86_64&amp;quot;, &amp;quot;x64&amp;quot;)), PPC(&amp;quot;ppc&amp;quot;, ImmutableSet.of(&amp;quot;ppc&amp;quot;, &amp;quot;ppc64&amp;quot;, &amp;quot;ppc64le&amp;quot;)), - ARM(&amp;quot;arm&amp;quot;, ImmutableSet.of(&amp;quot;arm&amp;quot;, &amp;quot;armv7l&amp;quot;)), + ARM(&amp;quot;arm&amp;quot;, ImmutableSet.of(&amp;quot;arm&amp;quot;, &amp;quot;armv7l&amp;quot;, &amp;quot;aarch64&amp;quot;)), S390X(&amp;quot;s390x&amp;quot;, ImmutableSet.of(&amp;quot;s390x&amp;quot;, &amp;quot;s390&amp;quot;)), UNKNOWN(&amp;quot;unknown&amp;quot;, ImmutableSet.&amp;lt;String&amp;gt;of());  修改好之后在代码目录运行 &amp;ldquo;compile.sh&amp;rdquo; 进行编译，编译好后将程序拷贝到执行环境：
$ sudo cp output/bazel /usr/local/bin  安装tensorflow 下载tensorflow源码 写这篇文章的时候tensorflow已经发展到了v1.3，下载release版本代码：
$ wget https://github.com/tensorflow/tensorflow/archive/v1.3.0.tar.gz  编译tensorflow  配置configure  首先configure编译环境：
nvidia@tegra-ubuntu:~/tensorflow/tensorflow-1.3.0$ ./configure You have bazel 0.</description>
    </item>
    
    <item>
      <title>The Current State of Machine Intelligence (from Shivon Zilis)</title>
      <link>https://www.singleye.net/2017/09/the-current-state-of-machine-intelligence-from-shivon-zilis/</link>
      <pubDate>Fri, 01 Sep 2017 14:29:00 +0000</pubDate>
      
      <guid>https://www.singleye.net/2017/09/the-current-state-of-machine-intelligence-from-shivon-zilis/</guid>
      <description>看到几张描绘近几年来机器学习领域的行业版图：
&amp;ldquo;The Current State of Machine Intelligence 3.0&amp;rdquo; published in 2016 by Shivon Zilis
&amp;ldquo;The current state of machine intelligence 2.0&amp;rdquo; published in 2015 by Shivon Zilis
&amp;ldquo;The Current State of Machine Intelligence&amp;rdquo; published in 2014 by Shivon Zilis</description>
    </item>
    
    <item>
      <title>神经网络实践：自动驾驶</title>
      <link>https://www.singleye.net/2017/08/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E8%B7%B5%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/</link>
      <pubDate>Thu, 17 Aug 2017 20:01:00 +0000</pubDate>
      
      <guid>https://www.singleye.net/2017/08/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E8%B7%B5%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/</guid>
      <description>最近学习了下神经网络，于是写了一个开车的小游戏，然后训练了一个6层神经网络自己驾驶练练手。
代码实现主要用了pygame和numpy，网络有7个输入分别对应小车前面的7个距离探头数据，2个输出进行转向输出。
 您还没有安装flash播放器,请点击 这里 安装</description>
    </item>
    
    <item>
      <title>图像卷积实践</title>
      <link>https://www.singleye.net/2017/07/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 30 Jul 2017 18:30:50 +0800</pubDate>
      
      <guid>https://www.singleye.net/2017/07/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E5%AE%9E%E8%B7%B5/</guid>
      <description>最近对图像识别技术很感兴趣，了解到在这个领域中CNN的应用可以比较有效的解决问题，这里对卷积（convolution）相关的知识进行一下记录说明。
图像卷积是什么？ 将一张图片看作一张像素的矩阵的话，卷积就是把另一个矩阵（卷积核）在这张图片上移动，在移动的过程中取图片上对应大小的矩阵与卷积核进行运算，每次矩阵运算得出的结果保存成一个新的像素，这个过程就是图像的卷积运算。
卷积的过程可以用下面的示意图展示：
为什么做卷积？ 一张原始图像包含了大量的噪音信息，这些噪音信息会干扰后续的运算过程。如果将一张图像看作一个输入信号的话，如果找到一种过滤器将噪音信息过滤掉就可以提高后续运算的准确度。卷积就是这么一个过滤器，这个过滤器的正式称呼是卷积核。
那么这个过滤器可以做些什么呢？其实常见的图像处理软件早已经在使用卷积进行图片处理了，比如图像锐化、模糊、浮雕效果等等&amp;hellip;
下面收集了一些常用的过滤器，对这张图片处理后可以看一下效果。
 图像边界检测   $$ \left[ \begin{matrix} -1 &amp; -1 &amp; -1 \\ -1 &amp; 8 &amp; -1 \\ -1 &amp; -1 &amp; -1 \end{matrix} \right] $$   图像模糊   $$ \left[ \begin{matrix} 0 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 0 \end{matrix} \right] $$   图像锐化   $$ \left[ \begin{matrix} -1 &amp; -1 &amp; -1 \\ -1 &amp; 9 &amp; -1 \\ -1 &amp; -1 &amp; -1 \end{matrix} \right] $$   浮雕   $$ \left[ \begin{matrix} -1 &amp; -1 &amp; 0 \\ -1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{matrix} \right] $$  用numpy进行卷积计算 以上的图片使用下面的算法生成，主要使用了numpy的array进行的计算。通过该算法生成的图片效果还不够理想：</description>
    </item>
    
    <item>
      <title>tensorflow playground</title>
      <link>https://www.singleye.net/2017/02/tensorflow-playground/</link>
      <pubDate>Sat, 18 Feb 2017 17:39:21 +0800</pubDate>
      
      <guid>https://www.singleye.net/2017/02/tensorflow-playground/</guid>
      <description>Tensorflow playground，感受一下machine learning的奇特之处：http://playground.tensorflow.org</description>
    </item>
    
  </channel>
</rss>
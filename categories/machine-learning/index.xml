<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on singleye</title>
    <link>/categories/machine-learning/</link>
    <description>singleye (Machine Learning)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <managingEditor>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</managingEditor>
    <webMaster>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</webMaster>
    <lastBuildDate>Fri, 09 Aug 2019 10:57:50 +0800</lastBuildDate>
    
    <atom:link href="/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>机器学习笔记 - 贝叶斯分类法推导</title>
      <link>/2019/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E6%B3%95%E6%8E%A8%E5%AF%BC/</link>
      <pubDate>Fri, 09 Aug 2019 10:57:50 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E6%B3%95%E6%8E%A8%E5%AF%BC/</guid>
      <description>&lt;!--toc--&gt;
&lt;p&gt;这篇笔记记录了最近对贝叶斯分类法的学习和理解。&lt;/p&gt;
&lt;h1 id=&#34;1概率基本概念回顾&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#1%e6%a6%82%e7%8e%87%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5%e5%9b%9e%e9%a1%be&#34;&gt;
        ##
    &lt;/a&gt;
    1.概率基本概念回顾
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;11概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#11%e6%a6%82%e7%8e%87&#34;&gt;
        #
    &lt;/a&gt;
    1.1.概率：
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;事件发生的概率 = $ \dfrac{事件可能发生的个数} {结果的总数} $&lt;/p&gt;
&lt;h2 id=&#34;12事件的分类&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#12%e4%ba%8b%e4%bb%b6%e7%9a%84%e5%88%86%e7%b1%bb&#34;&gt;
        #
    &lt;/a&gt;
    1.2.事件的分类：
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;独立事件：每个事件的发生是独立的，不受其他事件的影响，例如：抛硬币，掷骰子。&lt;/li&gt;
&lt;li&gt;相关事件：当前事件受之前发生事件的影响，例如：抽扑克牌。&lt;/li&gt;
&lt;li&gt;互斥事件：事件发生只能是其一，不能同时发生，例如：一枚硬币不能同时为正面和反面。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;13独立事件的概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#13%e7%8b%ac%e7%ab%8b%e4%ba%8b%e4%bb%b6%e7%9a%84%e6%a6%82%e7%8e%87&#34;&gt;
        #
    &lt;/a&gt;
    1.3.独立事件的概率：
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;单个独立事件的概率： P(A) = $ \dfrac{事件可能发生的个数} {结果的总数} $&lt;/li&gt;
&lt;li&gt;事件A和B发生的概率（多个独立事件的概率）： P(A B) = P(A) * P(B)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;14条件概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#14%e6%9d%a1%e4%bb%b6%e6%a6%82%e7%8e%87&#34;&gt;
        #
    &lt;/a&gt;
    1.4.条件概率：
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;在相关事件的情况中应用条件概率，用 P(B|A) 表示在事件 A 发生的条件下事件 B 发生的概率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;事件A和B发生的概率： P(A B) = P(A) * P(B|A)&lt;/p&gt;
&lt;p&gt;另外一个有用的公式转换： P(B|A) = $ \dfrac{P(A B)} {P(A)} $&lt;/p&gt;
&lt;p&gt;在事件 A 发生的情况下 B 发生的概率等于事件 A 和 B 的概率除以事件 A 的概率&lt;/p&gt;
&lt;p&gt;例子：冰淇淋&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  在你的社交群组里，70% 喜欢巧克力冰淇淋，35% 喜欢巧克力和草莓。

  在喜欢巧克力的人里，也喜欢草莓的百分比是多少？

  P(草莓|巧克力) = P(巧克力 与 草莓) / P(巧克力)

  0.35 / 0.7 = 50%

  在喜欢巧克力的人里，50% 也喜欢草莓
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;141-尝试计算下面的概率&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#141-%e5%b0%9d%e8%af%95%e8%ae%a1%e7%ae%97%e4%b8%8b%e9%9d%a2%e7%9a%84%e6%a6%82%e7%8e%87&#34;&gt;
        ##
    &lt;/a&gt;
    1.4.1. 尝试计算下面的概率
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;4个人在5个数字中各选一个数字，请问任何两个人选重的概率是多少？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/08/bayes-classification/events-dependent-ex-3.svg&#34; alt=&#34;events-dependent-ex-3.svg&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;2贝叶斯定理&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2%e8%b4%9d%e5%8f%b6%e6%96%af%e5%ae%9a%e7%90%86&#34;&gt;
        ##
    &lt;/a&gt;
    2.贝叶斯定理
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;$ P(A|B) = \dfrac {P(A)*P(B|A)} {P(B)} $&lt;/p&gt;
&lt;p&gt;在 B 发生的情况下发生 A 事件的概率 P(A|B) 可以通过已知 A 发生情况下 B 发生的概率和 A 与 B 的独自发生的概率求出来。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(A|B)：在 B 发生的情况下 A 发生的概率&lt;/li&gt;
&lt;li&gt;P(A)：A 发生的概率&lt;/li&gt;
&lt;li&gt;P(B)：B 发生的概率&lt;/li&gt;
&lt;li&gt;P(B|A)：在 A 发生的情况下 B 发生的概率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**例子1：**计算天气有云时下雨的概率：&lt;/p&gt;
&lt;p&gt;$ P(雨|云) = \dfrac {P(雨)*P(云|雨)} {P(云)} $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(雨)：下雨的概率 = 10%&lt;/li&gt;
&lt;li&gt;P(云|雨)：下雨时有云的概率 = 50%&lt;/li&gt;
&lt;li&gt;P(云)：有云的概率 = 40%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$ P(雨|云) = \dfrac {0.1 * 0.5} {0.4} = 0.125 $&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例子2：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有一种疾病检测手段，但是这种检测手段并不准确&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在真正有这种疾病的人中有 80% 的人可以被检测出&lt;/li&gt;
&lt;li&gt;对于没有这种疾病的人有 10% 的概率会被错误检测出&lt;/li&gt;
&lt;li&gt;以往的统计数据表明人群中有 1% 的人得了这种疾病，99% 的人没有得过&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;请问，当有一个人被检测出有该疾病时他真正有这种病的概率是多少？&lt;/p&gt;
&lt;p&gt;$ P(真有病|检测有病) = \dfrac {P(真有病) * P(检测有病|真有病)} {P(检测有病)} $&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;真实情况 \ 检测结果&lt;/th&gt;
&lt;th&gt;检测有病&lt;/th&gt;
&lt;th&gt;检测没病&lt;/th&gt;
&lt;th&gt;得病统计&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;真有病&lt;/td&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;td&gt;1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;真没病&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;td&gt;90%&lt;/td&gt;
&lt;td&gt;99%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;P(真有病)：1%&lt;/li&gt;
&lt;li&gt;P(检测有病|真有病)：80%&lt;/li&gt;
&lt;li&gt;P(检测有病)：P(没有病的人被检测出有病的概率) + P(真有病的人被检测出有病的概率)
&lt;ul&gt;
&lt;li&gt;P(没有病的人被检测出有病的概率) = P(真没病) * P(检测有病|真没病) = 99% * 10% = 0.099&lt;/li&gt;
&lt;li&gt;P(真有病的人被检测出有病的概率) = P(真有病) * P(检测有病|真有病) = 1% * 80% = 0.008&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$ P(真有病|检测有病) = \dfrac {1% * 80%} { 99% * 10% + 1% * 80%} =  7.48% $&lt;/p&gt;
&lt;p&gt;示意图：&lt;/p&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/08/bayes-classification/disease_1.jpeg&#34; style=&#34;width:400px&#34;/&gt;
&lt;p&gt;计算方法：&lt;/p&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/08/bayes-classification/disease_2.jpeg&#34; style=&#34;width:600px&#34;/&gt;
&lt;p&gt;那么怎么评估这个方法是否有效呢？可以使用准确度（Precision）和召回（Recall）两个指标来评估。&lt;/p&gt;
&lt;p&gt;$ Precision = \dfrac {TP} {TP + FP} = \dfrac {P(真有病) * P(检测有病|真有病)} {P(检测有病)} = \dfrac {1% * 80%} {1% * 80% + 99% * 10%} = 7.48%$&lt;/p&gt;
&lt;p&gt;$ Recall = \dfrac {TP} {TP + FN} = \dfrac {P(真有病) * P(检测有病|真有病)} {P(真有病)} = \dfrac {1% * 80%} {1%} = 80% $&lt;/p&gt;
&lt;h1 id=&#34;3贝叶斯定理在机器学习中的应用---文本分类&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#3%e8%b4%9d%e5%8f%b6%e6%96%af%e5%ae%9a%e7%90%86%e5%9c%a8%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8---%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb&#34;&gt;
        ##
    &lt;/a&gt;
    3.贝叶斯定理在机器学习中的应用 - 文本分类
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;**任务目标：**通过利用一批分好类（2类：正常/非正常）的文本信息，训练一个模型来识别一段给定文字，判断是不是正常言论。&lt;/p&gt;
&lt;p&gt;$ P(类别|数据) = \dfrac {P(类别) * P(数据|类别)} {P(数据)} $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当 P(正常|数据) &amp;gt; P(不正常|数据) 时认为文本为“正常”&lt;/li&gt;
&lt;li&gt;当 P(正常|数据) &amp;lt; P(不正常|数据) 时认为文本为“不正常”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;算法推导：&lt;/p&gt;
&lt;p&gt;进一步把问题转换成下面的表达方式：&lt;/p&gt;
&lt;p&gt;$ P(class|words) = \dfrac {P(words|class) * P(class)} {P(words)} $&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;class：代表类别&lt;/li&gt;
&lt;li&gt;words：代表一句话，它是由一组单词构成的，记做：w0, w1, w2, &amp;hellip;, wn&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$ P(class|w0, w0, w1, w2, &amp;hellip;, wn) = \dfrac {P(w0, w1, w2, &amp;hellip;, wn|class) * P(class)} {P(w0, w1, w2, &amp;hellip;, wn)} $&lt;/p&gt;
&lt;p&gt;由于 P(w0, w1, w2, &amp;hellip;, wn|class) 非常难于计算因此通过条件独立性假设把这个概率进行简化计算，最终转换成计算 P(w0|class)P(w1|class)P(w2|class)&amp;hellip;P(wn|class)。&lt;/p&gt;
&lt;p&gt;$ P(class|w0, w0, w1, w2, &amp;hellip;, wn) = \dfrac {P(w0|class)*P(w1|class)*P(w2|class)&amp;hellip;P(wn|class) * P(class)} {P(w0, w1, w2, &amp;hellip;, wn)} $&lt;/p&gt;
&lt;p&gt;训练方法就转换成根据已提供的数据计算下列概率值得过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个类别中出现某个单词的概率 P(w0|class), P(w1|class), P(w2|class)&amp;hellip;P(wn|class)&lt;/li&gt;
&lt;li&gt;训练数据中某个类别的概率 P(class)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比较 P(class1|w0, w0, w1, w2, &amp;hellip;, wn) P(class2|w0, w0, w1, w2, &amp;hellip;, wn) 可以简化成比较&lt;/p&gt;
&lt;p&gt;$ P(w0|class1)*P(w1|class1)*P(w2|class1)&amp;hellip;P(wn|class1) * P(class1) $&lt;/p&gt;
&lt;p&gt;$ P(w0|class2)*P(w1|class2)*P(w2|class2)&amp;hellip;P(wn|class2) * P(class2) $&lt;/p&gt;
&lt;p&gt;**注意：**实际计算中很少直接使用这样的乘法进行计算，主要原因是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;乘法运算计算量相对加法来说是复杂很多的&lt;/li&gt;
&lt;li&gt;由于每一项 P(wn|class1) 值很小或者为0（有时为了避免所有项为0会把每一项给一个初始化很小的数字），因此容易导致计算结果直接为0或者由于太小造成下溢出&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以，在实际情况下多使用 log 运算，根据 log 的性质可以进一步简化成比较：&lt;/p&gt;
&lt;p&gt;$ log(P(w0|class1)*P(w1|class1)*P(w2|class1)&amp;hellip;P(wn|class1) * P(class1)) = log(P(w0|class1) + log(P(w1|class1) + log(P(w2|class1) + &amp;hellip;  + log(P(wn|class1) + log(class1)$&lt;/p&gt;
&lt;p&gt;$ log(P(w0|class2)*P(w1|class2)*P(w2|class2)&amp;hellip;P(wn|class2) * P(class2)) = log(P(w0|class2) + log(P(w1|class2) + log(P(w2|class2) + &amp;hellip;  + log(P(wn|class2) + log(class2)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;另外使用 log 进行计算还有额外的好处：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先是直接将乘法运算转换成了加法，计算速度得到提升&lt;/li&gt;
&lt;li&gt;每一项 log(P(wn|class) 都可以在训练阶段固化，操作中可以直接用查表法解决进一步减少运算量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最后，引用一下来自《机器学习实战》的例子：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;from&lt;/span&gt; numpy &lt;span style=&#34;color:#ff6ac1&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;loadDataSet&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    postingList&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;[[&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;has&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;flea&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;problems&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;help&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;please&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;maybe&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;not&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;take&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;him&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;to&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;park&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dalmation&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;is&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;so&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cute&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;I&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;love&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;him&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stop&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;posting&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;worthless&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;garbage&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;mr&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;licks&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;ate&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;steak&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;how&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;to&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stop&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;him&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;quit&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;buying&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;worthless&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;food&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    classVec &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;]    &lt;span style=&#34;color:#78787e&#34;&gt;#1 is abusive, 0 not&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; postingList,classVec
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;createVocabList&lt;/span&gt;(dataSet):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vocabSet &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;set&lt;/span&gt;([])  &lt;span style=&#34;color:#78787e&#34;&gt;#create empty set&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; document &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataSet:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        vocabSet &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; vocabSet &lt;span style=&#34;color:#ff6ac1&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;set&lt;/span&gt;(document) &lt;span style=&#34;color:#78787e&#34;&gt;#union of the two sets&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;list&lt;/span&gt;(vocabSet)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;setOfWords2Vec&lt;/span&gt;(vocabList, inputSet):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    returnVec &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(vocabList)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; inputSet:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; word &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; vocabList:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            returnVec[vocabList&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;index(word)] &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;else&lt;/span&gt;: &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;the word: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt; is not in my Vocabulary!&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;%&lt;/span&gt; word)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; returnVec
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;trainNB0&lt;/span&gt;(trainMatrix,trainCategory):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    numTrainDocs &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(trainMatrix)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    numWords &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(trainMatrix[&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pAbusive &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(trainCategory)&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;float&lt;/span&gt;(numTrainDocs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; ones(numWords); p1Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; ones(numWords)      &lt;span style=&#34;color:#78787e&#34;&gt;#change to ones()，备注：初始化成1避免该项为0的情况发生&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;2.0&lt;/span&gt;; p1Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;2.0&lt;/span&gt;                        &lt;span style=&#34;color:#78787e&#34;&gt;#change to 2.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;range&lt;/span&gt;(numTrainDocs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; trainCategory[i] &lt;span style=&#34;color:#ff6ac1&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p1Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; trainMatrix[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p1Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(trainMatrix[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p0Num &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; trainMatrix[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            p0Denom &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(trainMatrix[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p1Vect &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; log(p1Num&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;p1Denom)          &lt;span style=&#34;color:#78787e&#34;&gt;#change to log()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0Vect &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; log(p0Num&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;p0Denom)          &lt;span style=&#34;color:#78787e&#34;&gt;#change to log()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; p0Vect,p1Vect,pAbusive
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;classifyNB&lt;/span&gt;(vec2Classify, p0Vec, p1Vec, pClass1):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p1 &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(vec2Classify &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; p1Vec) &lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt; log(pClass1)    &lt;span style=&#34;color:#78787e&#34;&gt;#element-wise mult&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0 &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;sum&lt;/span&gt;(vec2Classify &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; p0Vec) &lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt; log(&lt;span style=&#34;color:#ff9f43&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt; pClass1)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; p1 &lt;span style=&#34;color:#ff6ac1&#34;&gt;&amp;gt;&lt;/span&gt; p0:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;testingNB&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    listOPosts,listClasses &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; loadDataSet()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    myVocabList &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; createVocabList(listOPosts)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;[]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; postinDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; listOPosts:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;append(setOfWords2Vec(myVocabList, postinDoc))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p0V,p1V,pAb &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; trainNB0(array(trainMat),array(listClasses))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;love&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dalmation&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;garbage&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;第一步加载已分类数据并创建词典&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ac%ac%e4%b8%80%e6%ad%a5%e5%8a%a0%e8%bd%bd%e5%b7%b2%e5%88%86%e7%b1%bb%e6%95%b0%e6%8d%ae%e5%b9%b6%e5%88%9b%e5%bb%ba%e8%af%8d%e5%85%b8&#34;&gt;
        #
    &lt;/a&gt;
    第一步：加载已分类数据，并创建词典
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;listOPosts,listClasses &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; loadDataSet()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;myVocabList &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; createVocabList(listOPosts)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;All posts:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;80&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(listOPosts)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Vocabulary:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;80&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(myVocabList)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;All posts:
--------------------------------------------------------------------------------
[[&#39;my&#39;, &#39;dog&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;problems&#39;, &#39;help&#39;, &#39;please&#39;], [&#39;maybe&#39;, &#39;not&#39;, &#39;take&#39;, &#39;him&#39;, &#39;to&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;stupid&#39;], [&#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;so&#39;, &#39;cute&#39;, &#39;I&#39;, &#39;love&#39;, &#39;him&#39;], [&#39;stop&#39;, &#39;posting&#39;, &#39;stupid&#39;, &#39;worthless&#39;, &#39;garbage&#39;], [&#39;mr&#39;, &#39;licks&#39;, &#39;ate&#39;, &#39;my&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;to&#39;, &#39;stop&#39;, &#39;him&#39;], [&#39;quit&#39;, &#39;buying&#39;, &#39;worthless&#39;, &#39;dog&#39;, &#39;food&#39;, &#39;stupid&#39;]]


Vocabulary:
--------------------------------------------------------------------------------
[&#39;to&#39;, &#39;mr&#39;, &#39;quit&#39;, &#39;take&#39;, &#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;stop&#39;, &#39;worthless&#39;, &#39;him&#39;, &#39;problems&#39;, &#39;cute&#39;, &#39;maybe&#39;, &#39;I&#39;, &#39;so&#39;, &#39;not&#39;, &#39;buying&#39;, &#39;help&#39;, &#39;how&#39;, &#39;park&#39;, &#39;food&#39;, &#39;garbage&#39;, &#39;steak&#39;, &#39;please&#39;, &#39;dog&#39;, &#39;ate&#39;, &#39;licks&#39;, &#39;posting&#39;, &#39;love&#39;, &#39;stupid&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;第二步将词典数据转换成可计算的向量&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ac%ac%e4%ba%8c%e6%ad%a5%e5%b0%86%e8%af%8d%e5%85%b8%e6%95%b0%e6%8d%ae%e8%bd%ac%e6%8d%a2%e6%88%90%e5%8f%af%e8%ae%a1%e7%ae%97%e7%9a%84%e5%90%91%e9%87%8f&#34;&gt;
        #
    &lt;/a&gt;
    第二步：将词典数据转换成可计算的向量
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;[]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; postinDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; listOPosts:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    trainMat&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;append(setOfWords2Vec(myVocabList, postinDoc))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;第三步训练模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ac%ac%e4%b8%89%e6%ad%a5%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b&#34;&gt;
        #
    &lt;/a&gt;
    第三步：训练模型
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p0V,p1V,pAb &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; trainNB0(array(trainMat),array(listClasses))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;最后测试模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%9c%80%e5%90%8e%e6%b5%8b%e8%af%95%e6%a8%a1%e5%9e%8b&#34;&gt;
        #
    &lt;/a&gt;
    最后：测试模型
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;love&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;my&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dalmation&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;testEntry &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;stupid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;garbage&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;thisDoc &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; array(setOfWords2Vec(myVocabList, testEntry))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(testEntry,&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;classified as: &amp;#39;&lt;/span&gt;,classifyNB(thisDoc,p0V,p1V,pAb))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;] classified as:  0
[&#39;stupid&#39;, &#39;garbage&#39;] classified as:  1&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>哈希计算图片相似性</title>
      <link>/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</link>
      <pubDate>Mon, 03 Jun 2019 15:19:04 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</guid>
      <description>&lt;!--toc--&gt;
&lt;h1 id=&#34;ahash平均哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#ahash%e5%b9%b3%e5%9d%87%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    aHash（平均哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;将图片缩小到8x8的尺寸&lt;/li&gt;
&lt;li&gt;将缩小后的图片转换成灰度图&lt;/li&gt;
&lt;li&gt;计算8x8图片所有像素灰度值的平均值&lt;/li&gt;
&lt;li&gt;创建一个新的8x8矩阵，矩阵的每个值取值为0或1，计算方法是将原矩阵中对应像素的的灰度值与平均值进行对比，当大于等于平均值时记1，小于平均值时记0&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def ahash(filepath):
    img = cv2.imread(filepath)
    small = cv2.resize(img, (8, 8), interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    fp = 0
    mean = gray.mean()
    w, h = gray.shape
    for x in range(w):
        for y in range(h):
            if gray[x][y] &amp;gt;= mean:
                fp += ((fp &amp;lt;&amp;lt; 1) + 1)
            else:
                fp += ((fp &amp;lt;&amp;lt; 1) + 0)
    return fp
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;dhash差值哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#dhash%e5%b7%ae%e5%80%bc%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    dHash（差值哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def dhash(filepath):
    img = cv2.imread(filepath)
    small = cv2.resize(img, (9, 8), interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    fp = 0
    mean = gray.mean()
    w, h = gray.shape
    for x in range(w-1):
        for y in range(h):
            # if the pixel on the left is brighter mark it as 1
            if gray[x][y] &amp;gt; gray[x+1][y]:
                fp += ((fp &amp;lt;&amp;lt; 1) + 1)
            else:
                fp += ((fp &amp;lt;&amp;lt; 1) + 0)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;phash感知哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#phash%e6%84%9f%e7%9f%a5%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    pHash（感知哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;pHash算法主要是使用了离散余弦变换（DCT）进行转换。&lt;/p&gt;
&lt;p&gt;利用感知哈希算法计算图片相似度
计算步骤：&lt;/p&gt;
&lt;p&gt;缩放图片：一般大小为32*32，这样方便DCT计算&lt;/p&gt;
&lt;p&gt;简化色彩，转化为灰度图：可以使用Image的convert(&amp;lsquo;L&amp;rsquo;)方法&lt;/p&gt;
&lt;p&gt;计算DCT（离散余弦变换）:&lt;/p&gt;
&lt;p&gt;获得图像的二维数据矩阵f(x,y)&lt;/p&gt;
&lt;p&gt;求离散余弦变换的系数矩阵[A]&lt;/p&gt;
&lt;p&gt;求系数矩阵对应的转置矩阵[A]T&lt;/p&gt;
&lt;p&gt;根据公式[F(u,v)]=[A][f(x,y)][A]T 计算离散余弦变换
缩小DCT：DCT计算后的矩阵是32&lt;em&gt;32，保留左上角的8&lt;/em&gt;8，这些代表的图片的最低频率&lt;/p&gt;
&lt;p&gt;计算平均值：计算缩小DCT后的所有像素点的平均&lt;/p&gt;
&lt;p&gt;进一步减小DCT：大于平均值记录为1，否则为0&lt;/p&gt;
&lt;p&gt;得到64位信息指纹&lt;/p&gt;
&lt;p&gt;记录两张图片的图像指纹的汉明距离，计算图片相似度&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def phash(filepath, shape=(1, 1)):
    fp = np.zeros(shape, dtype=np.ulonglong)
    try:
        img = cv2.imread(filepath)
        resize = cv2.resize(img, (32, 32))
        gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)
    except Exception as e:
        print(&amp;#39;-&amp;#39;*80)
        print(&amp;#39;Exception: image [%s]&amp;#39; % filepath)
        print(e)
        print(&amp;#39;-&amp;#39;*80)
        return fp

    left_upper = cv2.dct(gray.astype(float))[:8, :8]
    mean = left_upper.mean()
    h, w = left_upper.shape
    for x in range(w):
        for y in range(h):
            val = int(fp[y//8, x//8])
            if left_upper[y, x] &amp;gt;= mean:
                fp[y//8, x//8] = ((val &amp;lt;&amp;lt; 1) | 1)
            else:
                fp[y//8, x//8] = ((val &amp;lt;&amp;lt; 1) | 0)
    return fp
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;直方图&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%9b%b4%e6%96%b9%e5%9b%be&#34;&gt;
        ##
    &lt;/a&gt;
    直方图
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nivance/image-similarity&#34;&gt;https://github.com/nivance/image-similarity&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nivance/image-similarity/blob/master/src/main/java/image/similarity/ImageHistogram.java&#34;&gt;https://github.com/nivance/image-similarity/blob/master/src/main/java/image/similarity/ImageHistogram.java&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;直方图算法是对源图像与要筛选的图像进行直方图数据采集，对采集的各自图像直方图进行归一化再使用巴氏系数算法对直方图数据进行计算，最终得出图像相似度值，其值范围在[0, 1]之间0表示极其不同，1表示极其相似（相同）。&lt;/p&gt;
&lt;p&gt;算法步骤大致可以分为两步，根据源图像与候选图像的像素数据，生成各自直方图数据。第二步：使用第一步输出的直方图结果，运用巴氏系数（Bhattacharyya coefficient）算法，计算出相似程度值。&lt;/p&gt;
&lt;p&gt;第一步：直方图计算 直方图分为灰度直方图与RGB直方图，对于灰度图像直方图计算十分简单，只要初始化一个大小为256的直方图数组H，然后根据像素值完成频率分布统计，假设像素值为124，则H[124] += 1, 而对于彩色RGB像素来说直方图表达有两种方式，一种是单一直方图，另外一种是三维直方图，三维直方图比较简单明了，分别对应RGB三种颜色，定义三个直方图HR,HG, HB, 假设某一个像素点P的RGB值为(4, 231,129), 则对于的直方图计算为HR[4] += 1,HG[231] += 1, HB[129] += 1, 如此对每个像素点完成统计以后，RGB彩色直方图数据就生成了。 而RGB像素的单一直方图SH表示稍微复杂点，每个颜色的值范围为0 ~ 255之间的，假设可以分为一定范围等份，当8等份时，每个等份的值范围为32， 16等份时，每个等份值范围为16，当4等份时候，每个等份值的范围为64，假设RGB值为(14, 68, 221), 16等份之后，它对应直方图索引值(index)分别为: (0, 4, 13), 根据计算索引值公式:index = R + G * 16 + B * 16 * 16 对应的直方图index = 0 + 4 * 16 + 13 * 16 * 16， SH[3392] += 1如此遍历所有RGB像素值，完成直方图数据计算。&lt;/p&gt;
&lt;p&gt;第二步：巴氏系数计算，计算公式如下：$\sum_{i=1}^N\sqrt{p(i)p^{&amp;rsquo;}(i)}$ 。其中p, p&amp;rsquo;分别代表源与候选的图像直方图数据，对每个相同i的数据点乘积开平方以后相加得出的结果即为图像相似度值（巴氏系数因子值），范围为0到1之间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cse.yorku.ca/~kosta/CompVis_Notes/bhattacharyya.pdf&#34;&gt;Bhattacharyya Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;其他思想&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%85%b6%e4%bb%96%e6%80%9d%e6%83%b3&#34;&gt;
        ##
    &lt;/a&gt;
    其他思想
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;大津法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%a4%a7%e6%b4%a5%e6%b3%95&#34;&gt;
        #
    &lt;/a&gt;
    大津法
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html&#34;&gt;Otsu Thresholding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html&#34;&gt;阮一峰blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1979年，日本学者大津展之证明了，&amp;ldquo;类内差异最小&amp;quot;与&amp;quot;类间差异最大&amp;quot;是同一件事，即对应同一个阈值。他提出一种简单的算法，可以求出这个阈值，这被称为&amp;quot;大津法&amp;rdquo;（Otsu&amp;rsquo;s method）。下面就是他的计算方法。&lt;/p&gt;
&lt;p&gt;假定一张图片共有n个像素，其中灰度值小于阈值的像素为 n1 个，大于等于阈值的像素为 n2 个（ n1 + n2 = n ）。w1 和 w2 表示这两种像素各自的比重。
　　w1 = n1 / n
　　w2 = n2 / n
再假定，所有灰度值小于阈值的像素的平均值和方差分别为 μ1 和 σ1，所有灰度值大于等于阈值的像素的平均值和方差分别为 μ2 和 σ2。于是，可以得到
　　类内差异 = w1(σ1的平方) + w2(σ2的平方)
　　类间差异 = w1w2(μ1-μ2)^2
可以证明，这两个式子是等价的：得到&amp;quot;类内差异&amp;quot;的最小值，等同于得到&amp;quot;类间差异&amp;quot;的最大值。不过，从计算难度看，后者的计算要容易一些。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习 - 决策树</title>
      <link>/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</link>
      <pubDate>Mon, 15 Apr 2019 17:04:37 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</guid>
      <description>&lt;!--toc--&gt;
&lt;h1 id=&#34;机器学习-决策树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0-%e5%86%b3%e7%ad%96%e6%a0%91&#34;&gt;
        ##
    &lt;/a&gt;
    机器学习-决策树
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;1什么是问题树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#1%e4%bb%80%e4%b9%88%e6%98%af%e9%97%ae%e9%a2%98%e6%a0%91&#34;&gt;
        #
    &lt;/a&gt;
    1.什么是问题树？
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;请思考以下场景&lt;/p&gt;
&lt;h3 id=&#34;11玩过猜字游戏吗&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#11%e7%8e%a9%e8%bf%87%e7%8c%9c%e5%ad%97%e6%b8%b8%e6%88%8f%e5%90%97&#34;&gt;
        ##
    &lt;/a&gt;
    1.1.玩过猜字游戏吗？
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;12如何通过几个问题区分猫狗鸡鸭&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#12%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e5%87%a0%e4%b8%aa%e9%97%ae%e9%a2%98%e5%8c%ba%e5%88%86%e7%8c%ab%e7%8b%97%e9%b8%a1%e9%b8%ad&#34;&gt;
        ##
    &lt;/a&gt;
    1.2.如何通过几个问题区分“猫狗鸡鸭”？
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/2.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;121他们的特征是什么&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#121%e4%bb%96%e4%bb%ac%e7%9a%84%e7%89%b9%e5%be%81%e6%98%af%e4%bb%80%e4%b9%88&#34;&gt;
        ###
    &lt;/a&gt;
    1.2.1.他们的特征是什么？
&lt;/div&gt;
&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;物种&lt;/th&gt;
&lt;th&gt;腿的数量&lt;/th&gt;
&lt;th&gt;有没有脚蹼&lt;/th&gt;
&lt;th&gt;喙的形状&lt;/th&gt;
&lt;th&gt;会不会游泳&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;猫&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;不会&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;狗&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;会&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸡&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;尖&lt;/td&gt;
&lt;td&gt;不会&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸭&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;扁&lt;/td&gt;
&lt;td&gt;会&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;数据的表示方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;类别：猫、狗、鸡、鸭&lt;/li&gt;
&lt;li&gt;特征：腿的数量、有没有脚蹼、喙的形状，会不会游泳&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;122以下是一种区分方法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#122%e4%bb%a5%e4%b8%8b%e6%98%af%e4%b8%80%e7%a7%8d%e5%8c%ba%e5%88%86%e6%96%b9%e6%b3%95&#34;&gt;
        ###
    &lt;/a&gt;
    1.2.2.以下是一种区分方法
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/6.png&#34; alt=&#34;6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考1：以上是不是唯一的方法？&lt;/strong&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/7.png&#34; alt=&#34;7&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考2：哪种判定方式更好？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考3：如何更有效的区分？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果某个特征区分问题更有效？&lt;/li&gt;
&lt;li&gt;怎么判断问题更有效？&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2为什么需要决策树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%86%b3%e7%ad%96%e6%a0%91&#34;&gt;
        #
    &lt;/a&gt;
    2.为什么需要决策树
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;此刻你可能会想到：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 寻找关键性问题！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 什么是关键性问题？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 怎么寻找关键性问题？&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;21理论依据是什么&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#21%e7%90%86%e8%ae%ba%e4%be%9d%e6%8d%ae%e6%98%af%e4%bb%80%e4%b9%88&#34;&gt;
        ##
    &lt;/a&gt;
    2.1.理论依据是什么？
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;香农&amp;quot;提出信息论，其中对信息的度量成为香农熵，简称“熵(Entropy)”&lt;/p&gt;
&lt;p&gt;在分类问题中，假设存在类别集合为  $ (X_1, X_2, &amp;hellip; X_n) $ ，将类别 $ X_i $ 的信息定义为:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$ l(X_i) = -log(P(X_i))$ , 其中 $ P(X_i)$为 $X_i $的概率&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;熵：信息的数学期望值： $ H= -\sum_{i=1}^n P(X_i) log(P(X_i))$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;思考4：怎么理解熵？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;信息量越大，熵越小&lt;/li&gt;
&lt;li&gt;信息量越小，熵越大&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/5.png&#34; alt=&#34;5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考5：为什么使用对数表示信息？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;概率 vs 信息&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;概率越大，信息量越小&lt;/li&gt;
&lt;li&gt;概率越小，信息量越大&lt;/li&gt;
&lt;li&gt;多个事件同时发生的概率是多个事件发生概率相乘，总信息量是多个事件信息量相加&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;练习1：给定以下数据集，写出熵的计算方法&lt;/strong&gt;&lt;/p&gt;
$$ H= -\sum_{i=1}^n P(X_i) log(P(X_i)) $$
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;from&lt;/span&gt; math &lt;span style=&#34;color:#ff6ac1&#34;&gt;import&lt;/span&gt; log
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;create_dataset&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;legs&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;flippers&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;beak&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;swim&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Yes&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Yes&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sharp&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;chicken&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sharp&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;chicken&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ff9f43&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Flat&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;duck&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; dataset, features
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;calc_entropy&lt;/span&gt;(dataset):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    count &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    class_counter &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; vector &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataset:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        cls &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; vector[&lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        class_counter[cls] &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; class_counter&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;get(cls, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; key &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; class_counter&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;keys():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;float&lt;/span&gt;(class_counter[key])&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;count
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;-=&lt;/span&gt; prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; log(prob)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; entropy
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset, features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; create_dataset()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; calc_entropy(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Entropy: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(entropy))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Entropy: 1.3208883431493221
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3怎么构建决策树&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#3%e6%80%8e%e4%b9%88%e6%9e%84%e5%bb%ba%e5%86%b3%e7%ad%96%e6%a0%91&#34;&gt;
        #
    &lt;/a&gt;
    3.怎么构建决策树
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;核心问题：如何通过划分数据集计算信息量的提升来找到最有效的数据特征&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;练习2：重新划分数据集，将符合指定特征值的数据提取出来组合新的数据集合&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;split_dataset&lt;/span&gt;(dataset, feature, value):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; data &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataset:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; data[feature] &lt;span style=&#34;color:#ff6ac1&#34;&gt;==&lt;/span&gt; value:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            new_data &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; data[:feature]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            new_data&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;extend(data[feature&lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;:])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            new_dataset&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;append(new_data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; new_dataset
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;小实验1：以下将有脚蹼和没有脚蹼的数据集划分出来&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;feature &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; features&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;index(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;flippers&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;with_flipper_dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; split_dataset(dataset, feature, &lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Dataset with flippers:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(with_flipper_dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Dataset without flippers:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;with_flipper_dataset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; split_dataset(dataset, feature, &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(with_flipper_dataset)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Dataset with flippers:
[[2, &#39;Flat&#39;, &#39;No&#39;, &#39;duck&#39;]]
Dataset without flippers:
[[4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;思考6：怎么表示最好的特征？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;信息增益：通过观察信息熵的变化求得&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#57c7ff&#34;&gt;select_best_feature&lt;/span&gt;(dataset, features):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    feature_count &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(dataset[&lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;])&lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    current_entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; calc_entropy(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    feature_selected &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff6ac1&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    best_entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dataset_size &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sub_datasets &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sub_features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;range&lt;/span&gt;(feature_count):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        feature_values &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff5c57&#34;&gt;set&lt;/span&gt;([vector[i] &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; vector &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; dataset])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        subset_entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ff9f43&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;  Calculating entropy by splitting dataset with feature[&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{0}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;]&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(features[i]))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        subsets &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; value &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; feature_values:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;    Splitting dataset with feature[&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{0}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;]==&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{1}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(features[i], value))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            subset &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; split_dataset(dataset, i, value)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            subsets[value] &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; subset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ff5c57&#34;&gt;len&lt;/span&gt;(subset)&lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1.0&lt;/span&gt;)&lt;span style=&#34;color:#ff6ac1&#34;&gt;/&lt;/span&gt;dataset_size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            subset_entropy &lt;span style=&#34;color:#ff6ac1&#34;&gt;+=&lt;/span&gt; prob &lt;span style=&#34;color:#ff6ac1&#34;&gt;*&lt;/span&gt; calc_entropy(subset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;      Subset:&amp;#39;&lt;/span&gt;, subset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;      Entropy:&amp;#39;&lt;/span&gt;, subset_entropy)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; current_entropy&lt;span style=&#34;color:#ff6ac1&#34;&gt;-&lt;/span&gt;subset_entropy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;    Entropy gain: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(entropy_gain))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ff6ac1&#34;&gt;if&lt;/span&gt; best_entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;&amp;lt;&lt;/span&gt; entropy_gain:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            best_entropy_gain &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; entropy_gain
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            feature_selected &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; i
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            sub_datasets &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; subsets
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            sub_features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; features[:feature_selected]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            sub_features&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;extend(features[feature_selected&lt;span style=&#34;color:#ff6ac1&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ff9f43&#34;&gt;1&lt;/span&gt;:])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff6ac1&#34;&gt;return&lt;/span&gt; feature_selected, sub_datasets, sub_features
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;小实验2：请在数据全集上运行计算出最优数据特征&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;best_feature, sub_datasets, sub_features &lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt; select_best_feature(dataset, features)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Best feature: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;, name: &lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(best_feature, features[best_feature]))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; feature_value &lt;span style=&#34;color:#ff6ac1&#34;&gt;in&lt;/span&gt; sub_datasets&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;keys():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sub dataset with feature[&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;]==&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ff6ac1&#34;&gt;.&lt;/span&gt;format(features[best_feature], feature_value))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(sub_datasets[feature_value])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ff5c57&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#39;Sub features: &amp;#39;&lt;/span&gt;, sub_features)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;  Calculating entropy by splitting dataset with feature[legs]
    Splitting dataset with feature[legs]==2
      Subset: [[0, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [0, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [1, &#39;Flat&#39;, &#39;No&#39;, &#39;duck&#39;]]
      Entropy: 0.2386928131105548
    Splitting dataset with feature[legs]==4
      Subset: [[0, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [0, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [0, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [0, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [0, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;]]
      Entropy: 0.6593251049913401
    Entropy gain: 0.661563238157982
  Calculating entropy by splitting dataset with feature[flippers]
    Splitting dataset with feature[flippers]==0
      Subset: [[4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;No&#39;, &#39;cat&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [4, &#39;No&#39;, &#39;Yes&#39;, &#39;dog&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;], [2, &#39;Sharp&#39;, &#39;No&#39;, &#39;chicken&#39;]]
      Entropy: 0.9441181818928854
    Splitting dataset with feature[flippers]==1
      Subset: [[2, &#39;Flat&#39;, &#39;No&#39;, &#39;duck&#39;]]
      Entropy: 0.9441181818928854
    Entropy gain: 0.3767701612564367
  Calculating entropy by splitting dataset with feature[beak]
    Splitting dataset with feature[beak]==No
      Subset: [[4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;]]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Flat
      Subset: [[2, 1, &#39;No&#39;, &#39;duck&#39;]]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Sharp
      Subset: [[2, 0, &#39;No&#39;, &#39;chicken&#39;], [2, 0, &#39;No&#39;, &#39;chicken&#39;]]
      Entropy: 0.4206322918807853
    Entropy gain: 0.9002560512685368
  Calculating entropy by splitting dataset with feature[swim]
    Splitting dataset with feature[swim]==No
      Subset: [[4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [2, 0, &#39;Sharp&#39;, &#39;chicken&#39;], [2, 0, &#39;Sharp&#39;, &#39;chicken&#39;], [2, 1, &#39;Flat&#39;, &#39;duck&#39;]]
      Entropy: 0.7585531985305136
    Splitting dataset with feature[swim]==Yes
      Subset: [[4, 0, &#39;No&#39;, &#39;dog&#39;], [4, 0, &#39;No&#39;, &#39;dog&#39;]]
      Entropy: 0.7585531985305136
    Entropy gain: 0.5623351446188085
Best feature: 2, name: beak
Sub dataset with feature[beak]==No
[[4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;No&#39;, &#39;cat&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;], [4, 0, &#39;Yes&#39;, &#39;dog&#39;]]
Sub features:  [&#39;legs&#39;, &#39;flippers&#39;, &#39;swim&#39;]
Sub dataset with feature[beak]==Flat
[[2, 1, &#39;No&#39;, &#39;duck&#39;]]
Sub features:  [&#39;legs&#39;, &#39;flippers&#39;, &#39;swim&#39;]
Sub dataset with feature[beak]==Sharp
[[2, 0, &#39;No&#39;, &#39;chicken&#39;], [2, 0, &#39;No&#39;, &#39;chicken&#39;]]
Sub features:  [&#39;legs&#39;, &#39;flippers&#39;, &#39;swim&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;思考7：如果改动数据集会出现什么情况？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;决策树算法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%86%b3%e7%ad%96%e6%a0%91%e7%ae%97%e6%b3%95&#34;&gt;
        #
    &lt;/a&gt;
    决策树算法
&lt;/div&gt;
&lt;/h2&gt;
&lt;h4 id=&#34;算法描述&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0&#34;&gt;
        ###
    &lt;/a&gt;
    算法描述：
&lt;/div&gt;
&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;当前数据集是否是确定的某个类型的数据，如果是则不用再对该数据集进行分类&lt;/li&gt;
&lt;li&gt;在当前数据集上选择最好的特征，通过使用这个特征区分的子数据集拥有最好的信息&lt;/li&gt;
&lt;li&gt;对各子数据集重复进行上述计算&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;伪代码&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%bc%aa%e4%bb%a3%e7%a0%81&#34;&gt;
        ###
    &lt;/a&gt;
    伪代码：
&lt;/div&gt;
&lt;/h4&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Function CreateTree
    IF 数据集不用再分割 THEN return 该数据集类别
    ELSE
        寻找待分类数据的最好特征
        划分子数据集
        创建分支节点
        for 每个划分的子数据集
            branchPoint = CreateTree
        return 分支节点
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;大家动手实现上面的算法，输出一棵树&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;4其他思考&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#4%e5%85%b6%e4%bb%96%e6%80%9d%e8%80%83&#34;&gt;
        ##
    &lt;/a&gt;
    4.其他思考
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;思考8：数据集有什么样的影响？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考9：数据特征有什么样的影响？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# &amp;#39;meow&amp;#39;:0, &amp;#39;wong&amp;#39;:1, &amp;#39;googooda&amp;#39;:2, &amp;#39;ga&amp;#39;:3

def create_dataset():
    features = [&amp;#39;legs&amp;#39;, &amp;#39;flippers&amp;#39;, &amp;#39;voice&amp;#39;]
    dataset = [
        [4, 0, 0, &amp;#39;cat&amp;#39;],
        [4, 0, 0, &amp;#39;cat&amp;#39;],
        [4, 0, 0, &amp;#39;cat&amp;#39;],
        [4, 0, 1, &amp;#39;dog&amp;#39;],
        [4, 0, 1, &amp;#39;dog&amp;#39;],
        [2, 0, 2, &amp;#39;chicken&amp;#39;],
        [2, 0, 2, &amp;#39;chicken&amp;#39;],
        [2, 1, 3, &amp;#39;duck&amp;#39;]
    ]
    return dataset, features
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;物种&lt;/th&gt;
&lt;th&gt;腿的数量&lt;/th&gt;
&lt;th&gt;有没有脚蹼&lt;/th&gt;
&lt;th&gt;叫声&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;猫&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;喵喵&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;狗&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;旺旺&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸡&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;没有&lt;/td&gt;
&lt;td&gt;咯咯哒&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;鸭&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;有&lt;/td&gt;
&lt;td&gt;嘎嘎&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;一种区分方法&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/3.png&#34; alt=&#34;3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考10：有没有其他方法？&lt;/strong&gt;
&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/4.png&#34; alt=&#34;4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考11：如果使用前面的算法会得出什么样的结果呢？&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>模型评估指标</title>
      <link>/2019/03/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</link>
      <pubDate>Thu, 28 Mar 2019 15:49:48 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/03/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</guid>
      <description>&lt;!--toc--&gt;
&lt;!--
精确率

召回率

# AP
## step1

1. 将检测结果按照confidence排序
2. 
--&gt;
&lt;p&gt;关于mAP这篇文章写得不错：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@chih.sheng.huang821/&#34;&gt;https://medium.com/@chih.sheng.huang821/&lt;/a&gt;深度學習系列-什麼是ap-map-aaf089920848&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://www.singleye.net/media/2019/03/TP-TF-FP-FN.jpg&#34; alt=&#34;TP-FP-FN-TN&#34;&gt;&lt;/p&gt;
&lt;p&gt;mAP定义及相关概念mAP: mean Average Precision, 即各类别AP的平均值AP: PR曲线下面积，后文会详细讲解PR曲线: Precision-Recall曲线Precision: TP / (TP + FP)Recall: TP / (TP + FN)TP: IoU&amp;gt;0.5的检测框数量（同一Ground Truth只计算一次）FP: IoU&amp;lt;=0.5的检测框，或者是检测到同一个GT的多余检测框的数量FN: 没有检测到的GT的数量&lt;/p&gt;
&lt;p&gt;mAP计算示例假设，对于Aeroplane类别，我们网络有以下输出(BB表示BoundingBox序号，IoU&amp;gt;0.5时GT=1)：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;BB  | confidence | GT
----------------------
BB1 |  0.9       | 1
----------------------
BB2 |  0.9       | 1
----------------------
BB1 |  0.8       | 1
----------------------
BB3 |  0.7       | 0
----------------------
BB4 |  0.7       | 0
----------------------
BB5 |  0.7       | 1
----------------------
BB6 |  0.7       | 0
----------------------
BB7 |  0.7       | 0
----------------------
BB8 |  0.7       | 1
----------------------
BB9 |  0.7       | 1
----------------------
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;因此，我们有 TP=5 (BB1, BB2, BB5, BB8, BB9), FP=5 (重复检测到的BB1也算FP)。除了表里检测到的5个GT以外，我们还有2个GT没被检测到，因此: FN = 2. 这时我们就可以按照Confidence的顺序给出各处的PR值，如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;rank=1  precision=1.00 and recall=0.14
----------
rank=2  precision=1.00 and recall=0.29
----------
rank=3  precision=0.66 and recall=0.29
----------
rank=4  precision=0.50 and recall=0.29
----------
rank=5  precision=0.40 and recall=0.29
----------
rank=6  precision=0.50 and recall=0.43
----------
rank=7  precision=0.43 and recall=0.43
----------
rank=8  precision=0.38 and recall=0.43
----------
rank=9  precision=0.44 and recall=0.57
----------
rank=10 precision=0.50 and recall=0.71
----------
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;作者：知乎用户
链接：https://www.zhihu.com/question/53405779/answer/419532990
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习资料收集</title>
      <link>/2019/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86/</link>
      <pubDate>Sat, 23 Mar 2019 23:23:28 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86/</guid>
      <description>&lt;!--toc--&gt;
&lt;h1 id=&#34;框架&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%a1%86%e6%9e%b6&#34;&gt;
        ##
    &lt;/a&gt;
    框架
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;tensorflow-models&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#tensorflow-models&#34;&gt;
        #
    &lt;/a&gt;
    Tensorflow models
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;tensorflow官方自带的例子：&lt;a href=&#34;https://github.com/tensorflow/models&#34;&gt;https://github.com/tensorflow/models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;算法模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%ae%97%e6%b3%95%e6%a8%a1%e5%9e%8b&#34;&gt;
        ##
    &lt;/a&gt;
    算法模型
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;cnn&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#cnn&#34;&gt;
        #
    &lt;/a&gt;
    CNN
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs231n.github.io/neural-networks-case-study/#grad&#34;&gt;CS231n Convolutional Neural Networks for Visual Recognition&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lstm&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#lstm&#34;&gt;
        #
    &lt;/a&gt;
    LSTM
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34;&gt;Understanding LSTM Networks by colah&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;数据集&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e9%9b%86&#34;&gt;
        ##
    &lt;/a&gt;
    数据集
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;cv数据集&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#cv%e6%95%b0%e6%8d%ae%e9%9b%86&#34;&gt;
        #
    &lt;/a&gt;
    CV数据集
&lt;/div&gt;
&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;th&gt;Info&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ImageNet&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.image-net.org/about-stats&#34;&gt;http://www.image-net.org/about-stats&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;~1TB，1400多万幅图片，涵盖2万多个类别，超过百万的图片有明确的类别标注和图像中物体位置的标注&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;COCO&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://cocodataset.org/#home&#34;&gt;http://cocodataset.org/#home&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;~40GB，Common Object in Context&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PASCAL VOC&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html&#34;&gt;http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;~2GB PASCAL VOC挑战赛是视觉对象的分类识别和检测的一个基准测试，提供了检测算法和学习性能的标准图像注释数据集和标准的评估系统。PASCAL VOC图片集包括20个目录：人类；动物（鸟、猫、牛、狗、马、羊）；交通工具（飞机、自行车、船、公共汽车、小轿车、摩托车、火车）；室内（瓶子、椅子、餐桌、盆栽植物、沙发、电视）。PASCAL VOC挑战赛在2012年后便不再举办，但其数据集图像质量好，标注完备，非常适合用来测试算法性能。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CIFAR&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.cs.toronto.edu/~kriz/cifar.html&#34;&gt;http://www.cs.toronto.edu/~kriz/cifar.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;~170MB CIFAR-10包含10个类别，50,000个训练图像，彩色图像大小：32x32，10,000个测试图像。CIFAR-100与CIFAR-10类似，包含100个类，每类有600张图片，其中500张用于训练，100张用于测试；这100个类分组成20个超类。图像类别均有明确标注。CIFAR对于图像分类算法测试来说是一个非常不错的中小规模数据集。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Open Image&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/openimages/dataset&#34;&gt;https://github.com/openimages/dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;~1.5GB（不包括图片） ，~900万张图像URL的数据集，里面的图片通过标签注释被分为6000多类。该数据集中的标签要比ImageNet（1000类）包含更真实生活的实体存在&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Youtube-8M&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://research.google.com/youtube8m/&#34;&gt;https://research.google.com/youtube8m/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;~1.5TB，来自youtube，共计8百万个视频，总时长50万小时，4800类。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;深度学习数据集收集网站&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://deeplearning.net/datasets/&#34;&gt;http://deeplearning.net/datasets/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tiny Images Dataset&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://horatio.cs.nyu.edu/mit/tiny/data/index.html&#34;&gt;http://horatio.cs.nyu.edu/mit/tiny/data/index.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;8000万的32x32图像，CIFAR-10和CIFAR-100便是从中挑选的。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CoPhIR&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://cophir.isti.cnr.it/whatis.html&#34;&gt;http://cophir.isti.cnr.it/whatis.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;雅虎发布的超大Flickr数据集，包含1亿多张图片。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MirFlickr1M&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://press.liacs.nl/mirflickr/&#34;&gt;http://press.liacs.nl/mirflickr/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Flickr数据集中挑选出的100万图像集。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SBU captioned photo dataset&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://dsl1.cewit.stonybrook.edu/~vicente/sbucaptions/&#34;&gt;http://dsl1.cewit.stonybrook.edu/~vicente/sbucaptions/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Flickr的一个子集，包含100万的图像集。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NUS-WIDE&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm&#34;&gt;http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Flickr中的27万的图像集。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Large-Scale Image Annotation using Visual Synset(ICCV 2011)&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://cpl.cc.gatech.edu/projects/VisualSynset/&#34;&gt;http://cpl.cc.gatech.edu/projects/VisualSynset/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;机器标注的一个超大规模数据集，包含2亿图像。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SUN dataset&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://people.csail.mit.edu/jxiao/SUN/&#34;&gt;http://people.csail.mit.edu/jxiao/SUN/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;包含13万的图像的数据集。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MSRA-MM&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://research.microsoft.com/en-us/projects/msrammdata/&#34;&gt;http://research.microsoft.com/en-us/projects/msrammdata/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;包含100万的图像，23000视频；微软亚洲研究院出品，质量应该有保障。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LSUN：用于场景理解和多任务辅助（房间布局估计，显着性预测等）&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://lsun.cs.princeton.edu/2016/&#34;&gt;http://lsun.cs.princeton.edu/2016/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Caltech行人检测数据库&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/&#34;&gt;http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UMDFaces 人脸数据库&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.umdfaces.io/&#34;&gt;http://www.umdfaces.io/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;一共8000+个类别，总共36W张人脸图片，标注数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;李子青组的 CASIA-WebFace(50万，1万个人)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;需申请&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MegaFace&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;华盛顿大学百万人脸MegaFace数据集，60G，邮件申请&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;南洋理工 WLFDB （Weakly Labeled Faces Database ）&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;70万+,6,025&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;微软的MSRA-CFW&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;202792 张, 1583人&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;汤晓欧实验室的CelebA&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;20万+，标注，Large-scale CelebFaces Attributes (CelebA) Dataset&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FaceScrub&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;100,100张，530人&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;搜狗实验室数据集&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;包括人物、动物、建筑、机械、风景、运动等类别，总数高达2,836,535张图片&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;标注工具&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%a0%87%e6%b3%a8%e5%b7%a5%e5%85%b7&#34;&gt;
        ##
    &lt;/a&gt;
    标注工具
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;nlp-标注工具&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#nlp-%e6%a0%87%e6%b3%a8%e5%b7%a5%e5%85%b7&#34;&gt;
        #
    &lt;/a&gt;
    NLP 标注工具
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;| 工具 | 链接 |
|&amp;mdash;+&amp;mdash;|
| BRAT | |&lt;/p&gt;
&lt;h2 id=&#34;图像标注工具&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%9b%be%e5%83%8f%e6%a0%87%e6%b3%a8%e5%b7%a5%e5%85%b7&#34;&gt;
        #
    &lt;/a&gt;
    图像标注工具
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;| 工具 | 链接 | 描述 |
|&amp;mdash;+&amp;mdash;+&amp;mdash;|
| labelImg | &lt;a href=&#34;https://github.com/tzutalin/labelImg&#34;&gt;https://github.com/tzutalin/labelImg&lt;/a&gt; | |
| BBox-Label-Tool || |
| Yolo_mark | &lt;a href=&#34;https://github.com/AlexeyAB/Yolo_mark&#34;&gt;https://github.com/AlexeyAB/Yolo_mark&lt;/a&gt; | YOLO v2 标注工具|&lt;/p&gt;
&lt;h2 id=&#34;视频标注工具&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e8%a7%86%e9%a2%91%e6%a0%87%e6%b3%a8%e5%b7%a5%e5%85%b7&#34;&gt;
        #
    &lt;/a&gt;
    视频标注工具
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;| 工具 | 链接 |
|&amp;mdash;+&amp;mdash;|
| vatic | &lt;a href=&#34;http://web.mit.edu/vondrick/vatic/&#34;&gt;http://web.mit.edu/vondrick/vatic/&lt;/a&gt; |
| CDVA（compact descriptor for video analysis）||&lt;/p&gt;
&lt;h1 id=&#34;论文&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e8%ae%ba%e6%96%87&#34;&gt;
        ##
    &lt;/a&gt;
    论文
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;cv&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#cv&#34;&gt;
        #
    &lt;/a&gt;
    CV
&lt;/div&gt;
&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Title&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;th&gt;Info&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Speed/accuracy trade-offs for modern convolutional object detectors&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1611.10012.pdf&#34;&gt;https://arxiv.org/pdf/1611.10012.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;nlp&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#nlp&#34;&gt;
        #
    &lt;/a&gt;
    NLP
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.singleye.net/2019/09/nlp-%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86/&#34;&gt;NLP相关资源&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;书籍&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%b9%a6%e7%b1%8d&#34;&gt;
        ##
    &lt;/a&gt;
    书籍
&lt;/div&gt;
&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Title&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;th&gt;Info&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Interpretable machine learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/intro.html&#34;&gt;https://christophm.github.io/interpretable-ml-book/intro.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;学习资料&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%96%99&#34;&gt;
        ##
    &lt;/a&gt;
    学习资料
&lt;/div&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;MIT 经典教程 Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/9bb0bd8597a0&#34;&gt;新手 Python-机器学习 四部曲资源汇总&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Avik-Jain/100-Days-Of-ML-Code&#34;&gt;100-Days-Of-ML-Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Build Tensorflow v1.7 on NVIDIA Jetson tx2</title>
      <link>/2018/04/build-tensorflow-v1.7-on-nvidia-jetson-tx2/</link>
      <pubDate>Thu, 12 Apr 2018 11:06:51 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2018/04/build-tensorflow-v1.7-on-nvidia-jetson-tx2/</guid>
      <description>&lt;!--toc--&gt;
&lt;h1 id=&#34;how-to-install-tensorflow-v17-on-nvidia-jetson-tx2&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#how-to-install-tensorflow-v17-on-nvidia-jetson-tx2&#34;&gt;
        ##
    &lt;/a&gt;
    How to install tensorflow v1.7 on NVIDIA Jetson TX2
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;Tensorflow is a popular machine learning platform and the latest version 1.7 comes out recently. I have a NVIDIA Jetson TX2 development board and I would like to use tensorflow on it, but tensorflow doesn&amp;rsquo;t come along with the Jetpack. Here is what I did to compile one from the source code.&lt;/p&gt;
&lt;h2 id=&#34;environment&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#environment&#34;&gt;
        #
    &lt;/a&gt;
    Environment
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Platform: NVIDIA Jetson TX2&lt;/li&gt;
&lt;li&gt;Jetpack: v3.2&lt;/li&gt;
&lt;li&gt;CUDA: 9.0&lt;/li&gt;
&lt;li&gt;cuDNN: 7.0&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;build-process&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#build-process&#34;&gt;
        #
    &lt;/a&gt;
    Build process
&lt;/div&gt;
&lt;/h2&gt;
&lt;h3 id=&#34;step1-upgrade-jetpack&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#step1-upgrade-jetpack&#34;&gt;
        ##
    &lt;/a&gt;
    Step1: Upgrade Jetpack
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;$ sudo apt-get upgrade&lt;/p&gt;
&lt;h3 id=&#34;step2-compile-bazelhttpsgithubcombazelbuildbazel&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#step2-compile-bazelhttpsgithubcombazelbuildbazel&#34;&gt;
        ##
    &lt;/a&gt;
    Step2: Compile &lt;a href=&#34;https://github.com/bazelbuild/bazel&#34;&gt;bazel&lt;/a&gt;
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;I tried 2 ways to build bazel and realized it&amp;rsquo;s far more easier to build the &amp;lsquo;dist&amp;rsquo; version.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build Bazel&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;On environment not bootstraping with protoc/grpc installed, use the &amp;lsquo;dist&amp;rsquo; distribution.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://github.com/bazelbuild/bazel/releases/download/0.11.1/bazel-0.11.1-dist.zip
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Decompress the source and enter the source root directory, then run the commands below to build bazel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./compile.sh
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp output/bazel /usr/local/bin/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;More words about the non-dist version:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you would like to try build from the non-dist version of source code, you can download it from here:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://github.com/bazelbuild/bazel/archive/0.11.1.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Building it depends on a bunch of stuffs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/google/protobuf&#34;&gt;protobuf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://netty.io/wiki/forked-tomcat-native.html#wiki-h2-5&#34;&gt;netty-tcnative&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/grpc/grpc-java/blob/master/COMPILING.md&#34;&gt;grpc-java&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step3-build-tensorflow&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#step3-build-tensorflow&#34;&gt;
        ##
    &lt;/a&gt;
    Step3: Build tensorflow
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Install python 2.7 dependencies:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ sudo apt-get install python-numpy python-dev python-pip python-wheel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Install python 3.x dependencies:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Download source:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget https://github.com/tensorflow/tensorflow/archive/v1.7.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Pre-build configure, here are the settings need to set manually:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Disable Amazon S3 File System support (I have issue of &amp;ldquo;undefined symbol: _ZN3Aws11Environment6GetEnvB5cxx11EPKc&amp;rdquo; while importing tensorflow)&lt;/li&gt;
&lt;li&gt;Enable &amp;lsquo;CUDA&amp;rsquo; support&lt;/li&gt;
&lt;li&gt;cuDNN library path: /usr/lib/aarch64-linux-gnu&lt;/li&gt;
&lt;li&gt;Enable &amp;lsquo;TensorRT&amp;rsquo; and set library path: /usr/lib/aarch64-linux-gnu&lt;/li&gt;
&lt;li&gt;CUDA compute capability: 6.2&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./configure
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;You have bazel 0.11.1- &lt;span style=&#34;color:#ff6ac1&#34;&gt;(&lt;/span&gt;@non-git&lt;span style=&#34;color:#ff6ac1&#34;&gt;)&lt;/span&gt; installed.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the location of python. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Default is /usr/bin/python&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Found possible Python library paths:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  /usr/local/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  /usr/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please input the desired Python library path to use.  Default is &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;/usr/local/lib/python2.7/dist-packages&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with jemalloc as malloc support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Y/n&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;jemalloc as malloc support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with Google Cloud Platform support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Y/n&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Google Cloud Platform support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with Hadoop File System support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Y/n&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Hadoop File System support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with Amazon S3 File System support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Y/n&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;: n
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No Amazon S3 File System support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with Apache Kafka Platform support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No Apache Kafka Platform support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with XLA JIT support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No XLA JIT support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with GDR support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No GDR support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with VERBS support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No VERBS support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with OpenCL SYCL support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No OpenCL SYCL support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with CUDA support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;: y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CUDA support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the CUDA SDK version you want to use, e.g. 7.0. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Leave empty to default to CUDA 9.0&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the location where CUDA 9.0 toolkit is installed. Refer to README.md &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; more details. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Default is /usr/local/cuda&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the cuDNN version you want to use. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Leave empty to default to cuDNN 7.0&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the location where cuDNN &lt;span style=&#34;color:#ff9f43&#34;&gt;7&lt;/span&gt; library is installed. Refer to README.md &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; more details. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Default is /usr/local/cuda&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:/usr/lib/aarch64-linux-gnu/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with TensorRT support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;: y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TensorRT support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the location where TensorRT is installed. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Default is /usr/lib/x86_64-linux-gnu&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:/usr/lib/aarch64-linux-gnu/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify a list of comma-separated Cuda compute capabilities you want to build with.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please note that each additional compute capability significantly increases your build &lt;span style=&#34;color:#ff5c57&#34;&gt;time&lt;/span&gt; and binary size. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Default is: 3.5,5.2&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;6.2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you want to use clang as CUDA compiler? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nvcc will be used as CUDA compiler.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify which gcc should be used by nvcc as the host compiler. &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Default is /usr/bin/gcc&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Do you wish to build TensorFlow with MPI support? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No MPI support will be enabled &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; TensorFlow.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify optimization flags to use during compilation when bazel option &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;--config=opt&amp;#34;&lt;/span&gt; is specified &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;Default is -march&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;native&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Would you like to interactively configure ./WORKSPACE &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; Android builds? &lt;span style=&#34;color:#ff6ac1&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#ff6ac1&#34;&gt;]&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Not configuring the WORKSPACE &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; Android builds.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Preconfigured Bazel build configs. You can use any of the below by adding &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;--config=&amp;lt;&amp;gt;&amp;#34;&lt;/span&gt; to your build command. See tools/bazel.rc &lt;span style=&#34;color:#ff6ac1&#34;&gt;for&lt;/span&gt; more details.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        --config&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;mkl            &lt;span style=&#34;color:#78787e&#34;&gt;# Build with MKL support.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        --config&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;monolithic     &lt;span style=&#34;color:#78787e&#34;&gt;# Config for mostly static monolithic build.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Configuration finished
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Apply patch &lt;a href=&#34;https://github.com/singleye/KnowledgeBase/blob/master/Tensorflow/Jetpack3.2/tensorrt.patch&#34;&gt;Jetpack3.2/tensorrt.patch&lt;/a&gt; if you want TensorRT support.&lt;/p&gt;
&lt;p&gt;Start the build:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ bazel build --config&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;opt --local_resources 3072,4.0,1.0 --config&lt;span style=&#34;color:#ff6ac1&#34;&gt;=&lt;/span&gt;cuda //tensorflow/tools/pip_package:build_pip_package
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After compilation, generate pip package to &amp;rsquo;target&amp;rsquo; directory:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package target
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;easy-usage&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#easy-usage&#34;&gt;
        ##
    &lt;/a&gt;
    Easy usage
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;ve build out the pip &lt;a href=&#34;https://pan.baidu.com/s/1ORp_FCb-ZR-ZAZoGd8CuRw&#34;&gt;package&lt;/a&gt;, feel free to use it to save some time ;-)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>softmax输出层公式推导及代码实验</title>
      <link>/2017/10/softmax%E8%BE%93%E5%87%BA%E5%B1%82%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E9%AA%8C/</link>
      <pubDate>Mon, 02 Oct 2017 02:11:00 +0000</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/10/softmax%E8%BE%93%E5%87%BA%E5%B1%82%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E9%AA%8C/</guid>
      <description>&lt;!-- more /--&gt;
&lt;p&gt;sigmoid激活函数在神经网络中有着强大的通用性，但也存在这一些问题，比如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在w/b参数还没有训练成熟时，训练预测偏差较大，此时的训练速度会较慢。这个问题的解决方法有两种：
&lt;ul&gt;
&lt;li&gt;使用交叉熵代价函数: $ C = -{1\over n} \sum_{i=1}^n [y_i \ln a_i + (1-y_i) \ln (1-a_i)] $&lt;/li&gt;
&lt;li&gt;使用softmax和log-likelyhood代价函数作为输出层&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;sigmoid的输出结果是伯努利分布 $ P(y_1|X), P(y_2|X), &amp;hellip; P(y_n|X) $，说明每一个输出项之间是相互独立的，这在预测一种输出结果的情形时不太符合人们的直观感受。这个问题也可以用softmax输出层解决，因为softmax的输出是多项分布：$ P(y_1, y_2, &amp;hellip; y_n | X) $，其中y1, &amp;hellip; yn之间相互关联，且总和为1。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样看起来softmax是个很有效的方法，下面就对这个方法进行一些研究。&lt;/p&gt;
&lt;h1 id=&#34;softmax定义&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#softmax%e5%ae%9a%e4%b9%89&#34;&gt;
        ##
    &lt;/a&gt;
    softmax定义：
&lt;/div&gt;
&lt;/h1&gt;
&lt;div&gt;
$$ softmax(z_j) = {e^{z_j} \over {\sum_{i=1}^m e^{z_i} }} , j=1, ... m $$
&lt;/div&gt;
&lt;p&gt;将softmax层应用在网络输出层时，每一个神经元的softmax激活输出可以理解为该神经元对应结果的预测概率，这里有几个基本事实：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个神经元的输出为正数，并且输出数值介于0-1之间。&lt;/li&gt;
&lt;li&gt;所有神经元的输出总和为1。&lt;/li&gt;
&lt;li&gt;某一项输入（Z值）增大时，其对应的输出概率增大；同时其他输出概率同时减小（总和总是1）。该结论可以从$ \frac {\partial a_i} {\partial {z_i}} $（总为正数）以及$ \frac {\partial a_i} {\partial {z_j}}$（总为负数）推算出来，这两个数字也说明了softmax的输入／输出单调性。&lt;/li&gt;
&lt;li&gt;softmax的每个激活输出值之间相互关联，表现出了输出非局部性特征。直观的理解就是因为所有激活输出的总和总是为1，那么其中一个激活输出的值发生变动的时候其他的激活输出也必将变化。这一点也是跟sigmoid激活函数的很不同的一点，也说明了$ \frac {\partial a_i} {\partial {z_j}}$值存在的意义。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图展示了softmax层工作的基本原理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/softmax/how_softmax_works.png?x-oss-process=style/png2jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;应用场景&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af&#34;&gt;
        ##
    &lt;/a&gt;
    应用场景：
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;从softmax的定义知道所有输出神经元的总和为1，因此softmax可以用在预测在多种可能性中只有一个结果的场景，比如mnist手写判定。&lt;/p&gt;
&lt;h1 id=&#34;softmax输出层组成的神经网络&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#softmax%e8%be%93%e5%87%ba%e5%b1%82%e7%bb%84%e6%88%90%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c&#34;&gt;
        ##
    &lt;/a&gt;
    softmax输出层组成的神经网络
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;下面的图展示了一个简单的softmax输出层神经网络，中间层依然使用sigmoid。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/softmax/softmax-network.jpg&#34; alt=&#34;softmax NN&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;代价函数c&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%bb%a3%e4%bb%b7%e5%87%bd%e6%95%b0c&#34;&gt;
        #
    &lt;/a&gt;
    代价函数C
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;为了解决在学习过程中出现的速度问题使用log-likelihood代价函数，函数定义为：&lt;/p&gt;
$$ C=-\sum_i^m y_i \ln a_i $$
&lt;p&gt;关于实际应用这个等式需要解释一下。假设softmax输出层有4个输出，预测a值为(0.1, 0.2, 0.3, 0.4)，实际结果y为(0, 1, 0, 0)，那么这个等式为 $C = -(0\ln(0.1) + 1\ln(0.2) + 0\ln(0.3) + 0\ln(0.4))$，可以看出来因为0的存在可以让这个等式只保留实际结果为真（1）的项。这时可以把等式简化为：&lt;/p&gt;
$$ C=-\ln a_i | y_i=1 $$
&lt;h2 id=&#34;用反向传播进行梯度下降&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%94%a8%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e8%bf%9b%e8%a1%8c%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d&#34;&gt;
        #
    &lt;/a&gt;
    用反向传播进行梯度下降
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;反向传播算法要求几个关键值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ \delta_i^L $&lt;/li&gt;
&lt;li&gt;$ \frac {\partial C}{\partial w_{ij}^L} $&lt;/li&gt;
&lt;li&gt;$ \frac {\partial C}{\partial b_{i}^L} $&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果输出层使用softmax时，最后一层（L层）的相应值与使用sigmoid的情况有些不同，下面对使用softmax是的这3个值进行推导。&lt;/p&gt;
&lt;h3 id=&#34;求解-delta_il--a_il---y_i-&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%b1%82%e8%a7%a3-delta_il--a_il---y_i-&#34;&gt;
        ##
    &lt;/a&gt;
    求解$ \delta_i^L = ({a_i^L} - y_i) $
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;过程如下：&lt;/p&gt;
&lt;div&gt;
$$ {\delta_i^L} = {\frac {\partial C}{\partial z_{i}^L}} = {\frac {\partial }{\partial z_{i}^L}} (-\sum_k^m y_k \ln {a_k^L})$$
$$ {\frac {\partial C}{\partial z_{i}^L}} = -(\sum_k^m y_k {1 \over {a_k^L}} {\frac {\partial {a_k^L}}{\partial z_{i}^L}})$$
$$ {\frac {\partial C}{\partial z_{i}^L}} = -(y_i {1 \over a_i^L} \frac {\partial a_i^L}{\partial z_{i}^L} + \sum_{k \neq i}^m y_k {1 \over a_k^L} {\frac {\partial a_k^L}{\partial z_{i}^L}})$$
$$ {\frac {\partial C}{\partial z_{i}^L}} = - (y_i {1 \over a_i^L} {a_i^L(1-a_i^L)} + \sum_{k \neq i}^m y_k {1 \over a_k^L} (-{a_i^L}{a_k^L}) )$$
$$ {\frac {\partial C}{\partial z_{i}^L}} = - (y_i (1-a_i^L) - \sum_{k \neq i}^m y_k {a_i^L})$$
$$ {\frac {\partial C}{\partial z_{i}^L}} = - (y_i - {y_i a_i^L} - \sum_{k \neq i}^m y_k {a_i^L})$$
$$ {\frac {\partial C}{\partial z_{i}^L}} = - (y_i - {a_i^L}{\sum_{k=1}^m y_k})$$
$$ {\frac {\partial C}{\partial z_{i}^L}} = ({a_i^L} - y_i)$$
&lt;/div&gt;
&lt;h3 id=&#34;求-frac-partial-cpartial-w_ijl--a_il-y_ia_jl-1-的过程&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%b1%82-frac-partial-cpartial-w_ijl--a_il-y_ia_jl-1-%e7%9a%84%e8%bf%87%e7%a8%8b&#34;&gt;
        ##
    &lt;/a&gt;
    求$ \frac {\partial C}{\partial w_{ij}^L} = ({a_i^L}-{y_i}){a_j^{L-1}} $的过程：
&lt;/div&gt;
&lt;/h3&gt;
&lt;div&gt;
$$ \frac {\partial C}{\partial w_{ij}^L} = {\frac {\partial C}{\partial z_{i}^L}} {\frac {\partial z_{i}^L}{\partial w_{ij}^L}}$$
$$ \frac {\partial C}{\partial w_{ij}^L} = {\delta_i^L} {a_j^{L-1}}$$
$$ \frac {\partial C}{\partial w_{ij}^L} = ({a_i^L}-{y_i}){a_j^{L-1}}$$
&lt;/div&gt;
&lt;h3 id=&#34;求-frac-partial-cpartial-b_il--a_il---y_i-的过程&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%b1%82-frac-partial-cpartial-b_il--a_il---y_i-%e7%9a%84%e8%bf%87%e7%a8%8b&#34;&gt;
        ##
    &lt;/a&gt;
    求$ \frac {\partial C}{\partial b_{i}^L} = ({a_i^L} - y_i) $的过程：
&lt;/div&gt;
&lt;/h3&gt;
&lt;div&gt;
$$ \frac {\partial C}{\partial b_{i}^L} = {\frac {\partial C}{\partial z_{i}^L}} {\frac {\partial z_{i}^L}{\partial b_{i}^L}}$$
$$ \frac {\partial C}{\partial b_{i}^L} = {\frac {\partial C}{\partial z_{i}^L}} $$
$$ \frac {\partial C}{\partial b_{i}^L} = {\delta_i^L} = ({a_i^L} - y_i) $$
&lt;/div&gt;
&lt;p&gt;以上求解过程中用了两个重要的计算等式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ \frac {\partial a_i} {\partial {z_i}} = a_i \cdot (1- a_i) $&lt;/li&gt;
&lt;li&gt;$ \frac {\partial a_j} {\partial {z_i}} = -{a_i \cdot a_j} | i \neq j$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面对这两个等式进行推导：&lt;/p&gt;
&lt;h4 id=&#34;求导情况1--frac-partial-a_i-partial-z_i--a_i-cdot-1--a_i-&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%b1%82%e5%af%bc%e6%83%85%e5%86%b51--frac-partial-a_i-partial-z_i--a_i-cdot-1--a_i-&#34;&gt;
        ###
    &lt;/a&gt;
    求导情况1: $ \frac {\partial a_i} {\partial {z_i}} = a_i \cdot (1- a_i) $
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/softmax/v2-acaf14aac554ab61ff6f32845fd5128e_b.png&#34; alt=&#34;i==j&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结论：&lt;/li&gt;
&lt;/ul&gt;
$$ \frac {\partial a_i} {\partial {z_i}} = a_i \cdot (1- a_i) $$
&lt;ul&gt;
&lt;li&gt;推导过程：&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$ \frac {\partial a_i} {\partial {z_i}} = \frac {\partial}{\partial {z_i}} ({e^{z_i} \over {\sum_{k=1}^m e^{z_k} }}) $$
$$ = \frac {\partial}{\partial {z_i}} (e^{z_i}) \cdot {1 \over {\sum_{k=1}^m e^{z_k} }} + \frac {\partial}{\partial {z_i}} ({1 \over {\sum_{k=1}^m e^{z_k} }}) \cdot {e^{z_i}}$$
$$ = {e^{z_i} \over {\sum_{k=1}^m e^{z_k} }} + (-1) \cdot {1 \over ({\sum_{k=1}^m e^{z_k} })^2} \cdot {\frac {\partial}{\partial z_i}({\sum_{k=1}^m e^{z_k} })} \cdot {e^{z_i}}$$
$$ = {e^{z_i} \over {\sum_{k=1}^m e^{z_k} }} + (-1) \cdot {1 \over ({\sum_{k=1}^m e^{z_k} })^2} \cdot (0+1){\frac {\partial}{\partial z_i}({e^{z_i}})} \cdot {e^{z_i}}$$
$$ = {e^{z_i} \over {\sum_{k=1}^m e^{z_k} }} + (-1) \cdot ({e^{z_i} \over {\sum_{k=1}^m e^{z_k} }})^2$$
$$ = a_i - (a_i)^2 $$
$$ = a_i \cdot (1- a_i) $$
&lt;/div&gt;
&lt;h4 id=&#34;求导情况2--frac-partial-a_j-partial-z_i---a_i-cdot-a_j&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%b1%82%e5%af%bc%e6%83%85%e5%86%b52--frac-partial-a_j-partial-z_i---a_i-cdot-a_j&#34;&gt;
        ###
    &lt;/a&gt;
    求导情况2: $ \frac {\partial a_j} {\partial {z_i}} = -a_i \cdot a_j$
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/softmax/v2-f09fb0c50194f6cc0828fc285eb9bc1c_b.png&#34; alt=&#34;i neq j&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结论：&lt;/li&gt;
&lt;/ul&gt;
$$ \frac {\partial a_j} {\partial {z_i}} = -a_i \cdot a_j$$
&lt;ul&gt;
&lt;li&gt;推导过程：&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$ \frac {\partial a_j} {\partial {z_i}} = \frac {\partial}{\partial {z_i}} ({e^{z_j} \over {\sum_{k=1}^m e^{z_k} }}) $$
$$ = \frac {\partial}{\partial {z_i}} (e^{z_j}) \cdot {1 \over {\sum_{k=1}^m e^{z_k} }} + \frac {\partial}{\partial {z_i}} ({1 \over {\sum_{k=1}^m e^{z_k} }}) \cdot {e^{z_j}}$$
$$ = 0 \cdot {1 \over {\sum_{k=1}^m e^{z_k} }} + (-1) \cdot {1 \over ({\sum_{k=1}^m e^{z_k} })^2} \cdot {\frac {\partial}{\partial z_i}({\sum_{k=1}^m e^{z_k} })} \cdot {e^{z_j}}$$
$$ = (-1) \cdot {1 \over ({\sum_{k=1}^m e^{z_k} })^2} \cdot (0+1) \cdot \frac {\partial}{\partial z_i}e^{z_i} \cdot {e^{z_j}}$$
$$ = (-1) \cdot {1 \over ({\sum_{k=1}^m e^{z_k} })^2} \cdot e^{z_i} \cdot {e^{z_j}}$$
$$ = - {e^{z_i} \over {\sum_{k=1}^m e^{z_k}}} \cdot {{e^{z_j}} \over {\sum_{k=1}^m e^{z_k}}}$$
$$ = -a_i \cdot a_j$$
&lt;/div&gt;
&lt;h2 id=&#34;sigmoid隐藏层与softmax输出层网络&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#sigmoid%e9%9a%90%e8%97%8f%e5%b1%82%e4%b8%8esoftmax%e8%be%93%e5%87%ba%e5%b1%82%e7%bd%91%e7%bb%9c&#34;&gt;
        #
    &lt;/a&gt;
    sigmoid隐藏层与softmax输出层网络
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;按照下图的拓扑构成的网络使用sigmoid进行隐藏层计算，使用softmax进行输出层计算，那么怎么进行网络训练呢？其实方法一样都是按照前馈网络计算代价值进行评估，使用反向传播算法进行梯度下降。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/softmax/softmax-network.jpg&#34; alt=&#34;softmax NN&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;前馈网络计算步骤&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%89%8d%e9%a6%88%e7%bd%91%e7%bb%9c%e8%ae%a1%e7%ae%97%e6%ad%a5%e9%aa%a4&#34;&gt;
        ##
    &lt;/a&gt;
    前馈网络计算步骤：
&lt;/div&gt;
&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;在隐藏层的计算时使用sigmoid&lt;/li&gt;
&lt;li&gt;在最后输出层使用softmax&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;反向传播计算步骤&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e8%ae%a1%e7%ae%97%e6%ad%a5%e9%aa%a4&#34;&gt;
        ##
    &lt;/a&gt;
    反向传播计算步骤：
&lt;/div&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;计算输出层，计算最后一层softmax输出层的下列值：&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$ \delta_i^L = ({a_i^L} - y_i) $$
$$ \frac {\partial C}{\partial w_{ij}^L} = ({a_i^L}-{y_i}){a_j^{L-1}} = \delta_i^L \cdot a_j^{L-1} $$
$$ \frac {\partial C}{\partial b_{i}^L} = ({a_i^L} - y_i) =\delta_i^L $$
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;计算隐藏层，反向一层一层计算sigmoid隐藏层的下列值：&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$ \delta_j^{l-1} = (\sum_{k=1}^m {\delta_k^l \cdot w_{kj}}) \cdot { a_j^{l-1} (1 - a_j^{l-1}) } $$
$$ \frac {\partial C}{\partial w_{ij}^l} = \delta_i^{l} \cdot a_j^{l-1} $$
$$ \frac {\partial C}{\partial b_{i}^l} = \delta_i^{l} $$
&lt;/div&gt;
&lt;p&gt;计算过程中可以发现只有最后一层的$ \delta_i^L$计算较为特殊，计算权重和偏置的方法与之前的sigmoid构成的网络一致。&lt;/p&gt;
&lt;h1 id=&#34;代码实例&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%bb%a3%e7%a0%81%e5%ae%9e%e4%be%8b&#34;&gt;
        ##
    &lt;/a&gt;
    代码实例
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;下面的例子实验一个输入层有4个输入，隐藏层有5个神经元并且使用sigmoid激活函数，输出层有2个神经元并使用softmax激活函数的网络，拓扑如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/softmax/experiment-softmax.jpg&#34; alt=&#34;拓扑&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# construct the network

# input layer: 4 inputs
# hidden layer: 5 neurons with sigmoid as activate function
# * weight: 4x5 matrices
# * bias: 1x5 matrices
# output layer: 2 neurons with softmax as activate function
# * weight: 5x2 matrices
# * bias: 1x2 matrices

# initialize the weight/bias of the hidden layer (2nd layer)
w2 = np.random.rand(4, 5)
b2 = np.random.rand(1, 5)

# initialize the weight/bias of the output layer (3rd layer) 
w3 = np.random.rand(5, 2)
b3 = np.random.rand(1, 2)
num_epochs = 10000
eta = 0.1

x=[]
y=[]

# training process
for i in xrange(num_epochs):
    # feed forward
    z2 = np.dot(input, w2) + b2
    a2 = sigmoid(z2)

    z3 = np.dot(a2, w3) + b3
    #z3 = np.dot(a2, w3)
    a3 = softmax(z3)
    
    if i%1000 == 0:
        print &amp;quot;Perception&amp;quot;, a3
        print &amp;quot;W2&amp;quot;, w2
        print &amp;quot;B2&amp;quot;, b2
        print &amp;quot;W3&amp;quot;, w3
        print &amp;quot;B3&amp;quot;, b3

    x.append(i)
    y.append(cost(a3, output))

    delta_l3 = a3 - output
    deriv_w3 = np.dot(a2.T, delta_l3)
    deriv_b3 = delta_l3
    w3 -= eta*deriv_w3
    b3 -= eta*np.mean(deriv_b3, 0)
    
    delta_l2 = np.dot(delta_l3, w3.T)*(a2*(1-a2))
    deriv_w2 = np.dot(input.T, delta_l2)
    deriv_b2 = delta_l2
    w2 -= eta*deriv_w2
    b2 -= eta*np.mean(deriv_b2, 0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/softmax/softmax-cost.png&#34; alt=&#34;训练代价&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/singleye/MachineLearning/blob/master/NeuralNetwork/Softmax/experiment-softmax.ipynb&#34;&gt;完整代码&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;
        ##
    &lt;/a&gt;
    参考
&lt;/div&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://neuralnetworksanddeeplearning.com/chap3.html#softmax&#34;&gt;http://neuralnetworksanddeeplearning.com/chap3.html#softmax&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25723112&#34;&gt;https://zhuanlan.zhihu.com/p/25723112&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://colah.github.io/posts/2015-09-Visual-Information/&#34;&gt;http://colah.github.io/posts/2015-09-Visual-Information/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>神经网络之反向传播算法</title>
      <link>/2017/09/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 25 Sep 2017 15:44:00 +0000</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/09/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/</guid>
      <description>&lt;!-- more /--&gt;
&lt;p&gt;之前使用神经网络算法的时候并没有认真总结关键的算法，虽然可以用但总觉得不爽，于是这两天对神经网络算法中的反向传播（Back Propagation）进行了推导。即理解了算法的数学本质，也对神经网络算法的工程特性有了深刻体会，工程算法真的是以解决问题为驱动的，追求的是解决问题的实用性。&lt;/p&gt;
&lt;h1 id=&#34;神经网络&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c&#34;&gt;
        ##
    &lt;/a&gt;
    神经网络
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;网络拓扑&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%bd%91%e7%bb%9c%e6%8b%93%e6%89%91&#34;&gt;
        #
    &lt;/a&gt;
    网络拓扑
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neural-network.jpg&#34; alt=&#34;神经网络&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;神经元&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%a5%9e%e7%bb%8f%e5%85%83&#34;&gt;
        #
    &lt;/a&gt;
    神经元
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;神经元是神经网络的基本构成，上图的每一个圆圈代表了一个神经元。每一个神经元有一个输入和一个输出，神经元的作用是对输入值进行计算。下图是一个神经元的简单示意图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron.jpg&#34; alt=&#34;神经元&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该神经元的输出：$ a=f(z)=sigmoid(z) $&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;神经元输入&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%a5%9e%e7%bb%8f%e5%85%83%e8%be%93%e5%85%a5&#34;&gt;
        ##
    &lt;/a&gt;
    神经元输入
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;在一个复杂点的神经网络中，一个神经元接收来自多个前级神经元的激活输出，并进行加权相加后产生该神经元的输入值，这个过程示意图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-input.jpg&#34; alt=&#34;neuron-input&#34;&gt;&lt;/p&gt;
&lt;p&gt;定义第 $ l^{th} $ 层第 $ j^{th} $ 个神经元的输入：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-input-equation.png&#34; alt=&#34;神经元输入&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;神经元加权&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%a5%9e%e7%bb%8f%e5%85%83%e5%8a%a0%e6%9d%83&#34;&gt;
        ##
    &lt;/a&gt;
    神经元加权
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;神经元的加权结构可以看下面的示意图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-weight.jpg&#34; alt=&#34;neuron-weight&#34;&gt;&lt;/p&gt;
&lt;p&gt;注，第一层神经元的输入就是采样数据，不需要计算z值，这层采样数据直接通过权重计算输入到第二层的神经元。&lt;/p&gt;
&lt;h1 id=&#34;反向传播算法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e7%ae%97%e6%b3%95&#34;&gt;
        ##
    &lt;/a&gt;
    反向传播算法
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;代价函数&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%bb%a3%e4%bb%b7%e5%87%bd%e6%95%b0&#34;&gt;
        #
    &lt;/a&gt;
    代价函数
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;定义代价函数：$ cost = {1 \over 2} \sum (y^{(i)} - a^{(i)})^2 $&lt;/p&gt;
&lt;h2 id=&#34;神经元错误量--delta_jl-&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%a5%9e%e7%bb%8f%e5%85%83%e9%94%99%e8%af%af%e9%87%8f--delta_jl-&#34;&gt;
        #
    &lt;/a&gt;
    神经元错误量 $ \delta_j^{(l)} $
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;每个神经元的输入记为&amp;rsquo;z&amp;rsquo;，经过激活函数&amp;rsquo;f(z)&amp;lsquo;生成激活值&amp;rsquo;a&amp;rsquo;，通常情况下激活函数使用sigmoid()。那么假设对于每个神经元的输入&amp;rsquo;z&amp;rsquo;做一点微小的改变记为 $ \Delta z $，由这个改变引起的代价变化记为这个神经元的错误量 $ \delta_j^{(l)} $，从这个定义可以看出来这是一个代价函数相对于神经元的输入&amp;rsquo;z&amp;rsquo;的偏导数。&lt;/p&gt;
&lt;p&gt;定义 $ \delta_j^{(l)} $ 为 $ l^{th} $ 层中的第 $ j^{th} $ 个神经元的错误量，记作：$ \delta_j^{(l)} =\frac{\partial C}{\partial z_j^{(l)}} $&lt;/p&gt;
&lt;p&gt;经过数学推导可以得出结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最后一层（L层）第j个神经元的错误量：&lt;/li&gt;
&lt;/ul&gt;
$$ \delta_j^{(L)} = -(y-a_j^{(L)}) \bigodot [a_j^{(L)}(1-a_j^{(L)})] $$
&lt;p&gt;简单推导若成如下：&lt;/p&gt;
$$ \delta_j^{(L)} = \frac{\partial C}{\partial z_j^{(l)}} $$
$$ \frac{\partial C}{\partial z_j^{(l)}} = \frac{\partial C}{\partial a_j^{(L)}} \frac{\partial a_j^{(L)}}{\partial z_j^{(L)}} $$
$$ \frac{\partial C}{\partial a_j^{(L)}} \frac{\partial a_j^{(L)}}{\partial z_j^{(L)}} = -(y-a_j^{(L)}) \bigodot [a_j^{(L)}(1-a_j^{(L)})] $$
&lt;p&gt;y：采样的结果&lt;/p&gt;
&lt;p&gt;$ a_j^{(L)} $：样本输入计算的结果&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其余各层(l层)第j个神经元的错误量：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/delta-layer-l.png&#34; alt=&#34;delta-equation&#34;&gt;&lt;/p&gt;
&lt;p&gt;因为首先可以算出来每一层的激活量 $ a_j^{(l)} $，那么可以看出来除了最后一层外的其他层的错误量可以靠后面一层的错误量计算出来，直至推算到最后一层 $ \delta_j^{(L)} $。&lt;/p&gt;
&lt;p&gt;因此反向传播算法也就是从最后一层往前一层一层计算的过程，与计算激活量的方向正好相反，因此得名反向传播。&lt;/p&gt;
&lt;h2 id=&#34;权重调整及偏置调整&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%9d%83%e9%87%8d%e8%b0%83%e6%95%b4%e5%8f%8a%e5%81%8f%e7%bd%ae%e8%b0%83%e6%95%b4&#34;&gt;
        #
    &lt;/a&gt;
    权重调整及偏置调整
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;观察每个神经元的输入可以发现神经网络计算过程中最重要的是要确定两个量权重w和偏置b。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-input-equation.png&#34; alt=&#34;神经元输入&#34;&gt;&lt;/p&gt;
&lt;p&gt;仿照错误量计算方法将问题进行一下转化，是否可以计算出代价函数相对于权重和偏置的变化速率（偏微分），然后通过乘以一个小数字（学习速率）来一点一点降低代价函数的输出，从而逼近最终需要的权重及偏置值呢？&lt;/p&gt;
&lt;p&gt;因此可以将问题转化为求 $ \frac{\partial C}{\partial w_{jk}^{(l)}} $ 和 $ \frac{\partial C}{\partial b_j^{(l)}} $&lt;/p&gt;
&lt;p&gt;通过推导可以得出：&lt;/p&gt;
$$ \frac{\partial C}{\partial w_{jk}^{(l)}} = \delta_j^{(l+1)} a_k^{(l)} $$
$$ \frac{\partial C}{\partial b_{jk}^{(l)}} = \delta_j^{(l)} $$
&lt;p&gt;基于前面对于错误量 $ \delta_j^{(l)} $ 就可以非常简单的得到相应的结果。&lt;/p&gt;
&lt;p&gt;那么最终对于权重及偏置的调整可以这样做：&lt;/p&gt;
$$ w = w-\eta \frac{\partial C}{\partial w_{jk}^{(l)}} $$
$$ b = b-\eta \frac{\partial C}{\partial b_{jk}^{(l)}} $$
&lt;p&gt;其中 $ \eta $ 是一个非常小的正数，这个数字也被叫做“学习速率”，通过这个值的调整可以控制拟合的速度。&lt;/p&gt;
&lt;h1 id=&#34;推导过程&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%8e%a8%e5%af%bc%e8%bf%87%e7%a8%8b&#34;&gt;
        ##
    &lt;/a&gt;
    推导过程
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;前面的部分直接使用了结论，实际推到过程比较啰嗦，markdown直接编写公式也不方便，索性把推到过程的草稿贴出来参考好了&lt;/p&gt;
&lt;p&gt;:-)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/derivation-process.JPG?x-oss-process=style/png2jpg&#34; alt=&#34;推导过程&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;实验代码&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ae%9e%e9%aa%8c%e4%bb%a3%e7%a0%81&#34;&gt;
        ##
    &lt;/a&gt;
    实验代码
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;做一个简单的神经网络实验，网络设计为3层，第一层对应3个输入，第二层用4个神经元，第三层为输出层使用1个神经元。&lt;/p&gt;
&lt;p&gt;网络初始化过程如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# network design:
# input(layer_1): 3 nodes
#    weights: 3x4 matrix
# layer_2: 4 nodes
#    weights: 4x1 matrix
# output: 1 node

# create training data
input = np.array([[0, 0, 1],
                 [0, 1, 0],
                 [0, 1, 1],
                 [1, 0, 0],
                 [1, 0, 1]])

# create the label related with the input training data
output = np.array([[0],
                  [1],
                  [0],
                  [1],
                  [1]])

# initialize random weight
weight_layer_1 = np.random.rand(3, 4)
weight_layer_2 = np.random.rand(4, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;训练过程主要代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# x/y is for drawing chart
x=[]
y=[]

# learning rate
eta = 0.1

loop = 0
while loop &amp;lt; 50000:
    # feed forward calculation
    z_layer_2 = np.dot(input, weight_layer_1)
    a_layer_2 = sigmoid(z_layer_2)

    z_layer_3 = np.dot(a_layer_2, weight_layer_2)
    a_layer_3 = sigmoid(z_layer_3)
    
    if loop % 100 == 0:
        # calculate the cost
        c = cost(output, a_layer_3)
        print &amp;quot;[%d] Cost: %f&amp;quot; % (loop, c)
        print &amp;quot;Perception: &amp;quot;, a_layer_3
        x.append(loop)
        y.append(c)
    loop += 1
    
    # back propagation
    # calculate delta_3
    delta_layer_3 = cost_derivative(output, a_layer_3)*deriv_z(a_layer_3)
    
    # calculate delta_2
    delta_layer_2 = np.dot(delta_layer_3, weight_layer_2.T)*deriv_z(a_layer_2)
    
    # there is NO delta_layer_1, since layer1 is the input layer

    # calculate new weight for layer 2
    weight_layer_2 -= eta*np.dot(a_layer_2.T, delta_layer_3)
    
    # calculate new weight for layer 1
    weight_layer_1 -= eta*np.dot(input.T, delta_layer_2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面代码可以观察到每100次计算修正后的代价函数输出以及预测值，可以发现代价值在逐渐趋近于0，说明误差在降低，预测值越来越接近实际采样的数值。&lt;/p&gt;
&lt;p&gt;为了更加清晰的看到这个过程，把x/y输出在图上进行查看，可以观察到拟合过程，并且可以看到拟合的速度变化情况。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import matplotlib.pyplot as plt
plt.plot(x, y)
plt.xlabel(&amp;quot;Epoch&amp;quot;)
plt.ylabel(&amp;quot;Cost&amp;quot;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/cost-epoch.png&#34; alt=&#34;拟合过程&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/singleye/MachineLearning/blob/master/NeuralNetwork/BackPropagation/experiment-back-propagation.ipynb&#34;&gt;完整代码&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;
        ##
    &lt;/a&gt;
    参考
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=mOmkv5SI9hU&amp;amp;list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&amp;amp;index=52&#34;&gt;https://www.youtube.com/watch?v=mOmkv5SI9hU&amp;amp;list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&amp;amp;index=52&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/charlotte77/p/5629865.html&#34;&gt;http://www.cnblogs.com/charlotte77/p/5629865.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在 Nvidia Jetson TX2 上编译安装tensorflow</title>
      <link>/2017/09/%E5%9C%A8-nvidia-jetson-tx2-%E4%B8%8A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85tensorflow/</link>
      <pubDate>Thu, 14 Sep 2017 00:22:00 +0000</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/09/%E5%9C%A8-nvidia-jetson-tx2-%E4%B8%8A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85tensorflow/</guid>
      <description>&lt;!-- more /--&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/tensorflow/IMG_6135.JPG?x-oss-process=style/png2jpg&#34; alt=&#34;TX2&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;系统环境&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%b3%bb%e7%bb%9f%e7%8e%af%e5%a2%83&#34;&gt;
        ##
    &lt;/a&gt;
    系统环境
&lt;/div&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Jetpack：v3.0&lt;/li&gt;
&lt;li&gt;CUDA：8.0&lt;/li&gt;
&lt;li&gt;cuDNN：5.1.10&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;编译安装bazel&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%bc%96%e8%af%91%e5%ae%89%e8%a3%85bazel&#34;&gt;
        ##
    &lt;/a&gt;
    编译安装bazel
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;bazel是google开发的一套开发管理工具，功能类似makefile和maven，特点是速度快，编译tensorflow时需要用到这个工具。&lt;/p&gt;
&lt;p&gt;在TX2上安装bazel需要对bazel源代码做一点修改以支持该平台。下载代码后修改文件 &amp;ldquo;bazel/src/main/java/com/google/devtools/build/lib/util/CPU.java&amp;rdquo;，修改如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public enum CPU {
  X86_32(&amp;quot;x86_32&amp;quot;, ImmutableSet.of(&amp;quot;i386&amp;quot;, &amp;quot;i486&amp;quot;, &amp;quot;i586&amp;quot;, &amp;quot;i686&amp;quot;, &amp;quot;i786&amp;quot;, &amp;quot;x86&amp;quot;)),
  X86_64(&amp;quot;x86_64&amp;quot;, ImmutableSet.of(&amp;quot;amd64&amp;quot;, &amp;quot;x86_64&amp;quot;, &amp;quot;x64&amp;quot;)),
  PPC(&amp;quot;ppc&amp;quot;, ImmutableSet.of(&amp;quot;ppc&amp;quot;, &amp;quot;ppc64&amp;quot;, &amp;quot;ppc64le&amp;quot;)),
-  ARM(&amp;quot;arm&amp;quot;, ImmutableSet.of(&amp;quot;arm&amp;quot;, &amp;quot;armv7l&amp;quot;)),
+  ARM(&amp;quot;arm&amp;quot;, ImmutableSet.of(&amp;quot;arm&amp;quot;, &amp;quot;armv7l&amp;quot;, &amp;quot;aarch64&amp;quot;)),
  S390X(&amp;quot;s390x&amp;quot;, ImmutableSet.of(&amp;quot;s390x&amp;quot;, &amp;quot;s390&amp;quot;)),
  UNKNOWN(&amp;quot;unknown&amp;quot;, ImmutableSet.&amp;lt;String&amp;gt;of());
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改好之后在代码目录运行 &amp;ldquo;compile.sh&amp;rdquo; 进行编译，编译好后将程序拷贝到执行环境：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo cp output/bazel /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;安装tensorflow&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ae%89%e8%a3%85tensorflow&#34;&gt;
        ##
    &lt;/a&gt;
    安装tensorflow
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;下载tensorflow源码&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%b8%8b%e8%bd%bdtensorflow%e6%ba%90%e7%a0%81&#34;&gt;
        #
    &lt;/a&gt;
    下载tensorflow源码
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;写这篇文章的时候tensorflow已经发展到了v1.3，下载release版本代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget https://github.com/tensorflow/tensorflow/archive/v1.3.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;编译tensorflow&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%bc%96%e8%af%91tensorflow&#34;&gt;
        #
    &lt;/a&gt;
    编译tensorflow
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;配置configure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先configure编译环境：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia@tegra-ubuntu:~/tensorflow/tensorflow-1.3.0$ ./configure
You have bazel 0.4.5- installed.
Please specify the location of python. [Default is /usr/bin/python]:
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Using python library path: /usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with MKL support? [y/N]
No MKL support will be enabled for TensorFlow
Please specify optimization flags to use during compilation when bazel option &amp;quot;--config=opt&amp;quot; is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n]
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N]
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N]
No VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N]
nvcc will be used as CUDA compiler
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 5.1.10
Please specify the location where cuDNN 5.1.10 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
./configure: line 669: /usr/local/cuda/extras/demo_suite/deviceQuery: No such file or directory
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: &amp;quot;3.5,5.2&amp;quot;]: 6.2
Do you wish to build TensorFlow with MPI support? [y/N]
MPI support will not be enabled for TensorFlow
Configuration finished
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里主要说一下配置&amp;quot;compute capability&amp;quot;的方法，默认值为&amp;quot;3.5,5.2&amp;quot;，但到底该填写什么值可以通过一个jetpack自带的程序查询出来：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia@tegra-ubuntu:~/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery$ ./deviceQuery
./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: &amp;quot;GP10B&amp;quot;
  CUDA Driver Version / Runtime Version          8.5 / 8.0
  CUDA Capability Major/Minor version number:    6.2
  Total amount of global memory:                 7854 MBytes (8235577344 bytes)
  ( 2) Multiprocessors, (128) CUDA Cores/MP:     256 CUDA Cores
  GPU Max Clock rate:                            1301 MHz (1.30 GHz)
  Memory Clock rate:                             13 Mhz
  Memory Bus Width:                              64-bit
  L2 Cache Size:                                 524288 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 32768
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            Yes
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0
  Compute Mode:
     &amp;lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &amp;gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.5, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GP10B
Result = PASS
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;主意上面的内容中有下面一行内容，这行的内容就是&amp;quot;compute capability&amp;quot;：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CUDA Capability Major/Minor version number:    6.2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;编译tensorflow&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;执行下面的命令进行编译，并指定使用cuda&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia@tegra-ubuntu:~/tensorflow$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;生成pip安装包&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;执行完之后会生成pip包生成脚本 &amp;ldquo;./bazel-bin/tensorflow/tools/pip_package/build_pip_package&amp;rdquo;，可以执行这个脚本生成pip安装包：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia@tegra-ubuntu:~/tensorflow/tensorflow-1.3.0$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow
Wed Sep 13 14:41:13 UTC 2017 : === Using tmpdir: /tmp/tmp.F109O2nAzd
~/tensorflow/tensorflow-1.3.0/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles ~/tensorflow/tensorflow-1.3.0
~/tensorflow/tensorflow-1.3.0
/tmp/tmp.F109O2nAzd ~/tensorflow/tensorflow-1.3.0
Wed Sep 13 14:41:20 UTC 2017 : === Building wheel
warning: no files found matching &#39;*.dll&#39; under directory &#39;*&#39;
warning: no files found matching &#39;*.lib&#39; under directory &#39;*&#39;
warning: no files found matching &#39;*.h&#39; under directory &#39;tensorflow/include/tensorflow&#39;
warning: no files found matching &#39;*&#39; under directory &#39;tensorflow/include/Eigen&#39;
warning: no files found matching &#39;*&#39; under directory &#39;tensorflow/include/external&#39;
warning: no files found matching &#39;*.h&#39; under directory &#39;tensorflow/include/google&#39;
warning: no files found matching &#39;*&#39; under directory &#39;tensorflow/include/third_party&#39;
warning: no files found matching &#39;*&#39; under directory &#39;tensorflow/include/unsupported&#39;
~/tensorflow/tensorflow-1.3.0
Wed Sep 13 14:41:52 UTC 2017 : === Output wheel file is in: /home/nvidia/tensorflow
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;安装tensorflow&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;执行下面的命令安装：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pip install tensorflow-1.3.0-cp27-cp27mu-linux_aarch64.whl
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;eigen导致编译错误处理&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#eigen%e5%af%bc%e8%87%b4%e7%bc%96%e8%af%91%e9%94%99%e8%af%af%e5%a4%84%e7%90%86&#34;&gt;
        ##
    &lt;/a&gt;
    eigen导致编译错误处理
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;在编译tensorflow的过程中碰到了几个问题，主要是由于eigen引起。&lt;/p&gt;
&lt;h2 id=&#34;错误1-jacobih-has-no-member-named-pmul&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e9%94%99%e8%af%af1-jacobih-has-no-member-named-pmul&#34;&gt;
        #
    &lt;/a&gt;
    错误1: Jacobi.h has no member named &amp;lsquo;pmul&amp;rsquo;
&lt;/div&gt;
&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;...

In file included from external/eigen_archive/Eigen/Jacobi:27:0,
                 from external/eigen_archive/Eigen/Eigenvalues:16,
                 from ./third_party/eigen3/Eigen/Eigenvalues:1,
                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:
external/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of &#39;void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase&amp;lt;Derived&amp;gt;&amp;amp;, Eigen::DenseBase&amp;lt;Derived&amp;gt;&amp;amp;, const Eigen::J
acobiRotation&amp;lt;OtherScalar&amp;gt;&amp;amp;) [with VectorX = Eigen::Block&amp;lt;Eigen::Map&amp;lt;Eigen::Matrix&amp;lt;std::complex&amp;lt;float&amp;gt;, -1, -1&amp;gt;, 0, Eigen::Stride&amp;lt;0, 0&amp;gt; &amp;gt;, -1, 1, true&amp;gt;; VectorY = Eigen::Block&amp;lt;Eigen::Map&amp;lt;Eige
n::Matrix&amp;lt;std::complex&amp;lt;float&amp;gt;, -1, -1&amp;gt;, 0, Eigen::Stride&amp;lt;0, 0&amp;gt; &amp;gt;, -1, 1, true&amp;gt;; OtherScalar = float]&#39;:
external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from &#39;void Eigen::MatrixBase&amp;lt;Derived&amp;gt;::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation&amp;lt;OtherScalar&amp;gt;
&amp;amp;) [with OtherScalar = float; Derived = Eigen::Map&amp;lt;Eigen::Matrix&amp;lt;std::complex&amp;lt;float&amp;gt;, -1, -1&amp;gt;, 0, Eigen::Stride&amp;lt;0, 0&amp;gt; &amp;gt;; Eigen::Index = long int]&#39;
external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from &#39;void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index)
 [with int StorageOrder = 0; RealScalar = float; Scalar = std::complex&amp;lt;float&amp;gt;; Index = long int]&#39;
external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from &#39;Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&amp;amp;, SubDiagType&amp;amp;, Eig
en::Index, bool, MatrixType&amp;amp;) [with MatrixType = Eigen::Matrix&amp;lt;std::complex&amp;lt;float&amp;gt;, -1, -1&amp;gt;; DiagType = Eigen::Matrix&amp;lt;float, -1, 1&amp;gt;; SubDiagType = Eigen::Matrix&amp;lt;float, -1, 1&amp;gt;; Eigen::Index =
long int]&#39;

....

external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: &#39;struct Eigen::internal::conj_helper&amp;lt;__vector(4) float, Eigen::internal::Packet2cf, false, false&amp;gt;&#39; has no member named &#39;pmul&#39;
external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: &#39;struct Eigen::internal::conj_helper&amp;lt;__vector(4) float, Eigen::internal::Packet2cf, false, false&amp;gt;&#39; has no member named &#39;pmul&#39;
       pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));
                      ^
external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: &#39;struct Eigen::internal::conj_helper&amp;lt;__vector(4) float, Eigen::internal::Packet2cf, false, false&amp;gt;&#39; has no member named &#39;pmul&#39;
external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: &#39;struct Eigen::internal::conj_helper&amp;lt;__vector(4) float, Eigen::internal::Packet2cf, false, false&amp;gt;&#39; has no member named &#39;pmul&#39;
       pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));
                      ^
external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: &#39;struct Eigen::internal::conj_helper&amp;lt;__vector(4) float, Eigen::internal::Packet2cf, false, false&amp;gt;&#39; has no member named &#39;pmul&#39;
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2366.425s, Critical Path: 2221.96s
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;错误2-tensorflowcorelibcorethreadpoolcc-nonblockingthreadpooltempl参数错误&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e9%94%99%e8%af%af2-tensorflowcorelibcorethreadpoolcc-nonblockingthreadpooltempl%e5%8f%82%e6%95%b0%e9%94%99%e8%af%af&#34;&gt;
        #
    &lt;/a&gt;
    错误2: tensorflow/core/lib/core/threadpool.cc NonBlockingThreadPoolTempl()参数错误
&lt;/div&gt;
&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;ERROR: /home/nvidia/tensorflow/tensorflow-1.3.0/tensorflow/core/BUILD:1244:1: C++ compilation of rule &#39;//tensorflow/core:lib_internal&#39; failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/              local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE &#39;-D_FORTIFY_SOURCE=1&#39; -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 115 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/core/lib/core/threadpool.cc: In constructor &#39;tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, const tensorflow::ThreadOptions&amp;amp;, const string&amp;amp;, int, bool)&#39;:
tensorflow/core/lib/core/threadpool.cc:91:56: error: no matching function for call to &#39;Eigen::NonBlockingThreadPoolTempl&amp;lt;tensorflow::thread::EigenEnvironment&amp;gt;::NonBlockingThreadPoolTempl(int&amp;amp;, bool&amp;amp;, tensorflow::thread::              EigenEnvironment)&#39;
             EigenEnvironment(env, thread_options, name)) {}
                                                        ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/ThreadPool:58:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:72,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from tensorflow/core/lib/core/threadpool.cc:19:
external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:22:3: note: candidate: Eigen::NonBlockingThreadPoolTempl&amp;lt;Environment&amp;gt;::NonBlockingThreadPoolTempl(int, Environment) [with Environment = tensorflow::thread::EigenEnvironment]
   NonBlockingThreadPoolTempl(int num_threads, Environment env = Environment())
   ^
external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:22:3: note:   candidate expects 2 arguments, 3 provided
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 292.433s, Critical Path: 68.80s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;解决方法是使用正确版本的eigen，其中“问题一”是用v3.3.4的eigen可以解决，“问题二”需要使用最新的eigen：&lt;/p&gt;
&lt;p&gt;修复的方法是编辑&amp;quot;tensorflow/workspace.bzl&amp;quot;，并指定最新的eigen：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  native.new_http_archive(
      name = &amp;quot;eigen_archive&amp;quot;,
      #urls = [
      #    &amp;quot;http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz&amp;quot;,
      #    &amp;quot;https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz&amp;quot;,
      #],
      #sha256 = &amp;quot;ca7beac153d4059c02c8fc59816c82d54ea47fe58365e8aded4082ded0b820c4&amp;quot;,
      #strip_prefix = &amp;quot;eigen-eigen-f3a22f35b044&amp;quot;,
      urls = [
          &amp;quot;https://bitbucket.org/eigen/eigen/get/tip.tar.gz&amp;quot;,
      ],
      sha256 = &amp;quot;6fe7af8244ab5d9c314a26bc8615adc61269896cfd66f1ae2cce3d6ee91a5b88&amp;quot;,
      strip_prefix = &amp;quot;eigen-eigen-034fba127699&amp;quot;,
      build_file = str(Label(&amp;quot;//third_party:eigen.BUILD&amp;quot;)),
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中“sha256”和“strip_prefix”需要根据新的eigen修正。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Current State of Machine Intelligence (from Shivon Zilis)</title>
      <link>/2017/09/the-current-state-of-machine-intelligence-from-shivon-zilis/</link>
      <pubDate>Fri, 01 Sep 2017 14:29:00 +0000</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/09/the-current-state-of-machine-intelligence-from-shivon-zilis/</guid>
      <description>&lt;!-- more /--&gt;
&lt;p&gt;看到几张描绘近几年来机器学习领域的行业版图：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.oreilly.com/ideas/the-current-state-of-machine-intelligence-3-0&#34;&gt;&amp;ldquo;The Current State of Machine Intelligence 3.0&amp;rdquo;&lt;/a&gt; published in 2016 by &lt;a href=&#34;http://www.shivonzilis.com&#34;&gt;Shivon Zilis&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://format-com-cld-res.cloudinary.com/image/private/s--c_G81ApD--/c_crop,h_2250,w_3000,x_0,y_0/c_fill,g_center,h_855,w_1140/a_auto,fl_keep_iptc.progressive,q_95/Machine_Intelligence_Landscape_2015-05-28_2_zh0pbb.png&#34; alt=&#34;The Current State of Machine Intelligence 3.0&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.oreilly.com/ideas/the-current-state-of-machine-intelligence-2-0&#34;&gt;&amp;ldquo;The current state of machine intelligence 2.0&amp;rdquo;&lt;/a&gt; published in 2015 by &lt;a href=&#34;http://www.shivonzilis.com&#34;&gt;Shivon Zilis&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://format-com-cld-res.cloudinary.com/image/private/s--XrGmu9XK--/c_crop,h_2250,w_3000,x_0,y_0/c_fill,g_center,h_855,w_1140/a_auto,fl_keep_iptc.progressive,q_95/v1/d8404d830b489d7a87eaefc35063a8a7/MI-Landscape-2_0-R10.jpg&#34; alt=&#34;The current state of machine intelligence 2.0&#34;&gt;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;The Current State of Machine Intelligence&amp;rdquo; published in 2014 by &lt;a href=&#34;http://www.shivonzilis.com&#34;&gt;Shivon Zilis&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://format-com-cld-res.cloudinary.com/image/private/s--LpKDjJvM--/c_crop,h_1500,w_2000,x_0,y_0/c_fill,g_center,h_855,w_1140/a_auto,fl_keep_iptc.progressive,q_95/v1/19575bcc040a6dcff3097618ec9c585e/MI-Landscape-3_7.png&#34; alt=&#34;The Current State of Machine Intelligence&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>神经网络实践：自动驾驶</title>
      <link>/2017/08/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E8%B7%B5%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/</link>
      <pubDate>Thu, 17 Aug 2017 20:01:00 +0000</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/08/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E8%B7%B5%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/</guid>
      <description>&lt;!-- more /--&gt;
&lt;p&gt;最近学习了下神经网络，于是写了一个开车的小游戏，然后训练了一个6层神经网络自己驾驶练练手。&lt;/p&gt;
&lt;p&gt;代码实现主要用了pygame和numpy，网络有7个输入分别对应小车前面的7个距离探头数据，2个输出进行转向输出。&lt;/p&gt;
&lt;embed&gt;
&lt;div class=&#34;td-player&#34;&gt;&lt;object type=&#34;application/x-shockwave-flash&#34; id=&#34;CustomPlayer&#34; data=&#34;http://static.youku.com/v20170420.0/v/custom/upsplayer/player.swf&#34; width=&#34;480&#34; height=&#34;400&#34;&gt;&lt;param name=&#34;menu&#34; value=&#34;false&#34;&gt;&lt;param name=&#34;scale&#34; value=&#34;noScale&#34;&gt;&lt;param name=&#34;allowFullscreen&#34; value=&#34;true&#34;&gt;&lt;param name=&#34;allowFullScreenInteractive&#34; value=&#34;true&#34;&gt;&lt;param name=&#34;allownetworking&#34; value=&#34;all&#34;&gt;&lt;param name=&#34;allowScriptAccess&#34; value=&#34;always&#34;&gt;&lt;param name=&#34;bgcolor&#34; value=&#34;#000000&#34;&gt;&lt;param name=&#34;wmode&#34; value=&#34;transparent&#34;&gt;&lt;param name=&#34;flashvars&#34; value=&#34;playerId=tdnws&amp;amp;autoPlay=true&amp;amp;skin=http://static.youku.com/v20170420.0/v/custom/upsplayer/skin/tdnws.swf&amp;amp;lang=td&amp;amp;vcode=XMjk3NjU0MTcwNA==&amp;amp;cna=JUIjEjtGCjoCAWVQ1%2BAkCtoY&amp;amp;ytid=-1&amp;amp;winType=interior&amp;amp;adext=&#34;&gt;&lt;/object&gt;&lt;div class=&#34;td-player__html5&#34; id=&#34;player_noflash&#34;&gt;&lt;div class=&#34;td-player__html5__skin&#34;&gt;&lt;div class=&#34;td-player__html5__con&#34;&gt;&lt;span class=&#34;td-player__html5__txt&#34;&gt;您还没有安装flash播放器,请点击 &lt;a href=&#34;//www.adobe.com/go/getflash&#34; target=&#34;_blank&#34;&gt;这里&lt;/a&gt; 安装&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;/embed&gt;
</description>
    </item>
    
    <item>
      <title>图像卷积实践</title>
      <link>/2017/07/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 30 Jul 2017 18:30:50 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/07/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E5%AE%9E%E8%B7%B5/</guid>
      <description>&lt;p&gt;最近对图像识别技术很感兴趣，了解到在这个领域中CNN的应用可以比较有效的解决问题，这里对卷积（convolution）相关的知识进行一下记录说明。&lt;/p&gt;
&lt;h1 id=&#34;图像卷积是什么&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%9b%be%e5%83%8f%e5%8d%b7%e7%a7%af%e6%98%af%e4%bb%80%e4%b9%88&#34;&gt;
        ##
    &lt;/a&gt;
    图像卷积是什么？
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;将一张图片看作一张像素的矩阵的话，卷积就是把另一个矩阵（卷积核）在这张图片上移动，在移动的过程中取图片上对应大小的矩阵与卷积核进行运算，每次矩阵运算得出的结果保存成一个新的像素，这个过程就是图像的卷积运算。&lt;/p&gt;
&lt;p&gt;卷积的过程可以用下面的示意图展示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=536&amp;amp;h=392&#34; alt=&#34;图像卷积过程&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/convolution-001.png&#34; alt=&#34;卷积计算&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;为什么做卷积&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%b8%ba%e4%bb%80%e4%b9%88%e5%81%9a%e5%8d%b7%e7%a7%af&#34;&gt;
        ##
    &lt;/a&gt;
    为什么做卷积？
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;一张原始图像包含了大量的噪音信息，这些噪音信息会干扰后续的运算过程。如果将一张图像看作一个输入信号的话，如果找到一种过滤器将噪音信息过滤掉就可以提高后续运算的准确度。卷积就是这么一个过滤器，这个过滤器的正式称呼是卷积核。&lt;/p&gt;
&lt;p&gt;那么这个过滤器可以做些什么呢？其实常见的图像处理软件早已经在使用卷积进行图片处理了，比如图像锐化、模糊、浮雕效果等等&amp;hellip;&lt;/p&gt;
&lt;p&gt;下面收集了一些常用的过滤器，对这张图片处理后可以看一下效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/mini.png?x-oss-process=style/png2jpg&#34; alt=&#34;原图&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像边界检测&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
-1 &amp; -1 &amp; -1 \\
-1 &amp; 8 &amp; -1 \\
-1 &amp; -1 &amp; -1
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/edge.png?x-oss-process=style/png2jpg&#34; alt=&#34;边界检测&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像模糊&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 0
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/blur.png?x-oss-process=style/png2jpg&#34; alt=&#34;模糊&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像锐化&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
-1 &amp; -1 &amp; -1 \\
-1 &amp; 9 &amp; -1 \\
-1 &amp; -1 &amp; -1
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/sharpen.png?x-oss-process=style/png2jpg&#34; alt=&#34;锐化&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;浮雕&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
-1 &amp; -1 &amp; 0 \\
-1 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 1
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/emboss.png?x-oss-process=style/png2jpg&#34; alt=&#34;浮雕&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;用numpy进行卷积计算&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%94%a8numpy%e8%bf%9b%e8%a1%8c%e5%8d%b7%e7%a7%af%e8%ae%a1%e7%ae%97&#34;&gt;
        ##
    &lt;/a&gt;
    用numpy进行卷积计算
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;以上的图片使用下面的算法生成，主要使用了numpy的array进行的计算。通过该算法生成的图片效果还不够理想：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;比如锐化及浮雕效果，锐化的边缘有些益处而其他部分亮度有些降低&lt;/li&gt;
&lt;li&gt;浮雕的效果感觉也不够明显&lt;/li&gt;
&lt;li&gt;程序执行速度有些慢&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    def convolution(self, kernel):
        &amp;#34;&amp;#34;&amp;#34;
        Create a new Image instance by applying the kernel
        &amp;#34;&amp;#34;&amp;#34;
        print &amp;#34;Run convolution transform&amp;#34;
        print &amp;#34;Start: %s&amp;#34; % time.ctime()

        k_height, k_width = kernel.shape
        n_width = self.width - k_width + 1
        n_height = self.height - k_height + 1

        if self.color_space == COLOR_SPACE_BW:
            new_img_data = np.zeros((n_height, n_width), dtype=self.img.dtype)
            channel_kernel = kernel
        elif self.color_space == COLOR_SPACE_RGB:
            new_img_data = np.zeros((n_height, n_width, 3), dtype=self.img.dtype)
            channel_kernel = np.zeros((k_height, k_width, 3))
            for c in range(3):
                channel_kernel[:,:,c] = kernel
        elif self.color_space == COLOR_SPACE_RGBA:
            # drop the alpha channel
            new_img_data = np.zeros((n_height, n_width, 3), dtype=self.img.dtype)
            channel_kernel = np.zeros((k_height, k_width, 3))
            for c in range(3):
                channel_kernel[:,:,c] = kernel
        else:
            print &amp;#34;Unknow color space&amp;#34;
            return None

        for y in range(n_height):
            for x in range(n_width):
                if self.color_space == COLOR_SPACE_RGBA:
                    new_img_data[y][x] = sum(sum(self.img[y:y+k_height, x:x+k_width,:3]*channel_kernel))
                else:
                    new_img_data[y][x] = sum(sum(self.img[y:y+k_height, x:x+k_width]*channel_kernel))

        imax = np.max(self.img)
        nmax = np.max(new_img_data)
        scale = 1.0*imax/nmax
        print &amp;#34;imax[{0}], nmax[{1}]&amp;#34;.format(imax, nmax)
        print &amp;#34;Scale:&amp;#34;, scale
        new_img_data = (new_img_data * scale).astype(self.img.dtype)

        print &amp;#34;End: %s&amp;#34; % time.ctime()

        new_image = Image()
        new_image.load_data(new_img_data)

        return new_image
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;完整的程序可以在&lt;a href=&#34;https://github.com/singleye/MachineLearning/blob/master/convolution/convolution.py&#34;&gt;GitHub&lt;/a&gt;上找到。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>tensorflow playground</title>
      <link>/2017/02/tensorflow-playground/</link>
      <pubDate>Sat, 18 Feb 2017 17:39:21 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/02/tensorflow-playground/</guid>
      <description>&lt;p&gt;Tensorflow playground，感受一下machine learning的奇特之处：&lt;a href=&#34;http://playground.tensorflow.org&#34;&gt;http://playground.tensorflow.org&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

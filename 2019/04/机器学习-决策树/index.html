<!DOCTYPE html>


<html lang="zh-cn" data-theme="">
<head>
    
        
<meta charset="utf-8">
<meta name="HandheldFriendly" content="True">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer-when-downgrade">

<title>机器学习 - 决策树 - singleye</title>

<meta name="description" content="">


    <meta name="keywords" content="Machine Learning,Decision tree,决策树,classification">




<link rel="icon" type="image/x-icon" href="http://www.singleye.net/favicon.ico">
<link rel="apple-touch-icon-precomposed" href="http://www.singleye.net/favicon.png">








    



<style>
  body {
    visibility: hidden;
    opacity: 0;
  }
</style>

<noscript>
  <style>
    body {
      visibility: visible;
      opacity: 1;
    }
  </style>
</noscript>




    





    
    
        
    
    

    
        <link rel="stylesheet" href="/css/style.min.184a655c5ad8596648622468e6696abf0cf0a2cf8266df17b4f7a36fe9c97551.css" integrity="sha256-GEplXFrYWWZIYiRo5mlqvwzwos&#43;CZt8XtPejb&#43;nJdVE=">
    





    





    
    
        
    
    

    
        <link rel="stylesheet" href="/css/style.min.c4c04b3ef88e3d619ad4c7ee5e03048422bc55c4fefdc1f07657c1133670aa22.css" integrity="sha256-xMBLPviOPWGa1MfuXgMEhCK8VcT&#43;/cHwdlfBEzZwqiI=">
    





    





    
    
        
    
    

    
        <link rel="stylesheet" href="/css/style.min.21c5d8fe0a79d623b0adc1ce4bd4f6dd2c05cd939c9aaaa966ba7186b1464f4d.css" integrity="sha256-IcXY/gp51iOwrcHOS9T23SwFzZOcmqqpZrpxhrFGT00=">
    












    

    





    
    
        
    
    

    
        <script src="/js/script.min.08f04d96386c73c9bf4d160333f8f448c05a6e01c06770542ee0e013954ce930.js" type="text/javascript" charset="utf-8" integrity="sha256-CPBNljhsc8m/TRYDM/j0SMBabgHAZ3BULuDgE5VM6TA="></script>
    



















    
</head>
<body>
    <a class="skip-main" href="#main">Skip to main content</a>
    <div class="container">
        <header class="common-header">
            
                <div class="header-top">
    <div class="header-top-left">
        <h1 class="site-title noselect">
    <a href="/">singleye</a>
</h1>

        







    
        <div class="theme-switcher">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-sun-high"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828a4 4 0 1 0 -5.656 -5.656a4 4 0 0 0 5.656 5.656z" /><path d="M6.343 17.657l-1.414 1.414" /><path d="M6.343 6.343l-1.414 -1.414" /><path d="M17.657 6.343l1.414 -1.414" /><path d="M17.657 17.657l1.414 1.414" /><path d="M4 12h-2" /><path d="M12 4v-2" /><path d="M20 12h2" /><path d="M12 20v2" /></svg>


</span>

        </div>
    

    <script>
        const STORAGE_KEY = 'user-color-scheme'
        const defaultTheme = "light"

        let currentTheme
        let switchButton
        let autoDefinedScheme = window.matchMedia('(prefers-color-scheme: dark)')

        function switchTheme(e) {
            currentTheme = (currentTheme === 'dark') ? 'light' : 'dark';
            if (localStorage) localStorage.setItem(STORAGE_KEY, currentTheme);
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        const autoChangeScheme = e => {
            currentTheme = e.matches ? 'dark' : 'light'
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        document.addEventListener('DOMContentLoaded', function () {
            switchButton = document.querySelector('.theme-switcher')
            currentTheme = detectCurrentScheme()

            if (currentTheme === 'auto') {
                autoChangeScheme(autoDefinedScheme);
                autoDefinedScheme.addListener(autoChangeScheme);
            } else {
                document.documentElement.setAttribute('data-theme', currentTheme)
            }

            if (switchButton) {
                switchButton.addEventListener('click', switchTheme, false)
            }

            showContent();
        })

        function detectCurrentScheme() {
            if (localStorage !== null && localStorage.getItem(STORAGE_KEY)) {
                return localStorage.getItem(STORAGE_KEY)
            }
            if (defaultTheme) {
                return defaultTheme
            }
            return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
        }

        function showContent() {
            document.body.style.visibility = 'visible';
            document.body.style.opacity = 1;
        }

        function changeGiscusTheme (theme) {
            function sendMessage(message) {
              const iframe = document.querySelector('iframe.giscus-frame');
              if (!iframe) return;
              iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
            }

            sendMessage({
              setConfig: {
                theme: theme
              }
            });
        }
    </script>


        <ul class="social-icons noselect">







    <li>
            <a href="/index.xml" title="RSS" rel="me">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-rss"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 19m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" /><path d="M4 4a16 16 0 0 1 16 16" /><path d="M4 11a9 9 0 0 1 9 9" /></svg>


</span>

            </a>
        </li>
    

</ul>

    </div>
    <div class="header-top-right">

    </div>
</div>


    <nav class="noselect">
        
        
        <a class="" href="http://www.singleye.net/" title="">Home</a>
        
        <a class="" href="http://www.singleye.net/categories" title="">Categories</a>
        
        <a class="" href="http://www.singleye.net/tags" title="">Tags</a>
        
        <a class="" href="https://github.com/singleye" title="">GitHub</a>
        
    </nav>



<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>





            
        </header>
        <main id="main" tabindex="-1">
            
    

    <article class="post h-entry">
        <div class="post-header">
            <header>
                <h1 class="p-name post-title">机器学习 - 决策树</h1>
                

            </header>
            



<div class="post-info noselect">
    
        <div class="post-date dt-published">
            <time datetime="2019-04-15">2019-04-15</time>
            
        </div>
    

    <a class="post-hidden-url u-url" href="/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/">/2019/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</a>
    <a href="http://www.singleye.net/" class="p-name p-author post-hidden-author h-card" rel="me"></a>


    <div class="post-taxonomies">
        
            <ul class="post-categories">
                
                    
                    <li><a href="/categories/machine-learning/">Machine Learning</a></li>
                
                    
                    <li><a href="/categories/classification/">Classification</a></li>
                
            </ul>
        
        
            <ul class="post-tags">
                
                    
                    <li><a href="/tags/machine-learning/">#Machine Learning</a></li>
                
                    
                    <li><a href="/tags/decision-tree/">#Decision Tree</a></li>
                
                    
                    <li><a href="">#决策树</a></li>
                
                    
                    <li><a href="/tags/classification/">#Classification</a></li>
                
            </ul>
        
        
    </div>
</div>

        </div>
        

  
  




  
  
  
  <details class="toc noselect">
    <summary>Table of Contents</summary>
    <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#1什么是问题树">1.什么是问题树？</a>
      <ul>
        <li><a href="#11玩过猜字游戏吗">1.1.玩过猜字游戏吗？</a></li>
        <li><a href="#12如何通过几个问题区分猫狗鸡鸭">1.2.如何通过几个问题区分“猫狗鸡鸭”？</a></li>
      </ul>
    </li>
    <li><a href="#2为什么需要决策树">2.为什么需要决策树</a>
      <ul>
        <li><a href="#21理论依据是什么">2.1.理论依据是什么？</a></li>
      </ul>
    </li>
    <li><a href="#3怎么构建决策树">3.怎么构建决策树</a></li>
    <li><a href="#决策树算法">决策树算法</a>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav></div>
  </details>
  



<script>
  var toc = document.querySelector(".toc");
  if (toc) {
    toc.addEventListener("click", function () {
      if (event.target.tagName !== "A") {
        event.preventDefault();
        if (this.open) {
          this.open = false;
          this.classList.remove("expanded");
        } else {
          this.open = true;
          this.classList.add("expanded");
        }
      }
    });
  }
</script>

        <div class="content e-content">
            <!--toc-->
<h1 id="机器学习-决策树" >
<div>
    <a href="#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0-%e5%86%b3%e7%ad%96%e6%a0%91">
        ##
    </a>
    机器学习-决策树
</div>
</h1>
<h2 id="1什么是问题树" >
<div>
    <a href="#1%e4%bb%80%e4%b9%88%e6%98%af%e9%97%ae%e9%a2%98%e6%a0%91">
        #
    </a>
    1.什么是问题树？
</div>
</h2>
<p>请思考以下场景</p>
<h3 id="11玩过猜字游戏吗" >
<div>
    <a href="#11%e7%8e%a9%e8%bf%87%e7%8c%9c%e5%ad%97%e6%b8%b8%e6%88%8f%e5%90%97">
        ##
    </a>
    1.1.玩过猜字游戏吗？
</div>
</h3>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/1.png" alt="1"></p>
<h3 id="12如何通过几个问题区分猫狗鸡鸭" >
<div>
    <a href="#12%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e5%87%a0%e4%b8%aa%e9%97%ae%e9%a2%98%e5%8c%ba%e5%88%86%e7%8c%ab%e7%8b%97%e9%b8%a1%e9%b8%ad">
        ##
    </a>
    1.2.如何通过几个问题区分“猫狗鸡鸭”？
</div>
</h3>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/2.png" alt="2"></p>
<h4 id="121他们的特征是什么" >
<div>
    <a href="#121%e4%bb%96%e4%bb%ac%e7%9a%84%e7%89%b9%e5%be%81%e6%98%af%e4%bb%80%e4%b9%88">
        ###
    </a>
    1.2.1.他们的特征是什么？
</div>
</h4>
<table>
<thead>
<tr>
<th>物种</th>
<th>腿的数量</th>
<th>有没有脚蹼</th>
<th>喙的形状</th>
<th>会不会游泳</th>
</tr>
</thead>
<tbody>
<tr>
<td>猫</td>
<td>4</td>
<td>没有</td>
<td>没有</td>
<td>不会</td>
</tr>
<tr>
<td>狗</td>
<td>4</td>
<td>没有</td>
<td>没有</td>
<td>会</td>
</tr>
<tr>
<td>鸡</td>
<td>2</td>
<td>没有</td>
<td>尖</td>
<td>不会</td>
</tr>
<tr>
<td>鸭</td>
<td>2</td>
<td>有</td>
<td>扁</td>
<td>会</td>
</tr>
</tbody>
</table>
<p>数据的表示方法：</p>
<ul>
<li>类别：猫、狗、鸡、鸭</li>
<li>特征：腿的数量、有没有脚蹼、喙的形状，会不会游泳</li>
</ul>
<h4 id="122以下是一种区分方法" >
<div>
    <a href="#122%e4%bb%a5%e4%b8%8b%e6%98%af%e4%b8%80%e7%a7%8d%e5%8c%ba%e5%88%86%e6%96%b9%e6%b3%95">
        ###
    </a>
    1.2.2.以下是一种区分方法
</div>
</h4>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/6.png" alt="6"></p>
<p><strong>思考1：以上是不是唯一的方法？</strong>
<img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/7.png" alt="7"></p>
<p><strong>思考2：哪种判定方式更好？</strong></p>
<p><strong>思考3：如何更有效的区分？</strong></p>
<ul>
<li>如果某个特征区分问题更有效？</li>
<li>怎么判断问题更有效？</li>
</ul>
<h2 id="2为什么需要决策树" >
<div>
    <a href="#2%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%86%b3%e7%ad%96%e6%a0%91">
        #
    </a>
    2.为什么需要决策树
</div>
</h2>
<p>此刻你可能会想到：</p>
<p><strong>1. 寻找关键性问题！</strong></p>
<p><strong>2. 什么是关键性问题？</strong></p>
<p><strong>3. 怎么寻找关键性问题？</strong></p>
<h3 id="21理论依据是什么" >
<div>
    <a href="#21%e7%90%86%e8%ae%ba%e4%be%9d%e6%8d%ae%e6%98%af%e4%bb%80%e4%b9%88">
        ##
    </a>
    2.1.理论依据是什么？
</div>
</h3>
<p>&ldquo;香农&quot;提出信息论，其中对信息的度量成为香农熵，简称“熵(Entropy)”</p>
<p>在分类问题中，假设存在类别集合为  $ (X_1, X_2, &hellip; X_n) $ ，将类别 $ X_i $ 的信息定义为:</p>
<ul>
<li>
<p>$ l(X_i) = -log(P(X_i))$ , 其中 $ P(X_i)$为 $X_i $的概率</p>
</li>
<li>
<p>熵：信息的数学期望值： $ H= -\sum_{i=1}^n P(X_i) log(P(X_i))$</p>
</li>
</ul>
<p><strong>思考4：怎么理解熵？</strong></p>
<ul>
<li>信息量越大，熵越小</li>
<li>信息量越小，熵越大</li>
</ul>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/5.png" alt="5"></p>
<p><strong>思考5：为什么使用对数表示信息？</strong></p>
<p>概率 vs 信息</p>
<ul>
<li>概率越大，信息量越小</li>
<li>概率越小，信息量越大</li>
<li>多个事件同时发生的概率是多个事件发生概率相乘，总信息量是多个事件信息量相加</li>
</ul>
<p><strong>练习1：给定以下数据集，写出熵的计算方法</strong></p>
$$ H= -\sum_{i=1}^n P(X_i) log(P(X_i)) $$
<div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff6ac1">from</span> math <span style="color:#ff6ac1">import</span> log
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff6ac1">def</span> <span style="color:#57c7ff">create_dataset</span>():
</span></span><span style="display:flex;"><span>    features <span style="color:#ff6ac1">=</span> [<span style="color:#5af78e">&#39;legs&#39;</span>, <span style="color:#5af78e">&#39;flippers&#39;</span>, <span style="color:#5af78e">&#39;beak&#39;</span>, <span style="color:#5af78e">&#39;swim&#39;</span>]
</span></span><span style="display:flex;"><span>    dataset <span style="color:#ff6ac1">=</span> [
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">4</span>, <span style="color:#ff9f43">0</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;cat&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">4</span>, <span style="color:#ff9f43">0</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;cat&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">4</span>, <span style="color:#ff9f43">0</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;cat&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">4</span>, <span style="color:#ff9f43">0</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;Yes&#39;</span>, <span style="color:#5af78e">&#39;dog&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">4</span>, <span style="color:#ff9f43">0</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;Yes&#39;</span>, <span style="color:#5af78e">&#39;dog&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">2</span>, <span style="color:#ff9f43">0</span>, <span style="color:#5af78e">&#39;Sharp&#39;</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;chicken&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">2</span>, <span style="color:#ff9f43">0</span>, <span style="color:#5af78e">&#39;Sharp&#39;</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;chicken&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ff9f43">2</span>, <span style="color:#ff9f43">1</span>, <span style="color:#5af78e">&#39;Flat&#39;</span>, <span style="color:#5af78e">&#39;No&#39;</span>, <span style="color:#5af78e">&#39;duck&#39;</span>]
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">return</span> dataset, features
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff6ac1">def</span> <span style="color:#57c7ff">calc_entropy</span>(dataset):
</span></span><span style="display:flex;"><span>    count <span style="color:#ff6ac1">=</span> <span style="color:#ff5c57">len</span>(dataset)
</span></span><span style="display:flex;"><span>    class_counter <span style="color:#ff6ac1">=</span> {}
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">for</span> vector <span style="color:#ff6ac1">in</span> dataset:
</span></span><span style="display:flex;"><span>        cls <span style="color:#ff6ac1">=</span> vector[<span style="color:#ff6ac1">-</span><span style="color:#ff9f43">1</span>]
</span></span><span style="display:flex;"><span>        class_counter[cls] <span style="color:#ff6ac1">=</span> class_counter<span style="color:#ff6ac1">.</span>get(cls, <span style="color:#ff9f43">0</span>) <span style="color:#ff6ac1">+</span> <span style="color:#ff9f43">1</span>
</span></span><span style="display:flex;"><span>    entropy <span style="color:#ff6ac1">=</span> <span style="color:#ff9f43">0.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">for</span> key <span style="color:#ff6ac1">in</span> class_counter<span style="color:#ff6ac1">.</span>keys():
</span></span><span style="display:flex;"><span>        prob <span style="color:#ff6ac1">=</span> <span style="color:#ff5c57">float</span>(class_counter[key])<span style="color:#ff6ac1">/</span>count
</span></span><span style="display:flex;"><span>        entropy <span style="color:#ff6ac1">-=</span> prob <span style="color:#ff6ac1">*</span> log(prob)
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">return</span> entropy
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset, features <span style="color:#ff6ac1">=</span> create_dataset()
</span></span><span style="display:flex;"><span>entropy <span style="color:#ff6ac1">=</span> calc_entropy(dataset)
</span></span><span style="display:flex;"><span><span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;Entropy: </span><span style="color:#5af78e">{}</span><span style="color:#5af78e">&#39;</span><span style="color:#ff6ac1">.</span>format(entropy))
</span></span></code></pre></div><pre><code>Entropy: 1.3208883431493221
</code></pre>
<h2 id="3怎么构建决策树" >
<div>
    <a href="#3%e6%80%8e%e4%b9%88%e6%9e%84%e5%bb%ba%e5%86%b3%e7%ad%96%e6%a0%91">
        #
    </a>
    3.怎么构建决策树
</div>
</h2>
<p><strong>核心问题：如何通过划分数据集计算信息量的提升来找到最有效的数据特征</strong></p>
<p><strong>练习2：重新划分数据集，将符合指定特征值的数据提取出来组合新的数据集合</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff6ac1">def</span> <span style="color:#57c7ff">split_dataset</span>(dataset, feature, value):
</span></span><span style="display:flex;"><span>    new_dataset <span style="color:#ff6ac1">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">for</span> data <span style="color:#ff6ac1">in</span> dataset:
</span></span><span style="display:flex;"><span>        <span style="color:#ff6ac1">if</span> data[feature] <span style="color:#ff6ac1">==</span> value:
</span></span><span style="display:flex;"><span>            new_data <span style="color:#ff6ac1">=</span> data[:feature]
</span></span><span style="display:flex;"><span>            new_data<span style="color:#ff6ac1">.</span>extend(data[feature<span style="color:#ff6ac1">+</span><span style="color:#ff9f43">1</span>:])
</span></span><span style="display:flex;"><span>            new_dataset<span style="color:#ff6ac1">.</span>append(new_data)
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">return</span> new_dataset
</span></span></code></pre></div><p><strong>小实验1：以下将有脚蹼和没有脚蹼的数据集划分出来</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>feature <span style="color:#ff6ac1">=</span> features<span style="color:#ff6ac1">.</span>index(<span style="color:#5af78e">&#39;flippers&#39;</span>)
</span></span><span style="display:flex;"><span>with_flipper_dataset <span style="color:#ff6ac1">=</span> split_dataset(dataset, feature, <span style="color:#ff9f43">1</span>)
</span></span><span style="display:flex;"><span><span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;Dataset with flippers:&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#ff5c57">print</span>(with_flipper_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;Dataset without flippers:&#39;</span>)
</span></span><span style="display:flex;"><span>with_flipper_dataset <span style="color:#ff6ac1">=</span> split_dataset(dataset, feature, <span style="color:#ff9f43">0</span>)
</span></span><span style="display:flex;"><span><span style="color:#ff5c57">print</span>(with_flipper_dataset)
</span></span></code></pre></div><pre><code>Dataset with flippers:
[[2, 'Flat', 'No', 'duck']]
Dataset without flippers:
[[4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'Yes', 'dog'], [4, 'No', 'Yes', 'dog'], [2, 'Sharp', 'No', 'chicken'], [2, 'Sharp', 'No', 'chicken']]
</code></pre>
<p><strong>思考6：怎么表示最好的特征？</strong></p>
<ul>
<li>信息增益：通过观察信息熵的变化求得</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff6ac1">def</span> <span style="color:#57c7ff">select_best_feature</span>(dataset, features):
</span></span><span style="display:flex;"><span>    feature_count <span style="color:#ff6ac1">=</span> <span style="color:#ff5c57">len</span>(dataset[<span style="color:#ff9f43">0</span>])<span style="color:#ff6ac1">-</span><span style="color:#ff9f43">1</span>
</span></span><span style="display:flex;"><span>    current_entropy <span style="color:#ff6ac1">=</span> calc_entropy(dataset)
</span></span><span style="display:flex;"><span>    feature_selected <span style="color:#ff6ac1">=</span> <span style="color:#ff6ac1">None</span>
</span></span><span style="display:flex;"><span>    best_entropy_gain <span style="color:#ff6ac1">=</span> <span style="color:#ff9f43">0</span>
</span></span><span style="display:flex;"><span>    dataset_size <span style="color:#ff6ac1">=</span> <span style="color:#ff5c57">len</span>(dataset)
</span></span><span style="display:flex;"><span>    sub_datasets <span style="color:#ff6ac1">=</span> {}
</span></span><span style="display:flex;"><span>    sub_features <span style="color:#ff6ac1">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">for</span> i <span style="color:#ff6ac1">in</span> <span style="color:#ff5c57">range</span>(feature_count):
</span></span><span style="display:flex;"><span>        feature_values <span style="color:#ff6ac1">=</span> <span style="color:#ff5c57">set</span>([vector[i] <span style="color:#ff6ac1">for</span> vector <span style="color:#ff6ac1">in</span> dataset])
</span></span><span style="display:flex;"><span>        subset_entropy <span style="color:#ff6ac1">=</span> <span style="color:#ff9f43">0.0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;  Calculating entropy by splitting dataset with feature[</span><span style="color:#5af78e">{0}</span><span style="color:#5af78e">]&#39;</span><span style="color:#ff6ac1">.</span>format(features[i]))
</span></span><span style="display:flex;"><span>        subsets <span style="color:#ff6ac1">=</span> {}
</span></span><span style="display:flex;"><span>        <span style="color:#ff6ac1">for</span> value <span style="color:#ff6ac1">in</span> feature_values:
</span></span><span style="display:flex;"><span>            <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;    Splitting dataset with feature[</span><span style="color:#5af78e">{0}</span><span style="color:#5af78e">]==</span><span style="color:#5af78e">{1}</span><span style="color:#5af78e">&#39;</span><span style="color:#ff6ac1">.</span>format(features[i], value))
</span></span><span style="display:flex;"><span>            subset <span style="color:#ff6ac1">=</span> split_dataset(dataset, i, value)
</span></span><span style="display:flex;"><span>            subsets[value] <span style="color:#ff6ac1">=</span> subset
</span></span><span style="display:flex;"><span>            prob <span style="color:#ff6ac1">=</span> (<span style="color:#ff5c57">len</span>(subset)<span style="color:#ff6ac1">*</span><span style="color:#ff9f43">1.0</span>)<span style="color:#ff6ac1">/</span>dataset_size
</span></span><span style="display:flex;"><span>            subset_entropy <span style="color:#ff6ac1">+=</span> prob <span style="color:#ff6ac1">*</span> calc_entropy(subset)
</span></span><span style="display:flex;"><span>            <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;      Subset:&#39;</span>, subset)
</span></span><span style="display:flex;"><span>            <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;      Entropy:&#39;</span>, subset_entropy)
</span></span><span style="display:flex;"><span>        entropy_gain <span style="color:#ff6ac1">=</span> current_entropy<span style="color:#ff6ac1">-</span>subset_entropy
</span></span><span style="display:flex;"><span>        <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;    Entropy gain: </span><span style="color:#5af78e">{}</span><span style="color:#5af78e">&#39;</span><span style="color:#ff6ac1">.</span>format(entropy_gain))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#ff6ac1">if</span> best_entropy_gain <span style="color:#ff6ac1">&lt;</span> entropy_gain:
</span></span><span style="display:flex;"><span>            best_entropy_gain <span style="color:#ff6ac1">=</span> entropy_gain
</span></span><span style="display:flex;"><span>            feature_selected <span style="color:#ff6ac1">=</span> i
</span></span><span style="display:flex;"><span>            sub_datasets <span style="color:#ff6ac1">=</span> subsets
</span></span><span style="display:flex;"><span>            sub_features <span style="color:#ff6ac1">=</span> features[:feature_selected]
</span></span><span style="display:flex;"><span>            sub_features<span style="color:#ff6ac1">.</span>extend(features[feature_selected<span style="color:#ff6ac1">+</span><span style="color:#ff9f43">1</span>:])
</span></span><span style="display:flex;"><span>    <span style="color:#ff6ac1">return</span> feature_selected, sub_datasets, sub_features
</span></span></code></pre></div><p><strong>小实验2：请在数据全集上运行计算出最优数据特征</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>best_feature, sub_datasets, sub_features <span style="color:#ff6ac1">=</span> select_best_feature(dataset, features)
</span></span><span style="display:flex;"><span><span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;Best feature: </span><span style="color:#5af78e">{}</span><span style="color:#5af78e">, name: </span><span style="color:#5af78e">{}</span><span style="color:#5af78e">&#39;</span><span style="color:#ff6ac1">.</span>format(best_feature, features[best_feature]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff6ac1">for</span> feature_value <span style="color:#ff6ac1">in</span> sub_datasets<span style="color:#ff6ac1">.</span>keys():
</span></span><span style="display:flex;"><span>    <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;Sub dataset with feature[</span><span style="color:#5af78e">{}</span><span style="color:#5af78e">]==</span><span style="color:#5af78e">{}</span><span style="color:#5af78e">&#39;</span><span style="color:#ff6ac1">.</span>format(features[best_feature], feature_value))
</span></span><span style="display:flex;"><span>    <span style="color:#ff5c57">print</span>(sub_datasets[feature_value])
</span></span><span style="display:flex;"><span>    <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#39;Sub features: &#39;</span>, sub_features)
</span></span></code></pre></div><pre><code>  Calculating entropy by splitting dataset with feature[legs]
    Splitting dataset with feature[legs]==2
      Subset: [[0, 'Sharp', 'No', 'chicken'], [0, 'Sharp', 'No', 'chicken'], [1, 'Flat', 'No', 'duck']]
      Entropy: 0.2386928131105548
    Splitting dataset with feature[legs]==4
      Subset: [[0, 'No', 'No', 'cat'], [0, 'No', 'No', 'cat'], [0, 'No', 'No', 'cat'], [0, 'No', 'Yes', 'dog'], [0, 'No', 'Yes', 'dog']]
      Entropy: 0.6593251049913401
    Entropy gain: 0.661563238157982
  Calculating entropy by splitting dataset with feature[flippers]
    Splitting dataset with feature[flippers]==0
      Subset: [[4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'Yes', 'dog'], [4, 'No', 'Yes', 'dog'], [2, 'Sharp', 'No', 'chicken'], [2, 'Sharp', 'No', 'chicken']]
      Entropy: 0.9441181818928854
    Splitting dataset with feature[flippers]==1
      Subset: [[2, 'Flat', 'No', 'duck']]
      Entropy: 0.9441181818928854
    Entropy gain: 0.3767701612564367
  Calculating entropy by splitting dataset with feature[beak]
    Splitting dataset with feature[beak]==No
      Subset: [[4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'Yes', 'dog'], [4, 0, 'Yes', 'dog']]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Flat
      Subset: [[2, 1, 'No', 'duck']]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Sharp
      Subset: [[2, 0, 'No', 'chicken'], [2, 0, 'No', 'chicken']]
      Entropy: 0.4206322918807853
    Entropy gain: 0.9002560512685368
  Calculating entropy by splitting dataset with feature[swim]
    Splitting dataset with feature[swim]==No
      Subset: [[4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [2, 0, 'Sharp', 'chicken'], [2, 0, 'Sharp', 'chicken'], [2, 1, 'Flat', 'duck']]
      Entropy: 0.7585531985305136
    Splitting dataset with feature[swim]==Yes
      Subset: [[4, 0, 'No', 'dog'], [4, 0, 'No', 'dog']]
      Entropy: 0.7585531985305136
    Entropy gain: 0.5623351446188085
Best feature: 2, name: beak
Sub dataset with feature[beak]==No
[[4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'Yes', 'dog'], [4, 0, 'Yes', 'dog']]
Sub features:  ['legs', 'flippers', 'swim']
Sub dataset with feature[beak]==Flat
[[2, 1, 'No', 'duck']]
Sub features:  ['legs', 'flippers', 'swim']
Sub dataset with feature[beak]==Sharp
[[2, 0, 'No', 'chicken'], [2, 0, 'No', 'chicken']]
Sub features:  ['legs', 'flippers', 'swim']
</code></pre>
<p><strong>思考7：如果改动数据集会出现什么情况？</strong></p>
<h2 id="决策树算法" >
<div>
    <a href="#%e5%86%b3%e7%ad%96%e6%a0%91%e7%ae%97%e6%b3%95">
        #
    </a>
    决策树算法
</div>
</h2>
<h4 id="算法描述" >
<div>
    <a href="#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0">
        ###
    </a>
    算法描述：
</div>
</h4>
<ol>
<li>当前数据集是否是确定的某个类型的数据，如果是则不用再对该数据集进行分类</li>
<li>在当前数据集上选择最好的特征，通过使用这个特征区分的子数据集拥有最好的信息</li>
<li>对各子数据集重复进行上述计算</li>
</ol>
<h4 id="伪代码" >
<div>
    <a href="#%e4%bc%aa%e4%bb%a3%e7%a0%81">
        ###
    </a>
    伪代码：
</div>
</h4>
<pre tabindex="0"><code>Function CreateTree
    IF 数据集不用再分割 THEN return 该数据集类别
    ELSE
        寻找待分类数据的最好特征
        划分子数据集
        创建分支节点
        for 每个划分的子数据集
            branchPoint = CreateTree
        return 分支节点
</code></pre><p><strong>大家动手实现上面的算法，输出一棵树</strong></p>
<h1 id="4其他思考" >
<div>
    <a href="#4%e5%85%b6%e4%bb%96%e6%80%9d%e8%80%83">
        ##
    </a>
    4.其他思考
</div>
</h1>
<p><strong>思考8：数据集有什么样的影响？</strong></p>
<p><strong>思考9：数据特征有什么样的影响？</strong></p>
<p>例如：</p>
<pre tabindex="0"><code># &#39;meow&#39;:0, &#39;wong&#39;:1, &#39;googooda&#39;:2, &#39;ga&#39;:3

def create_dataset():
    features = [&#39;legs&#39;, &#39;flippers&#39;, &#39;voice&#39;]
    dataset = [
        [4, 0, 0, &#39;cat&#39;],
        [4, 0, 0, &#39;cat&#39;],
        [4, 0, 0, &#39;cat&#39;],
        [4, 0, 1, &#39;dog&#39;],
        [4, 0, 1, &#39;dog&#39;],
        [2, 0, 2, &#39;chicken&#39;],
        [2, 0, 2, &#39;chicken&#39;],
        [2, 1, 3, &#39;duck&#39;]
    ]
    return dataset, features
</code></pre><table>
<thead>
<tr>
<th>物种</th>
<th>腿的数量</th>
<th>有没有脚蹼</th>
<th>叫声</th>
</tr>
</thead>
<tbody>
<tr>
<td>猫</td>
<td>4</td>
<td>没有</td>
<td>喵喵</td>
</tr>
<tr>
<td>狗</td>
<td>4</td>
<td>没有</td>
<td>旺旺</td>
</tr>
<tr>
<td>鸡</td>
<td>2</td>
<td>没有</td>
<td>咯咯哒</td>
</tr>
<tr>
<td>鸭</td>
<td>2</td>
<td>有</td>
<td>嘎嘎</td>
</tr>
</tbody>
</table>
<p>一种区分方法</p>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/3.png" alt="3"></p>
<p><strong>思考10：有没有其他方法？</strong>
<img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/4.png" alt="4"></p>
<p><strong>思考11：如果使用前面的算法会得出什么样的结果呢？</strong></p>
        </div>

    </article>

    
    

    
        
        
            <h3 class="read-next-title noselect">Read next</h3>
            <ul class="read-next-posts noselect">
                
                <li><a href="/2019/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86/">机器学习资料收集</a></li>
                
                <li><a href="/2018/04/build-tensorflow-v1.7-on-nvidia-jetson-tx2/">Build Tensorflow v1.7 on NVIDIA Jetson tx2</a></li>
                
                <li><a href="/2017/09/the-current-state-of-machine-intelligence-from-shivon-zilis/">The Current State of Machine Intelligence (from Shivon Zilis)</a></li>
                
            </ul>
        
    

    

    
        
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "singleye" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>











    

    

    

        </main>
        
            <footer class="common-footer noselect">
    
    

    <div class="common-footer-bottom">
        

        <div style="display: flex; align-items: center; gap:8px">
            © singleye, 2024
            
        </div>
        <div style="display:flex;align-items: center">
            
            
            
            
            
            
        </div>
        <div>
            Powered by <a target="_blank" rel="noopener noreferrer" href="https://gohugo.io/">Hugo</a>, theme <a target="_blank" rel="noopener noreferrer" href="https://github.com/Junyi-99/hugo-theme-anubis2">Anubis2</a>.<br>
            

        </div>
    </div>

    <p class="h-card vcard">

    <a href=http://www.singleye.net/ class="p-name u-url url fn" rel="me"></a>

    

    
</p>

</footer>

        
    </div>
</body>
</html>

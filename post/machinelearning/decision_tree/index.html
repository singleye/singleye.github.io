<!DOCTYPE html>


<html lang="en-us" data-theme="">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
        
<meta charset="utf-8">
<meta name="HandheldFriendly" content="True">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer-when-downgrade">

<title>机器学习 - 决策树 - My New Hugo Site</title>

<meta name="description" content="">


    <meta name="keywords" content="Machine Learning,Decision tree,决策树,classification">




<link rel="icon" type="image/x-icon" href="http://localhost:1313/favicon.ico">
<link rel="apple-touch-icon-precomposed" href="http://localhost:1313/favicon.png">








    



<style>
  body {
    visibility: hidden;
    opacity: 0;
  }
</style>

<noscript>
  <style>
    body {
      visibility: visible;
      opacity: 1;
    }
  </style>
</noscript>




    





    
    
    

    
        <link rel="stylesheet" href="/css/style.03df79c682b91915c7cd261ecd1a6ec4d0fe668c98fa46310d0fbade319b11bd.css" integrity="sha256-A995xoK5GRXHzSYezRpuxND&#43;ZoyY&#43;kYxDQ&#43;63jGbEb0=">
    





    





    
    
    

    
        <link rel="stylesheet" href="/css/style.9c1888ebff42c0224ce04dac10cb2c401f1b77f54f78e8d87d73c3bed781c263.css" integrity="sha256-nBiI6/9CwCJM4E2sEMssQB8bd/VPeOjYfXPDvteBwmM=">
    





    





    
    
    

    
        <link rel="stylesheet" href="/css/style.acd606c0fce58853afe0248d37bb41acbbcdd8b1aca2412b6c0fa760da0137f3.css" integrity="sha256-rNYGwPzliFOv4CSNN7tBrLvN2LGsokErbA&#43;nYNoBN/M=">
    












    

    





    
    
    

    
        <script src="/js/script.672e2309c296e07c18bcd08b28d797a56222ff941d65f308fba3158c44885b14.js" type="text/javascript" charset="utf-8" integrity="sha256-Zy4jCcKW4HwYvNCLKNeXpWIi/5QdZfMI&#43;6MVjESIWxQ="></script>
    



















    
</head>
<body>
    <a class="skip-main" href="#main">Skip to main content</a>
    <div class="container">
        <header class="common-header">
            
                <div class="header-top">
    <div class="header-top-left">
        <h1 class="site-title noselect">
    <a href="/">My New Hugo Site</a>
</h1>

        







    
        <div class="theme-switcher">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-sun-high"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828a4 4 0 1 0 -5.656 -5.656a4 4 0 0 0 5.656 5.656z" /><path d="M6.343 17.657l-1.414 1.414" /><path d="M6.343 6.343l-1.414 -1.414" /><path d="M17.657 6.343l1.414 -1.414" /><path d="M17.657 17.657l1.414 1.414" /><path d="M4 12h-2" /><path d="M12 4v-2" /><path d="M20 12h2" /><path d="M12 20v2" /></svg>


</span>

        </div>
    

    <script>
        const STORAGE_KEY = 'user-color-scheme'
        const defaultTheme = "light"

        let currentTheme
        let switchButton
        let autoDefinedScheme = window.matchMedia('(prefers-color-scheme: dark)')

        function switchTheme(e) {
            currentTheme = (currentTheme === 'dark') ? 'light' : 'dark';
            if (localStorage) localStorage.setItem(STORAGE_KEY, currentTheme);
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        const autoChangeScheme = e => {
            currentTheme = e.matches ? 'dark' : 'light'
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        document.addEventListener('DOMContentLoaded', function () {
            switchButton = document.querySelector('.theme-switcher')
            currentTheme = detectCurrentScheme()

            if (currentTheme === 'auto') {
                autoChangeScheme(autoDefinedScheme);
                autoDefinedScheme.addListener(autoChangeScheme);
            } else {
                document.documentElement.setAttribute('data-theme', currentTheme)
            }

            if (switchButton) {
                switchButton.addEventListener('click', switchTheme, false)
            }

            showContent();
        })

        function detectCurrentScheme() {
            if (localStorage !== null && localStorage.getItem(STORAGE_KEY)) {
                return localStorage.getItem(STORAGE_KEY)
            }
            if (defaultTheme) {
                return defaultTheme
            }
            return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
        }

        function showContent() {
            document.body.style.visibility = 'visible';
            document.body.style.opacity = 1;
        }

        function changeGiscusTheme (theme) {
            function sendMessage(message) {
              const iframe = document.querySelector('iframe.giscus-frame');
              if (!iframe) return;
              iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
            }

            sendMessage({
              setConfig: {
                theme: theme
              }
            });
        }
    </script>


        <ul class="social-icons noselect">







    <li>
            <a href="/index.xml" title="RSS" rel="me">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-rss"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 19m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" /><path d="M4 4a16 16 0 0 1 16 16" /><path d="M4 11a9 9 0 0 1 9 9" /></svg>


</span>

            </a>
        </li>
    

</ul>

    </div>
    <div class="header-top-right">

    </div>
</div>


    <nav class="noselect">
        
        
        <a class="" href="http://localhost:1313/" title="">Home</a>
        
        <a class="" href="http://localhost:1313/posts/" title="">Posts</a>
        
        <a class="" href="http://localhost:1313/project/" title="">Project</a>
        
        <a class="" href="http://localhost:1313/about/" title="">About</a>
        
        <a class="" href="http://localhost:1313/journey/" title="">Journey</a>
        
        <a class="" href="http://localhost:1313/contact/" title="">Contact</a>
        
    </nav>



<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>





            
        </header>
        <main id="main" tabindex="-1">
            
    

    <article class="post h-entry">
        <div class="post-header">
            <header>
                <h1 class="p-name post-title">机器学习 - 决策树</h1>
                

            </header>
            



<div class="post-info noselect">
    
        <div class="post-date dt-published">
            <time datetime="2019-04-15">2019-04-15</time>
            
        </div>
    

    <a class="post-hidden-url u-url" href="/post/machinelearning/decision_tree/">/post/machinelearning/decision_tree/</a>
    <a href="http://localhost:1313/" class="p-name p-author post-hidden-author h-card" rel="me"></a>


    <div class="post-taxonomies">
        
            <ul class="post-categories">
                
                    
                    <li><a href="/categories/machine-learning/">Machine Learning</a></li>
                
                    
                    <li><a href="/categories/classification/">Classification</a></li>
                
            </ul>
        
        
            <ul class="post-tags">
                
                    
                    <li><a href="/tags/machine-learning/">#Machine Learning</a></li>
                
                    
                    <li><a href="/tags/decision-tree/">#Decision Tree</a></li>
                
                    
                    <li><a href="">#决策树</a></li>
                
                    
                    <li><a href="/tags/classification/">#Classification</a></li>
                
            </ul>
        
        
    </div>
</div>

        </div>
        

  
  




  
  
  
  <details class="toc noselect">
    <summary>Table of Contents</summary>
    <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#1什么是问题树">1.什么是问题树？</a>
      <ul>
        <li><a href="#11玩过猜字游戏吗">1.1.玩过猜字游戏吗？</a></li>
        <li><a href="#12如何通过几个问题区分猫狗鸡鸭">1.2.如何通过几个问题区分“猫狗鸡鸭”？</a></li>
      </ul>
    </li>
    <li><a href="#2为什么需要决策树">2.为什么需要决策树</a>
      <ul>
        <li><a href="#21理论依据是什么">2.1.理论依据是什么？</a></li>
      </ul>
    </li>
    <li><a href="#3怎么构建决策树">3.怎么构建决策树</a></li>
    <li><a href="#决策树算法">决策树算法</a>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav></div>
  </details>
  



<script>
  var toc = document.querySelector(".toc");
  if (toc) {
    toc.addEventListener("click", function () {
      if (event.target.tagName !== "A") {
        event.preventDefault();
        if (this.open) {
          this.open = false;
          this.classList.remove("expanded");
        } else {
          this.open = true;
          this.classList.add("expanded");
        }
      }
    });
  }
</script>

        <div class="content e-content">
            <!-- raw HTML omitted -->
<h1 id="机器学习-决策树" >
<div>
    <a href="#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0-%e5%86%b3%e7%ad%96%e6%a0%91">
        ##
    </a>
    机器学习-决策树
</div>
</h1>
<h2 id="1什么是问题树" >
<div>
    <a href="#1%e4%bb%80%e4%b9%88%e6%98%af%e9%97%ae%e9%a2%98%e6%a0%91">
        #
    </a>
    1.什么是问题树？
</div>
</h2>
<p>请思考以下场景</p>
<h3 id="11玩过猜字游戏吗" >
<div>
    <a href="#11%e7%8e%a9%e8%bf%87%e7%8c%9c%e5%ad%97%e6%b8%b8%e6%88%8f%e5%90%97">
        ##
    </a>
    1.1.玩过猜字游戏吗？
</div>
</h3>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/1.png" alt="1"></p>
<h3 id="12如何通过几个问题区分猫狗鸡鸭" >
<div>
    <a href="#12%e5%a6%82%e4%bd%95%e9%80%9a%e8%bf%87%e5%87%a0%e4%b8%aa%e9%97%ae%e9%a2%98%e5%8c%ba%e5%88%86%e7%8c%ab%e7%8b%97%e9%b8%a1%e9%b8%ad">
        ##
    </a>
    1.2.如何通过几个问题区分“猫狗鸡鸭”？
</div>
</h3>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/2.png" alt="2"></p>
<h4 id="121他们的特征是什么" >
<div>
    <a href="#121%e4%bb%96%e4%bb%ac%e7%9a%84%e7%89%b9%e5%be%81%e6%98%af%e4%bb%80%e4%b9%88">
        ###
    </a>
    1.2.1.他们的特征是什么？
</div>
</h4>
<table>
<thead>
<tr>
<th>物种</th>
<th>腿的数量</th>
<th>有没有脚蹼</th>
<th>喙的形状</th>
<th>会不会游泳</th>
</tr>
</thead>
<tbody>
<tr>
<td>猫</td>
<td>4</td>
<td>没有</td>
<td>没有</td>
<td>不会</td>
</tr>
<tr>
<td>狗</td>
<td>4</td>
<td>没有</td>
<td>没有</td>
<td>会</td>
</tr>
<tr>
<td>鸡</td>
<td>2</td>
<td>没有</td>
<td>尖</td>
<td>不会</td>
</tr>
<tr>
<td>鸭</td>
<td>2</td>
<td>有</td>
<td>扁</td>
<td>会</td>
</tr>
</tbody>
</table>
<p>数据的表示方法：</p>
<ul>
<li>类别：猫、狗、鸡、鸭</li>
<li>特征：腿的数量、有没有脚蹼、喙的形状，会不会游泳</li>
</ul>
<h4 id="122以下是一种区分方法" >
<div>
    <a href="#122%e4%bb%a5%e4%b8%8b%e6%98%af%e4%b8%80%e7%a7%8d%e5%8c%ba%e5%88%86%e6%96%b9%e6%b3%95">
        ###
    </a>
    1.2.2.以下是一种区分方法
</div>
</h4>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/6.png" alt="6"></p>
<p><strong>思考1：以上是不是唯一的方法？</strong>
<img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/7.png" alt="7"></p>
<p><strong>思考2：哪种判定方式更好？</strong></p>
<p><strong>思考3：如何更有效的区分？</strong></p>
<ul>
<li>如果某个特征区分问题更有效？</li>
<li>怎么判断问题更有效？</li>
</ul>
<h2 id="2为什么需要决策树" >
<div>
    <a href="#2%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%86%b3%e7%ad%96%e6%a0%91">
        #
    </a>
    2.为什么需要决策树
</div>
</h2>
<p>此刻你可能会想到：</p>
<p><strong>1. 寻找关键性问题！</strong></p>
<p><strong>2. 什么是关键性问题？</strong></p>
<p><strong>3. 怎么寻找关键性问题？</strong></p>
<h3 id="21理论依据是什么" >
<div>
    <a href="#21%e7%90%86%e8%ae%ba%e4%be%9d%e6%8d%ae%e6%98%af%e4%bb%80%e4%b9%88">
        ##
    </a>
    2.1.理论依据是什么？
</div>
</h3>
<p>&ldquo;香农&quot;提出信息论，其中对信息的度量成为香农熵，简称“熵(Entropy)”</p>
<p>在分类问题中，假设存在类别集合为  $ (X_1, X_2, &hellip; X_n) $ ，将类别 $ X_i $ 的信息定义为:</p>
<ul>
<li>
<p>$ l(X_i) = -log(P(X_i))$ , 其中 $ P(X_i)$为 $X_i $的概率</p>
</li>
<li>
<p>熵：信息的数学期望值： $ H= -\sum_{i=1}^n P(X_i) log(P(X_i))$</p>
</li>
</ul>
<p><strong>思考4：怎么理解熵？</strong></p>
<ul>
<li>信息量越大，熵越小</li>
<li>信息量越小，熵越大</li>
</ul>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/5.png" alt="5"></p>
<p><strong>思考5：为什么使用对数表示信息？</strong></p>
<p>概率 vs 信息</p>
<ul>
<li>概率越大，信息量越小</li>
<li>概率越小，信息量越大</li>
<li>多个事件同时发生的概率是多个事件发生概率相乘，总信息量是多个事件信息量相加</li>
</ul>
<p><strong>练习1：给定以下数据集，写出熵的计算方法</strong></p>
$$ H= -\sum_{i=1}^n P(X_i) log(P(X_i)) $$
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> math <span style="color:#f92672">import</span> log
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_dataset</span>():
</span></span><span style="display:flex;"><span>    features <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;legs&#39;</span>, <span style="color:#e6db74">&#39;flippers&#39;</span>, <span style="color:#e6db74">&#39;beak&#39;</span>, <span style="color:#e6db74">&#39;swim&#39;</span>]
</span></span><span style="display:flex;"><span>    dataset <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;cat&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;cat&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;cat&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;Yes&#39;</span>, <span style="color:#e6db74">&#39;dog&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;Yes&#39;</span>, <span style="color:#e6db74">&#39;dog&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;Sharp&#39;</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;chicken&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;Sharp&#39;</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;chicken&#39;</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#39;Flat&#39;</span>, <span style="color:#e6db74">&#39;No&#39;</span>, <span style="color:#e6db74">&#39;duck&#39;</span>]
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dataset, features
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calc_entropy</span>(dataset):
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">=</span> len(dataset)
</span></span><span style="display:flex;"><span>    class_counter <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> vector <span style="color:#f92672">in</span> dataset:
</span></span><span style="display:flex;"><span>        cls <span style="color:#f92672">=</span> vector[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        class_counter[cls] <span style="color:#f92672">=</span> class_counter<span style="color:#f92672">.</span>get(cls, <span style="color:#ae81ff">0</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    entropy <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> key <span style="color:#f92672">in</span> class_counter<span style="color:#f92672">.</span>keys():
</span></span><span style="display:flex;"><span>        prob <span style="color:#f92672">=</span> float(class_counter[key])<span style="color:#f92672">/</span>count
</span></span><span style="display:flex;"><span>        entropy <span style="color:#f92672">-=</span> prob <span style="color:#f92672">*</span> log(prob)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> entropy
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset, features <span style="color:#f92672">=</span> create_dataset()
</span></span><span style="display:flex;"><span>entropy <span style="color:#f92672">=</span> calc_entropy(dataset)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Entropy: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(entropy))
</span></span></code></pre></div><pre><code>Entropy: 1.3208883431493221
</code></pre>
<h2 id="3怎么构建决策树" >
<div>
    <a href="#3%e6%80%8e%e4%b9%88%e6%9e%84%e5%bb%ba%e5%86%b3%e7%ad%96%e6%a0%91">
        #
    </a>
    3.怎么构建决策树
</div>
</h2>
<p><strong>核心问题：如何通过划分数据集计算信息量的提升来找到最有效的数据特征</strong></p>
<p><strong>练习2：重新划分数据集，将符合指定特征值的数据提取出来组合新的数据集合</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">split_dataset</span>(dataset, feature, value):
</span></span><span style="display:flex;"><span>    new_dataset <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> dataset:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> data[feature] <span style="color:#f92672">==</span> value:
</span></span><span style="display:flex;"><span>            new_data <span style="color:#f92672">=</span> data[:feature]
</span></span><span style="display:flex;"><span>            new_data<span style="color:#f92672">.</span>extend(data[feature<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>:])
</span></span><span style="display:flex;"><span>            new_dataset<span style="color:#f92672">.</span>append(new_data)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> new_dataset
</span></span></code></pre></div><p><strong>小实验1：以下将有脚蹼和没有脚蹼的数据集划分出来</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>feature <span style="color:#f92672">=</span> features<span style="color:#f92672">.</span>index(<span style="color:#e6db74">&#39;flippers&#39;</span>)
</span></span><span style="display:flex;"><span>with_flipper_dataset <span style="color:#f92672">=</span> split_dataset(dataset, feature, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Dataset with flippers:&#39;</span>)
</span></span><span style="display:flex;"><span>print(with_flipper_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Dataset without flippers:&#39;</span>)
</span></span><span style="display:flex;"><span>with_flipper_dataset <span style="color:#f92672">=</span> split_dataset(dataset, feature, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>print(with_flipper_dataset)
</span></span></code></pre></div><pre><code>Dataset with flippers:
[[2, 'Flat', 'No', 'duck']]
Dataset without flippers:
[[4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'Yes', 'dog'], [4, 'No', 'Yes', 'dog'], [2, 'Sharp', 'No', 'chicken'], [2, 'Sharp', 'No', 'chicken']]
</code></pre>
<p><strong>思考6：怎么表示最好的特征？</strong></p>
<ul>
<li>信息增益：通过观察信息熵的变化求得</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">select_best_feature</span>(dataset, features):
</span></span><span style="display:flex;"><span>    feature_count <span style="color:#f92672">=</span> len(dataset[<span style="color:#ae81ff">0</span>])<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    current_entropy <span style="color:#f92672">=</span> calc_entropy(dataset)
</span></span><span style="display:flex;"><span>    feature_selected <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>    best_entropy_gain <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    dataset_size <span style="color:#f92672">=</span> len(dataset)
</span></span><span style="display:flex;"><span>    sub_datasets <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>    sub_features <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(feature_count):
</span></span><span style="display:flex;"><span>        feature_values <span style="color:#f92672">=</span> set([vector[i] <span style="color:#66d9ef">for</span> vector <span style="color:#f92672">in</span> dataset])
</span></span><span style="display:flex;"><span>        subset_entropy <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;  Calculating entropy by splitting dataset with feature[</span><span style="color:#e6db74">{0}</span><span style="color:#e6db74">]&#39;</span><span style="color:#f92672">.</span>format(features[i]))
</span></span><span style="display:flex;"><span>        subsets <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> value <span style="color:#f92672">in</span> feature_values:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#39;    Splitting dataset with feature[</span><span style="color:#e6db74">{0}</span><span style="color:#e6db74">]==</span><span style="color:#e6db74">{1}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(features[i], value))
</span></span><span style="display:flex;"><span>            subset <span style="color:#f92672">=</span> split_dataset(dataset, i, value)
</span></span><span style="display:flex;"><span>            subsets[value] <span style="color:#f92672">=</span> subset
</span></span><span style="display:flex;"><span>            prob <span style="color:#f92672">=</span> (len(subset)<span style="color:#f92672">*</span><span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">/</span>dataset_size
</span></span><span style="display:flex;"><span>            subset_entropy <span style="color:#f92672">+=</span> prob <span style="color:#f92672">*</span> calc_entropy(subset)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#39;      Subset:&#39;</span>, subset)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#39;      Entropy:&#39;</span>, subset_entropy)
</span></span><span style="display:flex;"><span>        entropy_gain <span style="color:#f92672">=</span> current_entropy<span style="color:#f92672">-</span>subset_entropy
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;    Entropy gain: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(entropy_gain))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> best_entropy_gain <span style="color:#f92672">&lt;</span> entropy_gain:
</span></span><span style="display:flex;"><span>            best_entropy_gain <span style="color:#f92672">=</span> entropy_gain
</span></span><span style="display:flex;"><span>            feature_selected <span style="color:#f92672">=</span> i
</span></span><span style="display:flex;"><span>            sub_datasets <span style="color:#f92672">=</span> subsets
</span></span><span style="display:flex;"><span>            sub_features <span style="color:#f92672">=</span> features[:feature_selected]
</span></span><span style="display:flex;"><span>            sub_features<span style="color:#f92672">.</span>extend(features[feature_selected<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>:])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> feature_selected, sub_datasets, sub_features
</span></span></code></pre></div><p><strong>小实验2：请在数据全集上运行计算出最优数据特征</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>best_feature, sub_datasets, sub_features <span style="color:#f92672">=</span> select_best_feature(dataset, features)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Best feature: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, name: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(best_feature, features[best_feature]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> feature_value <span style="color:#f92672">in</span> sub_datasets<span style="color:#f92672">.</span>keys():
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Sub dataset with feature[</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">]==</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(features[best_feature], feature_value))
</span></span><span style="display:flex;"><span>    print(sub_datasets[feature_value])
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Sub features: &#39;</span>, sub_features)
</span></span></code></pre></div><pre><code>  Calculating entropy by splitting dataset with feature[legs]
    Splitting dataset with feature[legs]==2
      Subset: [[0, 'Sharp', 'No', 'chicken'], [0, 'Sharp', 'No', 'chicken'], [1, 'Flat', 'No', 'duck']]
      Entropy: 0.2386928131105548
    Splitting dataset with feature[legs]==4
      Subset: [[0, 'No', 'No', 'cat'], [0, 'No', 'No', 'cat'], [0, 'No', 'No', 'cat'], [0, 'No', 'Yes', 'dog'], [0, 'No', 'Yes', 'dog']]
      Entropy: 0.6593251049913401
    Entropy gain: 0.661563238157982
  Calculating entropy by splitting dataset with feature[flippers]
    Splitting dataset with feature[flippers]==0
      Subset: [[4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'No', 'cat'], [4, 'No', 'Yes', 'dog'], [4, 'No', 'Yes', 'dog'], [2, 'Sharp', 'No', 'chicken'], [2, 'Sharp', 'No', 'chicken']]
      Entropy: 0.9441181818928854
    Splitting dataset with feature[flippers]==1
      Subset: [[2, 'Flat', 'No', 'duck']]
      Entropy: 0.9441181818928854
    Entropy gain: 0.3767701612564367
  Calculating entropy by splitting dataset with feature[beak]
    Splitting dataset with feature[beak]==No
      Subset: [[4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'Yes', 'dog'], [4, 0, 'Yes', 'dog']]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Flat
      Subset: [[2, 1, 'No', 'duck']]
      Entropy: 0.4206322918807853
    Splitting dataset with feature[beak]==Sharp
      Subset: [[2, 0, 'No', 'chicken'], [2, 0, 'No', 'chicken']]
      Entropy: 0.4206322918807853
    Entropy gain: 0.9002560512685368
  Calculating entropy by splitting dataset with feature[swim]
    Splitting dataset with feature[swim]==No
      Subset: [[4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [2, 0, 'Sharp', 'chicken'], [2, 0, 'Sharp', 'chicken'], [2, 1, 'Flat', 'duck']]
      Entropy: 0.7585531985305136
    Splitting dataset with feature[swim]==Yes
      Subset: [[4, 0, 'No', 'dog'], [4, 0, 'No', 'dog']]
      Entropy: 0.7585531985305136
    Entropy gain: 0.5623351446188085
Best feature: 2, name: beak
Sub dataset with feature[beak]==No
[[4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'No', 'cat'], [4, 0, 'Yes', 'dog'], [4, 0, 'Yes', 'dog']]
Sub features:  ['legs', 'flippers', 'swim']
Sub dataset with feature[beak]==Flat
[[2, 1, 'No', 'duck']]
Sub features:  ['legs', 'flippers', 'swim']
Sub dataset with feature[beak]==Sharp
[[2, 0, 'No', 'chicken'], [2, 0, 'No', 'chicken']]
Sub features:  ['legs', 'flippers', 'swim']
</code></pre>
<p><strong>思考7：如果改动数据集会出现什么情况？</strong></p>
<h2 id="决策树算法" >
<div>
    <a href="#%e5%86%b3%e7%ad%96%e6%a0%91%e7%ae%97%e6%b3%95">
        #
    </a>
    决策树算法
</div>
</h2>
<h4 id="算法描述" >
<div>
    <a href="#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0">
        ###
    </a>
    算法描述：
</div>
</h4>
<ol>
<li>当前数据集是否是确定的某个类型的数据，如果是则不用再对该数据集进行分类</li>
<li>在当前数据集上选择最好的特征，通过使用这个特征区分的子数据集拥有最好的信息</li>
<li>对各子数据集重复进行上述计算</li>
</ol>
<h4 id="伪代码" >
<div>
    <a href="#%e4%bc%aa%e4%bb%a3%e7%a0%81">
        ###
    </a>
    伪代码：
</div>
</h4>
<pre tabindex="0"><code>Function CreateTree
    IF 数据集不用再分割 THEN return 该数据集类别
    ELSE
        寻找待分类数据的最好特征
        划分子数据集
        创建分支节点
        for 每个划分的子数据集
            branchPoint = CreateTree
        return 分支节点
</code></pre><p><strong>大家动手实现上面的算法，输出一棵树</strong></p>
<h1 id="4其他思考" >
<div>
    <a href="#4%e5%85%b6%e4%bb%96%e6%80%9d%e8%80%83">
        ##
    </a>
    4.其他思考
</div>
</h1>
<p><strong>思考8：数据集有什么样的影响？</strong></p>
<p><strong>思考9：数据特征有什么样的影响？</strong></p>
<p>例如：</p>
<pre tabindex="0"><code># &#39;meow&#39;:0, &#39;wong&#39;:1, &#39;googooda&#39;:2, &#39;ga&#39;:3

def create_dataset():
    features = [&#39;legs&#39;, &#39;flippers&#39;, &#39;voice&#39;]
    dataset = [
        [4, 0, 0, &#39;cat&#39;],
        [4, 0, 0, &#39;cat&#39;],
        [4, 0, 0, &#39;cat&#39;],
        [4, 0, 1, &#39;dog&#39;],
        [4, 0, 1, &#39;dog&#39;],
        [2, 0, 2, &#39;chicken&#39;],
        [2, 0, 2, &#39;chicken&#39;],
        [2, 1, 3, &#39;duck&#39;]
    ]
    return dataset, features
</code></pre><table>
<thead>
<tr>
<th>物种</th>
<th>腿的数量</th>
<th>有没有脚蹼</th>
<th>叫声</th>
</tr>
</thead>
<tbody>
<tr>
<td>猫</td>
<td>4</td>
<td>没有</td>
<td>喵喵</td>
</tr>
<tr>
<td>狗</td>
<td>4</td>
<td>没有</td>
<td>旺旺</td>
</tr>
<tr>
<td>鸡</td>
<td>2</td>
<td>没有</td>
<td>咯咯哒</td>
</tr>
<tr>
<td>鸭</td>
<td>2</td>
<td>有</td>
<td>嘎嘎</td>
</tr>
</tbody>
</table>
<p>一种区分方法</p>
<p><img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/3.png" alt="3"></p>
<p><strong>思考10：有没有其他方法？</strong>
<img src="https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2019/04/decision-tree/4.png" alt="4"></p>
<p><strong>思考11：如果使用前面的算法会得出什么样的结果呢？</strong></p>
        </div>

    </article>

    
    

    
        
        
            <h3 class="read-next-title noselect">Read next</h3>
            <ul class="read-next-posts noselect">
                
                <li><a href="/post/machinelearning/resources/">机器学习资料收集</a></li>
                
                <li><a href="/post/machinelearning/tensorflow/build_v1.7_on_tx2/">Build Tensorflow v1.7 on NVIDIA Jetson tx2</a></li>
                
                <li><a href="/post/machinelearning/machine_learning_chart/">The Current State of Machine Intelligence (from Shivon Zilis)</a></li>
                
            </ul>
        
    

    

    
        









    

    

    

        </main>
        
            <footer class="common-footer noselect">
    
    

    <div class="common-footer-bottom">
        

        <div style="display: flex; align-items: center; gap:8px">
            © 2024
            
        </div>
        <div style="display:flex;align-items: center">
            
            
            
            
            
            
        </div>
        <div>
            Powered by <a target="_blank" rel="noopener noreferrer" href="https://gohugo.io/">Hugo</a>, theme <a target="_blank" rel="noopener noreferrer" href="https://github.com/Junyi-99/hugo-theme-anubis2">Anubis2</a>.<br>
            

        </div>
    </div>

    <p class="h-card vcard">

    <a href=http://localhost:1313/ class="p-name u-url url fn" rel="me"></a>

    

    
</p>

</footer>

        
    </div>
</body>
</html>

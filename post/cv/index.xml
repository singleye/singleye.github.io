<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision on singleye</title>
    <link>/post/cv/</link>
    <description>singleye (Computer Vision)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <managingEditor>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</managingEditor>
    <webMaster>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</webMaster>
    <lastBuildDate>Wed, 09 Aug 2023 15:15:25 +0800</lastBuildDate>
    
    <atom:link href="/post/cv/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>多媒体格式标准、H264 编码与 MP4 格式简要介绍</title>
      <link>/2023/08/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%A0%BC%E5%BC%8F%E6%A0%87%E5%87%86h264-%E7%BC%96%E7%A0%81%E4%B8%8E-mp4-%E6%A0%BC%E5%BC%8F%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Wed, 09 Aug 2023 15:15:25 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2023/08/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%A0%BC%E5%BC%8F%E6%A0%87%E5%87%86h264-%E7%BC%96%E7%A0%81%E4%B8%8E-mp4-%E6%A0%BC%E5%BC%8F%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D/</guid>
      <description>&lt;h1 id=&#34;1标准概括&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#1%e6%a0%87%e5%87%86%e6%a6%82%e6%8b%ac&#34;&gt;
        ##
    &lt;/a&gt;
    1.标准概括
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;11mpeg-1&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#11mpeg-1&#34;&gt;
        #
    &lt;/a&gt;
    1.1.MPEG-1
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;主要用于 CD / VCD 光盘时代的音视频压缩。&lt;/p&gt;
&lt;p&gt;MPEG-1可以按照分层的概念来理解，一个MPEG-1视频编码序列分为三个层次，从顶层到最底层依次是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像组层（GOP: Group of Picture）&lt;/li&gt;
&lt;li&gt;帧层（frame），每个 GOP 可以包含多个 frame&lt;/li&gt;
&lt;li&gt;像条层（slice），每个 frame 可以包含多个 slice&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MPEG-1 定义的帧种类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I-图像／帧（节点编码图像，intra coded picture）参考图像，相当于一个固定影像，且独立于其它的图像类型。每个图像组群由此类型的图像开始。编码时独立编码，仅适用帧内编码技术，因而解码时不参考其他帧，类似JPEG编码。&lt;/li&gt;
&lt;li&gt;P-图像／帧（预测编码图像，predictive coded picture）包含来自先前的I或P-画格的差异信息。编码时使用运动补偿和运动估计，采用前向估计，参考之前的I-帧或者P-帧去预测该P格。&lt;/li&gt;
&lt;li&gt;B-图像／帧（前后预测编码图像，bidirectionally predictive coded pictures）包含来自先前和／或之后的I或 P-画格的差异信息。编码也使用运动补偿和运动估计，预估采用前向估计、后向估计或是双向估计，主要参考前面的或者后面的I格或者P格。&lt;/li&gt;
&lt;li&gt;D-图像／帧（指示编码图像，DC direct coded picture）用于快速进带。仅由DC直流分量构造的图像，可在低比特率的时候做浏览用。实际编码中很少使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;12mpeg-2&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#12mpeg-2&#34;&gt;
        #
    &lt;/a&gt;
    1.2.MPEG-2
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;MPEG-2 是 DVD 和数字电视广播时代产生的音视频编码标准，但也被应用于后来的高清电视（HDTV）和蓝光光盘。&lt;/p&gt;
&lt;p&gt;MPEG-2 的编码码流分为六个层次，从顶层到最底层依次是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;视频序列层（Sequence）&lt;/li&gt;
&lt;li&gt;图像组层（GOP: Group of Picture）&lt;/li&gt;
&lt;li&gt;图像层（Picture）&lt;/li&gt;
&lt;li&gt;像条层（Slice）&lt;/li&gt;
&lt;li&gt;宏块层（Macro Block）&lt;/li&gt;
&lt;li&gt;像块层（Block）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;13mpeg-3&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#13mpeg-3&#34;&gt;
        #
    &lt;/a&gt;
    1.3.MPEG-3
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;MPEG-3是MPEG组织制定的视频和音频压缩标准。本来的目标是为HDTV提供20-40Mbps视频压缩技术。在标准制定的过程中，委员会很快发现MPEG-2技术足以获取类似的效果，因此将其合并到MPEG-2，成为MPEG-2的延伸。&lt;/p&gt;
&lt;h3 id=&#34;mp3-vs-mpeg-3&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#mp3-vs-mpeg-3&#34;&gt;
        ##
    &lt;/a&gt;
    MP3 vs MPEG-3
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;MP3 是 MPEG-1 音频 Layer-3 部分，MPEG-1 的音频格式有 3 代，MP3 是第三代。&lt;/p&gt;
&lt;p&gt;MPEG-3 是音视频标准，目前已经属于 MPEG-2 的一部分。&lt;/p&gt;
&lt;h2 id=&#34;14-mpeg-4&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#14-mpeg-4&#34;&gt;
        #
    &lt;/a&gt;
    1.4. MPEG-4
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;MPEG-4 是由一系列标准组成&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;第一部分（ISO/IEC 14496-1）：系统：描述视频和音频数据流的控制、同步以及混合方式（即混流Multiplexing，简写为MUX）。&lt;/p&gt;
&lt;p&gt;第二部分（ISO/IEC 14496-2）：视频：定义一个对各种视觉信息（包括自然视频、静止纹理、计算机合成图形等等）的编解码器。（例如XviD编码就属于MPEG-4 Part 2）&lt;/p&gt;
&lt;p&gt;第三部分（ISO/IEC 14496-3）：音频：定义一个对各种音频信号进行编码的编解码器的集合。包括高级音频编码（Advanced Audio Coding，缩写为AAC）的若干变形和其他一些音频/语音编码工具(如Audio Lossless Coding,缩写为ALS)。&lt;/p&gt;
&lt;p&gt;第四部分（ISO/IEC 14496-4）：一致性：定义对本标准其他的部分进行一致性测试的程序。&lt;/p&gt;
&lt;p&gt;第五部分（ISO/IEC 14496-5）：参考软件：提供用于演示功能和说明本标准其他部分功能的软件。&lt;/p&gt;
&lt;p&gt;第六部分（ISO/IEC 14496-6）：多媒体传输集成框架（DMIF for Delivery Multimedia Integration Framework）&lt;/p&gt;
&lt;p&gt;第七部分（ISO/IEC 14496-7）：优化的参考软件：提供对实现进行优化的例子（这里的实现指的是第五部分）。&lt;/p&gt;
&lt;p&gt;第八部分（ISO/IEC 14496-8）：在IP网络上传输：定义在IP网络上传输MPEG-4内容的方式。&lt;/p&gt;
&lt;p&gt;第九部分（ISO/IEC 14496-9）：参考硬件：提供用于演示怎样在硬件上实现本标准其他部分功能的硬件设计方案。&lt;/p&gt;
&lt;p&gt;第十部分（ISO/IEC 14496-10）：高级视频编码或称高级视频编码（Advanced Video Coding，缩写为AVC）：定义一个视频编解码器（codec）。AVC和XviD都属于MPEG-4编码，但由于AVC属于MPEG-4 Part 10，在技术特性上比属于MPEG-4 Part2的XviD要先进。另外，它和ITU-T H.264标准是一致的，故又称为H.264。&lt;/p&gt;
&lt;p&gt;第十二部分（ISO/IEC 14496-12）：基于ISO的媒体文件格式：定义一个存储媒体内容的文件格式。&lt;/p&gt;
&lt;p&gt;第十三部分（ISO/IEC 14496-13）：知识产权管理和保护（IPMP for Intellectual Property Management and Protection）拓展。&lt;/p&gt;
&lt;p&gt;第十四部分（ISO/IEC 14496-14）：MPEG-4（即MP4）文件格式：定义基于第十二部分的用于存储MPEG-4内容的视频文档格式。&lt;/p&gt;
&lt;p&gt;第十五部分（ISO/IEC 14496-15）：AVC文件格式：定义基于第十二部分的用于存储第十部分的视频内容的文件格式。&lt;/p&gt;
&lt;p&gt;第十六部分（ISO/IEC 14496-16）：动画框架扩展（AFX : Animation Framework eXtension）。&lt;/p&gt;
&lt;p&gt;第十七部分（ISO/IEC 14496-17）：同步文本字幕格式。&lt;/p&gt;
&lt;p&gt;第十八部分（ISO/IEC 14496-18）：字体压缩和流式传输（针对开放字体格式Open Font Format）。&lt;/p&gt;
&lt;p&gt;第十九部分（ISO/IEC 14496-19）：合成材质流（Synthesized Texture Stream）。&lt;/p&gt;
&lt;p&gt;第二十部分（ISO/IEC 14496-20）：简单场景表示（LASeR for Lightweight Scene Representation。&lt;/p&gt;
&lt;p&gt;第二十一部分（ISO/IEC 14496-21）：用于描绘（Rendering）的MPEG-J拓展。&lt;/p&gt;
&lt;p&gt;第二十二部分（ISO/IEC 14496-22）：开放字体格式（Open Font Format）。&lt;/p&gt;
&lt;p&gt;第二十三部分（ISO/IEC 14496-23）：符号化音乐表示（Symbolic Music Representation）。&lt;/p&gt;
&lt;p&gt;第二十四部分（ISO/IEC 14496-24）：音频与系统交互作用（Audio and systems interaction）。&lt;/p&gt;
&lt;p&gt;第二十五部分（ISO/IEC 14496-25）：3D图形压缩模型（3D Graphics Compression Model）。&lt;/p&gt;
&lt;p&gt;第二十六部分（ISO/IEC 14496-26）：音频一致性检查：定义测试音频数据与ISO/IEC 14496-3是否一致的方法（Audio conformance）。&lt;/p&gt;
&lt;p&gt;第二十七部分（ISO/IEC 14496-27）：3D图形一致性检查：定义测试3D图形数据与ISO/IEC 14496-11:2005, ISO/IEC 14496-16:2006, ISO/IEC 14&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;几个重点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;音视频编码：第二部分（ISO/IEC 14496-2）/第三部分（ISO/IEC 14496-3）（MPEG4 编码）、第十部分（ISO/IEC 14496-10）(H.264)&lt;/li&gt;
&lt;li&gt;网络传输：第八部分（ISO/IEC 14496-8）&lt;/li&gt;
&lt;li&gt;MP4文件格式：第十四部分（ISO/IEC 14496-14）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;141mp4-vs-mpeg-4&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#141mp4-vs-mpeg-4&#34;&gt;
        ##
    &lt;/a&gt;
    1.4.1.MP4 vs MPEG-4
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;MP4或称MPEG-4第14部分（英语：MPEG-4 Part 14）是一种标准的数字多媒体容器格式。MPEG-4第14部分的扩展名为.mp4，以存储数字音频及数字视频为主，但也可以存储字幕和静止图像。因其可容纳支持比特流的视频流（如高级视频编码），为流媒体。&lt;/p&gt;
&lt;p&gt;MPEG-4 是一系列用来定义音频、视频的标准集&lt;/p&gt;
&lt;h2 id=&#34;15视频编码标准的演变&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#15%e8%a7%86%e9%a2%91%e7%bc%96%e7%a0%81%e6%a0%87%e5%87%86%e7%9a%84%e6%bc%94%e5%8f%98&#34;&gt;
        #
    &lt;/a&gt;
    1.5.视频编码标准的演变
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/evolution-of-video-compression-standards.png&#34; alt=&#34;Evolution&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;H.261: 视频电话&lt;/li&gt;
&lt;li&gt;MPEG-1: VCD&lt;/li&gt;
&lt;li&gt;H.262: 数字电视 / DVD&lt;/li&gt;
&lt;li&gt;H.263/H.263+/H.263++：通讯类应用，如视频会议，支持多种网络（PSTN, mobile, LAN/Internet），对丢包/出错场景的兼容性更高&lt;/li&gt;
&lt;li&gt;MPEG-4：基于目标编码，形状编码&lt;/li&gt;
&lt;li&gt;H.264 / AVC Coding：多种使用场景，有线/无线广播、DVD/蓝光存储、视频会议、流式多媒体、多媒体消息（MMS）。因此支持各种读取方式支持顺序/随机，高/低比特率，高/低网络延迟，高/低丢包等情景。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;2h264第十部分isoiec-14496-10&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2h264%e7%ac%ac%e5%8d%81%e9%83%a8%e5%88%86isoiec-14496-10&#34;&gt;
        ##
    &lt;/a&gt;
    2.H.264.第十部分（ISO/IEC 14496-10）
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;21架构&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#21%e6%9e%b6%e6%9e%84&#34;&gt;
        #
    &lt;/a&gt;
    2.1.架构
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/structure-of-h264.png&#34; alt=&#34;structure&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分层设计:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Network Abstraction Layer (NAL)：视频和 metadata 格式化进行各种网络适配&lt;/li&gt;
&lt;li&gt;Video Coding Layer (VCL)：视频编码层&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;主要步骤：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;压缩：预测（帧内预测/帧间预测），DCT转换和量化，比特流编码，结果是编码的 Macroblock&lt;/li&gt;
&lt;li&gt;切分数据：分片，切分&lt;/li&gt;
&lt;li&gt;封装：包装 NAL&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;22-nal&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#22-nal&#34;&gt;
        #
    &lt;/a&gt;
    2.2. NAL
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;主要目标定义如何把视频数据在不同的网络上进行传输&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RTP/IP：互联网广播&lt;/li&gt;
&lt;li&gt;MPEG-2：广播服务流&lt;/li&gt;
&lt;li&gt;ISO 文件：存储应用（光盘）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;NALU 按内容进行分类：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VCL unit：视频图像
&lt;ul&gt;
&lt;li&gt;头信息块（A类）：包括宏块类型，量化参数，运动矢量&lt;/li&gt;
&lt;li&gt;帧内编码信息块（B类）：包含帧内编码宏块类型，帧内编码系数&lt;/li&gt;
&lt;li&gt;帧间编码信息块（C类）：包含帧间编码宏块类型，帧间编码系数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Non-VCL unit：metadata 等信息
&lt;ul&gt;
&lt;li&gt;Parameter sets：被 VCL NAL units 共享的数据头信息
&lt;ul&gt;
&lt;li&gt;picture parameter set (PPS): 图像参数集，PPS对如熵编码类型、有效参考图像的数目、初始化量化参数、去方块滤波系数等解码参数进行标志记录。一个 VCL 包含一个自己的 picture parameter set 指向对应 PPS Non-VCL unit 的指针。&lt;/li&gt;
&lt;li&gt;sequence parameter set (SPS): 序列参数集，SPS对如标识符、帧数以及参考帧数目、解码图像尺寸和帧场模式等解码参数进行标识记录。每个 picture parameter set 指向 sequence parameter set&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Supplemental Enhancement Info (SEI)：用于提高播放质量（rate-distortion等），非必需的，扩展性强（应用程序可扩展）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/PPS-SPS.png&#34; alt=&#34;SPS-PPS&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NALU 传输分类：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于流（stream-oriented）：需要使用 Start Code prefix (00 00 00 01 或 00 00 01)&lt;/li&gt;
&lt;li&gt;基于包（packet-oriented）：不需要使用 Start Code prefix&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;编码：&lt;/strong&gt;
H.264 NALU 单元常由[Start Code] [NALU Header] [NALU Payload] 三部分组成&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start Code: 表示 NALU 开始，必须是 00 00 00 01 或 00 00 01&lt;/li&gt;
&lt;li&gt;NALU Header：1 个字节&lt;/li&gt;
&lt;li&gt;NALU Payload：内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;访问（Access Units）：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一组可以解码成图像的 NALU 被称为 Access Units&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/access-units.png&#34; alt=&#34;access units&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Delimiter: 定位&lt;/li&gt;
&lt;li&gt;SEI：时间和其他信息&lt;/li&gt;
&lt;li&gt;Primary coded picture: VCL&lt;/li&gt;
&lt;li&gt;Redundant coded picture：主码解码错误后进行错误修复&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;23-vcl&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#23-vcl&#34;&gt;
        #
    &lt;/a&gt;
    2.3. VCL
&lt;/div&gt;
&lt;/h2&gt;
&lt;h3 id=&#34;231图像表示方法概念&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#231%e5%9b%be%e5%83%8f%e8%a1%a8%e7%a4%ba%e6%96%b9%e6%b3%95%e6%a6%82%e5%bf%b5&#34;&gt;
        ##
    &lt;/a&gt;
    2.3.1.图像表示方法概念
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/VCL-hierarchy.png&#34; alt=&#34;VCL hierarchy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;宏块 Macroblock(MB):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;亮度宏块（luma）：大小 16x16，1个&lt;/li&gt;
&lt;li&gt;色差宏块（chroma）：大小 8x8，2个，与 primary colors 的色差分量 Cb, Cr。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;片（slice）：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;slice是 一组 MB 构成的集合，一个 slice 可以不需要别的 slice 参与进行独立解码，可以分为以下几类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I-slice: 帧内预测 (I-MB)&lt;/li&gt;
&lt;li&gt;P-slice: 帧间预测 (I- and P-MBs)&lt;/li&gt;
&lt;li&gt;B-slice: 双向帧间预测 (I- and B-MBs)&lt;/li&gt;
&lt;li&gt;SP-slice: 在不同码流间切换&lt;/li&gt;
&lt;li&gt;SI-slice: 与 SP-slice 一起在不同码流间切换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;灵活的宏块顺序 (Flexible Macroblock Order - FMO)：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/flexible-macroblock-ordering.png&#34; alt=&#34;FMO&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 slice 内部 macroblock 按照栅格顺序排列&lt;/li&gt;
&lt;li&gt;slice group：包含一个或多个 slice&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;图像（Picture）:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个图像通常对应一帧(Frame)或两场(Field)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;帧（Frame）:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个帧包含 1 个亮度分量和 2 个色差分量&lt;/p&gt;
&lt;p&gt;分类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I帧(Intra coded frame/关键帧)
&lt;ul&gt;
&lt;li&gt;普通 I 帧：所有 MB 采用帧内预测方式，仅用 I 帧就可以解码出完整图像
&lt;ul&gt;
&lt;li&gt;作为P帧/B帧的参考帧&lt;/li&gt;
&lt;li&gt;可以作为快进/快退的参考点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IDR 帧：立即刷新图像缓冲区，从 IDR 可以重新开始一个序列（Sequence），IDR 之后的 P帧/B帧都不能参考之前的帧
&lt;ul&gt;
&lt;li&gt;主要用于随机播放&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;P帧：前向预测帧间编码帧，参考前面靠近的 I 帧和 P 帧
&lt;ul&gt;
&lt;li&gt;P 帧可以作为后续 P 帧的参考帧（如果中间出现错误会传递扩大）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;B帧：双向预测帧间编码帧，参考前面靠近的 I 帧和 P 帧和后面的 P 帧
&lt;ul&gt;
&lt;li&gt;在更早的标准中（如 MPEG-2）不作为参考帧&lt;/li&gt;
&lt;li&gt;在 H.264 中可以作为参考帧&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SI帧：用于不同编码流之间的切换&lt;/li&gt;
&lt;li&gt;SP帧：用于不同编码流之间的切换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“帧”与“片”与“宏块”&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;帧/片类型&lt;/th&gt;
&lt;th&gt;宏块&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;I frames/slices (Intra)&lt;/td&gt;
&lt;td&gt;I宏块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;P frames/slices (Predicted)&lt;/td&gt;
&lt;td&gt;I宏块、P宏块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;B frames/slices (Bi-Predicted)&lt;/td&gt;
&lt;td&gt;I宏块、B宏块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SI-frames/slices (switching I)&lt;/td&gt;
&lt;td&gt;SI宏块（一种特殊的帧内编码宏块），用于不同编码流之间的切换&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SP-frames/slices (switching P)&lt;/td&gt;
&lt;td&gt;I宏块、P宏块，用于不同编码流之间的切换&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;场/帧场（Field）:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;帧内交替行（奇偶行）的集合，一个帧由顶场(Top Field)/底场(Bottom Field)组成，每个场可以在不同的时间拍摄（Interlaced）&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt; Top field					Top field
 			Bottom field					Bottom field
^                     ^
|       frame         |

          ^                        ^
 			|         frame          |
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Field 编码成 Frame 有几种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;frame mode: 只用单个 frame&lt;/li&gt;
&lt;li&gt;field mode: 2 个 field 组成一个 frame&lt;/li&gt;
&lt;li&gt;mixed mode (adaptive): 自适应的决定使用 frame mode 或 field mode&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自适应 (adaptive mode) 可以分两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PAFF (Picture-Adaptive frame/field)
&lt;ul&gt;
&lt;li&gt;在 frame 级别进行判定使用 frame / field mode&lt;/li&gt;
&lt;li&gt;比使用 frame mode 提高 16-20% 压缩率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MBAFF (Macroblock-adaptive frame/field)
&lt;ul&gt;
&lt;li&gt;在 MB 级别进行判定使用 frame / field mode&lt;/li&gt;
&lt;li&gt;比 PAFF 进一步提高 14-16% 压缩率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**题外话：**过去的阴极射线电视机在帧率接近电影的帧率时图像会过快消失，所以采用隔行扫描形式组成 1 帧，同时可以降低数据带宽。&lt;/p&gt;
&lt;h3 id=&#34;232帧内预测-intra-frame-prediction&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#232%e5%b8%a7%e5%86%85%e9%a2%84%e6%b5%8b-intra-frame-prediction&#34;&gt;
        ##
    &lt;/a&gt;
    2.3.2.帧内预测 (Intra-frame Prediction)
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;使用一个 MB 左边及上边的 MB 进行预测。&lt;/p&gt;
&lt;p&gt;预测类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intra_4x4: detailed luma blocks&lt;/li&gt;
&lt;li&gt;Intra_16x16: smoothed luma blocks&lt;/li&gt;
&lt;li&gt;Chroma_8x8: 色差比较平滑&lt;/li&gt;
&lt;li&gt;I_PCM: 忽略 prediction/transform，适用于不规则的图像、或者无损的图像、或者需要进行确定性 bit-rate 的场景&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2321intra_4x4&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2321intra_4x4&#34;&gt;
        ###
    &lt;/a&gt;
    2.3.2.1.Intra_4x4
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/intra-4x4.png&#34; alt=&#34;Intra_4x4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预测模式：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 个 DC 模式&lt;/li&gt;
&lt;li&gt;8 个方向模式&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2322intra_16x16&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2322intra_16x16&#34;&gt;
        ###
    &lt;/a&gt;
    2.3.2.2.Intra_16x16
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/intra-16x16.png&#34; alt=&#34;Intra_16x16&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预测模式：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vertical&lt;/li&gt;
&lt;li&gt;Horizontal&lt;/li&gt;
&lt;li&gt;DC&lt;/li&gt;
&lt;li&gt;Planar (Diagonal)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;233inter-prediction-in-p-slices&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#233inter-prediction-in-p-slices&#34;&gt;
        ##
    &lt;/a&gt;
    2.3.3.Inter-Prediction in P slices
&lt;/div&gt;
&lt;/h3&gt;
&lt;h4 id=&#34;2331切分-mb&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#2331%e5%88%87%e5%88%86-mb&#34;&gt;
        ###
    &lt;/a&gt;
    2.3.3.1.切分 MB
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/inter-prediction-P-slice.png&#34; alt=&#34;segmentation&#34;&gt;&lt;/p&gt;
&lt;p&gt;按照亮度和色差切分&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/segmentation-example.png&#34; alt=&#34;segmentation example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;234multiframe-inter-prediction-in-b-slices&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#234multiframe-inter-prediction-in-b-slices&#34;&gt;
        ##
    &lt;/a&gt;
    2.3.4.Multiframe Inter-Prediction in B slices
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/inter-prediction-B-slice.png&#34; alt=&#34;B slices&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;24码流结构&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#24%e7%a0%81%e6%b5%81%e7%bb%93%e6%9e%84&#34;&gt;
        #
    &lt;/a&gt;
    2.4.码流结构
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/nal-structure.png&#34; alt=&#34;structure&#34;&gt;&lt;/p&gt;
&lt;p&gt;经过 VCL 编码后生成的 NALU 原始数据会被分包，因为 NALU 的 Start Code 是 00 00 00 01 或 00 00 01，因此在 NALU 数据中也可能存在冲突，解决办法是引入 EBSP&lt;/p&gt;
&lt;p&gt;几个概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SODB：String of Data Bits，原始数据比特流，是最原始的编码压缩后的数据&lt;/li&gt;
&lt;li&gt;RBSP：Raw Byte Sequence Payload，原始字节序列载荷，对 SODB 进行 8 位补齐
&lt;ul&gt;
&lt;li&gt;RBSP = SODB + RBSP Trailing Bits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;EBSP：Encapsulated Byte Sequence Payload，扩展字节序列载荷，在 RBSP 中引入防竞争字节（0x03），在 RBSP 中如果出现了连续两个 00 字节，就在后面添加一个防竞争字节（0x03）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/payload-encoding.png&#34; alt=&#34;payload encoding&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;25profiles-and-applications&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#25profiles-and-applications&#34;&gt;
        #
    &lt;/a&gt;
    2.5.Profiles and Applications
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/profiles-applications.png&#34; alt=&#34;profiles &amp;amp; applications&#34;&gt;&lt;/p&gt;
&lt;p&gt;主要目的是定义编码工具和算法&lt;/p&gt;
&lt;p&gt;3 个 Profile:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Baseline: 主要用于视频会议&lt;/li&gt;
&lt;li&gt;Main: 广播、媒体存储、数字影院&lt;/li&gt;
&lt;li&gt;Extended: IP 网络流媒体&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;3网络传输-第八部分isoiec-14496-8&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#3%e7%bd%91%e7%bb%9c%e4%bc%a0%e8%be%93-%e7%ac%ac%e5%85%ab%e9%83%a8%e5%88%86isoiec-14496-8&#34;&gt;
        ##
    &lt;/a&gt;
    3.网络传输: 第八部分（ISO/IEC 14496-8）
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;这个标准定义了以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 IP 网络上传输 ISO/IEC 14496 内容的框架&lt;/li&gt;
&lt;li&gt;在 RTP 中分片/组装负载的指导方法&lt;/li&gt;
&lt;li&gt;使用 SDP (Session description protocol) 传输 ISO/IEC 14496-1 内容&lt;/li&gt;
&lt;li&gt;ISO/IEC14496 相关的 MIME type&lt;/li&gt;
&lt;li&gt;RTP 安全和多播&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;31-rtp&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#31-rtp&#34;&gt;
        #
    &lt;/a&gt;
    3.1. RTP
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;RTP 负载分片/组装规则&lt;/p&gt;
&lt;h3 id=&#34;311-rtp-传输-h264&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#311-rtp-%e4%bc%a0%e8%be%93-h264&#34;&gt;
        ##
    &lt;/a&gt;
    3.1.1. RTP 传输 H.264
&lt;/div&gt;
&lt;/h3&gt;
&lt;h4 id=&#34;h264-nalu&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#h264-nalu&#34;&gt;
        ###
    &lt;/a&gt;
    H.264 NALU
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;H.264 NALU 单元常由[Start Code] [NALU Header] [NALU Payload] 三部分组成&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start Code: 表示 NALU 开始，必须是 00 00 00 01 或 00 00 01&lt;/li&gt;
&lt;li&gt;NALU Header：1 个字节&lt;/li&gt;
&lt;li&gt;NALU Payload：内容&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;nalu-header--payload&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#nalu-header--payload&#34;&gt;
        ####
    &lt;/a&gt;
    NALU (Header + Payload)
&lt;/div&gt;
&lt;/h5&gt;
&lt;p&gt;一个 NALU 的封装形式如下，包含了 NALU Header 及 NALU Payload&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;   0                   1                   2                   3
   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |F|NRI|  type   |                                               |
  +-+-+-+-+-+-+-+-+                                               |
  |                                                               |
  |               Bytes 2..n of a Single NAL unit                 |
  |                                                               |
  |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                               :...OPTIONAL RTP padding        |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;h5 id=&#34;nalu-header&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#nalu-header&#34;&gt;
        ####
    &lt;/a&gt;
    NALU Header：
&lt;/div&gt;
&lt;/h5&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+---------------+
|0|1|2|3|4|5|6|7|
+-+-+-+-+-+-+-+-+
|F|NRI|  Type   |
+---------------+
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;F: 1 bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;forbidden_zero_bit，h264语法规定值为0。rtp封包中，当检测到值为1时，则表示该nalu中已出现错误。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;NRI: 2 bits
nal_ref_idc, 参考级别，当值为00时，表示后面的负载可以丢弃，并不会影响正常解码，当大于00时后面的该包丢弃会影响解码，不可丢弃。rtp封包中，该值也表示该数据包的重要性，11为重要性最高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Type: 5 bits&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;nal_unit_type，nalu的类型，h264文档中定义为&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;nal_unit_type&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;未定义&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;非IDR图像中不采用数据划分的片段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;非IDR图像中A类数据划分片段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;非IDR图像中B类数据划分片段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;非IDR图像中C类数据划分片段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;IDR图像的片段&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;补充增强信息 (SEI)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;序列参数集/SPS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;图像参数集/PPS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;分割符&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;序列结束符&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;流结束符&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;填充数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;13 – 23&lt;/td&gt;
&lt;td&gt;保留&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24 – 31&lt;/td&gt;
&lt;td&gt;未定义&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;1-23 是 H.264 的标准定义，24 以后 RTP 进行了专有扩展&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      Type   Packet    Single NAL    Non-Interleaved    Interleaved
                       Unit Mode           Mode             Mode
      -------------------------------------------------------------

      0      undefined     ig               ig               ig
      1-23   NAL unit     yes              yes               no
      24     STAP-A        no              yes               no
      25     STAP-B        no               no              yes
      26     MTAP16        no               no              yes
      27     MTAP24        no               no              yes
      28     FU-A          no              yes              yes
      29     FU-B          no               no              yes
      30-31  undefined     ig               ig               ig
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1-23 单一时间数据包 (Single NAL unit packet)，一个rtp包中只包含一个nalu。&lt;/p&gt;
&lt;p&gt;24-25 单一时间组合包(Aggregation packet)，一个rtp包含多个同一时间nalu。&lt;/p&gt;
&lt;p&gt;26-27 多时间组合包(Aggregation packet)，一个rtp包含多个时间片的多个nalu。&lt;/p&gt;
&lt;p&gt;28-29 分片组合(Fragmentation unit)，多个rtp包才能组合成一个完整的nalu。&lt;/p&gt;
&lt;p&gt;#####打包封装:&lt;/p&gt;
&lt;p&gt;使用 RTP 打包时会用 RTP 头替换掉 NALU 中开始的 Start Code (00 00 00 01 或 00 00 01)&lt;/p&gt;
&lt;p&gt;打包举例，对于如下 NALU&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[00 00 00 01 67 42 A0 1E 23 56 0E 2F … ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用 RTP 打包成下面的内容：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[RTP Header] [67 42 A0 1E 23 56 0E 2F … ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Single NAL unit packet：可以在一个网络包中传输整个 NALU&lt;/li&gt;
&lt;li&gt;Aggregation packet：可以在一个网络包中传输多个 NALU，又可以分为“单一时间组合包”和“多时间组合包”&lt;/li&gt;
&lt;li&gt;Fragmentation unit：无法在一个网络包中传输整个 NALU，可以理解成一个 NALU 长度超过 MTU 减去各种协议头（UDP/TCP/IP/RTP）的长度，需要把一个 NALU 拆分成多个 NAL&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;单一时间数据包：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当nalu较小，一个rtp包即可传输时，可在单个rtp包中只包含一个nalu，进行发送。&lt;/p&gt;
&lt;p&gt;一个rtp中只包含一个nalu，rtp的负载如下&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |F|NRI|  type   |                                               |
      +-+-+-+-+-+-+-+-+                                               |
      |                                                               |
      |               Bytes 2..n of a Single NAL unit                 |
      |                                                               |
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;单一时间组合包：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;nalu较小的情况下，在同一时刻生成了多个nalu，可以使用该打包方式，将多个nalu封装在一个包中。webrtc中sps和pps通常打包在同一个rtp中。&lt;/p&gt;
&lt;p&gt;STAP-A 封装格式&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |STAP-A NAL HDR |         NALU 1 Size           | NALU 1 HDR    |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                         NALU 1 Data                           |
      :                                                               :
      +               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |               | NALU 2 Size                   | NALU 2 HDR    |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                         NALU 2 Data                           |
      :                                                               :
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;STAP-A NAL HDR 中 nalu type取值为24。&lt;/p&gt;
&lt;p&gt;相对于单一数据包中，多了一个 NALU Size 字段，表示每个nalu的长度。&lt;/p&gt;
&lt;p&gt;STAP-B 封装格式&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |STAP-B NAL HDR | DON                           | NALU 1 Size   |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      | NALU 1 Size   | NALU 1 HDR    | NALU 1 Data                   |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               +
      :                                                               :
      +               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |               | NALU 2 Size                   | NALU 2 HDR    |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                       NALU 2 Data                             |
      :                                                               :
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;STAP-B NAL HDR 中 nalu type取值为25。&lt;/p&gt;
&lt;p&gt;相对于STAP-A多了一个DON (decoding order number)字段，既解码顺序，而后续的每个nalu的解码顺序为DON累加1，既nalu 1 解码顺序为DON,而NALU2 为DON+1,NALU3 为(DON +1)+1，以此类推。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多时间组合包：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;nalu较小的情况下，在一个rtp包中封装多个不同时间戳的nalu。&lt;/p&gt;
&lt;p&gt;MTAP16&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |MTAP16 NAL HDR |  decoding order number base   | NALU 1 Size   |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |  NALU 1 Size  |  NALU 1 DOND  |       NALU 1 TS offset        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |  NALU 1 HDR   |  NALU 1 DATA                                  |
      +-+-+-+-+-+-+-+-+                                               +
      :                                                               :
      +               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |               | NALU 2 SIZE                   |  NALU 2 DOND  |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |       NALU 2 TS offset        |  NALU 2 HDR   |  NALU 2 DATA  |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+               |
      :                                                               :
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MTAP16 NAL HDR 中 nalu type取值为26。&lt;/p&gt;
&lt;p&gt;DONB(decoding order number base)表示解码顺序的基数值，DOND 表示与DONB的偏移值。&lt;/p&gt;
&lt;p&gt;NALU TS offset ，为nalu原始时间戳与 rtp包头中的timestap的偏移值。&lt;/p&gt;
&lt;p&gt;MTAP24&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |MTAP24 NAL HDR |  decoding order number base   | NALU 1 Size   |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |  NALU 1 Size  |  NALU 1 DOND  |       NALU 1 TS offs          |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |NALU 1 TS offs |  NALU 1 HDR   |  NALU 1 DATA                  |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               +
      :                                                               :
      +               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |               | NALU 2 SIZE                   |  NALU 2 DOND  |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |       NALU 2 TS offset                        |  NALU 2 HDR   |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |  NALU 2 DATA                                                  |
      :                                                               :
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MTAP24 NAL HDR 中 nalu type取值为27。&lt;/p&gt;
&lt;p&gt;MATP16与 MTAP24 的区别在于NALU TS offset 值存放空间不同，前者为16bit，而后者为24bit。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分片组合：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当使用udp传输rtp包时，由于一个udp的荷载最大为1480个字节，当一个nalu大于1480时，就需要将一个nalu分割为多个rtp包进行传输，具体的分割方式有以下两种。&lt;/p&gt;
&lt;p&gt;FU-A&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      | FU indicator  |   FU header   |                               |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               |
      |                                                               |
      |                         FU payload                            |
      |                                                               |
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;FU-B&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      | FU indicator  |   FU header   |               DON             |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-|
      |                                                               |
      |                         FU payload                            |
      |                                                               |
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中 FU indicator&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      +---------------+
      |0|1|2|3|4|5|6|7|
      +-+-+-+-+-+-+-+-+
      |F|NRI|  Type   |
      +---------------+
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;F: 1 bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;forbidden_zero_bit，h264语法规定值为0。rtp封包中，当检测到值为1时，则表示该nalu中已出现错误。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NRI: 2 bits&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;nal_ref_idc, 当值为00时，表示后面的负载可以丢弃，并不会影响正常解码，当大于00时后面的该包丢弃会影响解码，不可丢弃。rtp封包中，该值也表示该数据包的重要性，11为重要性最高。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type: 5bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;rtp包中nalu type，可取值为28(FU-A)，29(FU-B)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FU header&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      +---------------+
      |0|1|2|3|4|5|6|7|
      +-+-+-+-+-+-+-+-+
      |S|E|R|  Type   |
      +---------------+
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;S: 1 bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;值为1表示该rtp包为nalu的开始。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;E: 1 bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;值为1表示该rtp包为nalu的结束。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R: 1 bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;保留字段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type: 5bit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表示h264中的nalu type 可取值1-23。&lt;/p&gt;
&lt;p&gt;从分片恢复 NALU header:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;nal_unit_type = (fu_indicator &amp;amp; 0xe0) | (fu_header &amp;amp; 0x1f)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;一个全局的 NAL RTP 打包结构图如下：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/NAL-RTP.png&#34; alt=&#34;NAL-RTP&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NALU：主体数据打包进 RTP&lt;/li&gt;
&lt;li&gt;Slice Header: 包含分片类型、分片中的宏块类型、分片帧的数量以及对应的帧的设置和参数等信息&lt;/li&gt;
&lt;li&gt;Slice Data: 宏块信息&lt;/li&gt;
&lt;li&gt;宏块：宏块类型、预测类型、Coded Block Pattern、Quantization Parameter、像素的亮度和色度数据集等等信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;32sdp-isoiec-14496-1&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#32sdp-isoiec-14496-1&#34;&gt;
        #
    &lt;/a&gt;
    3.2.SDP (ISO/IEC 14496-1)
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;使用 SDP 传输 ISO/IEC 14496-1 定义的内容&lt;/p&gt;
&lt;h2 id=&#34;33mime-type&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#33mime-type&#34;&gt;
        #
    &lt;/a&gt;
    3.3.MIME type
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;互联网媒体类型 (Internet media type，也称为 MIME type），给互联网上传输的内容进行分类。&lt;/p&gt;
&lt;p&gt;MIME type 格式为：&amp;lt;类型&amp;gt;/&amp;lt;子类型&amp;gt;; [可选参数]&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;text/html; charset = UTF-8

video/mp4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以下是常用的视频类 MIME type：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;video/mpeg：MPEG-1视频文件&lt;/p&gt;
&lt;p&gt;video/mp4：MP4视频文件&lt;/p&gt;
&lt;p&gt;video/ogg：Ogg视频文件&lt;/p&gt;
&lt;p&gt;video/quicktime：QuickTime视频文件&lt;/p&gt;
&lt;p&gt;video/webm：WebM视频文件（基于Matroska基础）&lt;/p&gt;
&lt;p&gt;video/x-matroska：Matroska（多媒体封装格式）&lt;/p&gt;
&lt;p&gt;video/x-ms-wmv：Windows Media Video视频文件&lt;/p&gt;
&lt;p&gt;video/x-flv：Flash Video（FLV档）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;4mp4-第十四部分isoiec-14496-14&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#4mp4-%e7%ac%ac%e5%8d%81%e5%9b%9b%e9%83%a8%e5%88%86isoiec-14496-14&#34;&gt;
        ##
    &lt;/a&gt;
    4.MP4: 第十四部分（ISO/IEC 14496-14）
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;MP4 文件由可以嵌套的 box 组成，每个 box 有 header 和 data，header 定义 box 的类型和大小，data 包含数据或者子 box。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/mp4-box.png&#34; alt=&#34;mp4 box&#34;&gt;&lt;/p&gt;
&lt;p&gt;一个典型的视频文件格式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/CV/video-media-container/mp4-file-format.png&#34; alt=&#34;mp4 file format&#34;&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;th&gt;5&lt;/th&gt;
&lt;th&gt;6&lt;/th&gt;
&lt;th&gt;7&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ftyp&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;描述文件类型、版本等信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mdat&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;Media Data 媒体数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;嵌套 box&lt;/td&gt;
&lt;td&gt;Movie box，用来存放每个媒体轨道的描述信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;mvhd&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;Movie Header box，记录整个媒体文件信息，如创建时间、修改时间、时间度量标尺、时长等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;udta&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;嵌套 box&lt;/td&gt;
&lt;td&gt;User Data box，用户自定义信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;嵌套 box&lt;/td&gt;
&lt;td&gt;Track box，记录每个轨道的信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;tkhd&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;Track Header box，轨道的头信息，如创建/修改时间、时长、画面宽度/高度等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;嵌套 box&lt;/td&gt;
&lt;td&gt;Media box，媒体信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;mdhd&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;Media Header box，记录创建时间、时长等信息，&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;hdlr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;Handler Reference box，媒体播放过程信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;嵌套 box&lt;/td&gt;
&lt;td&gt;Media Information box&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;vmhd&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;视频媒体头信息，smhd：针对音频&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;嵌套 box&lt;/td&gt;
&lt;td&gt;Sample Table box，媒体数据的索引信息，找到视频的帧数据可以从这里获取&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;stsd&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;嵌套 box&lt;/td&gt;
&lt;td&gt;sample description, 给出视频、音频的编码、宽高、音量等信息，以及每个sample中包含多少个frame&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;stco&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;chunk offset, chunk（一个chunk 包含多个 sample，一个 sample 对应一帧） 在文件中的偏移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;stsc&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;sample-to-chunk, chunk 中包含 sample 的数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;stsz&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;sample size, 每个 sample 的 size 信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;stts&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;time-to-sample，时间戳到 sample 的映射，每个 sample 的时长&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;stss&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;sync sampel table, 可以随机访问的 sample 列表（记录哪些 sample 是关键帧）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;moov&lt;/td&gt;
&lt;td&gt;trak&lt;/td&gt;
&lt;td&gt;mdia&lt;/td&gt;
&lt;td&gt;minf&lt;/td&gt;
&lt;td&gt;stbl&lt;/td&gt;
&lt;td&gt;ctts&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;数据 box&lt;/td&gt;
&lt;td&gt;帧解码到渲染的时间差，针对 B 帧&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;5其他&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#5%e5%85%b6%e4%bb%96&#34;&gt;
        ##
    &lt;/a&gt;
    5.其他
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;51mpeg-7&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#51mpeg-7&#34;&gt;
        #
    &lt;/a&gt;
    5.1.MPEG-7
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;来自 wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MPEG-7并不是一个视频压缩标准，它是一个多媒体内容的描述标准。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;来自 mpeg.org:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ISO/IEC 15938
Multimedia content description interface&lt;/p&gt;
&lt;p&gt;A suite of standards for description and search of audio, visual and multimedia content&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;52mpeg-21&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#52mpeg-21&#34;&gt;
        #
    &lt;/a&gt;
    5.2.MPEG-21
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;来自 wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MPEG-21标准的正式名称为“多媒体框架”,它致力于为多媒体传输和使用定义一个标准化的、可互操作的和高度自动化的开放框架，这个框架考虑到了对象化的多媒体接入以及使用不同的网络和终端进行传输等问题。 MPEG-21标准将各种不同协议、标准和技术融合在一起，透过这种统一环境对全球媒体资源进行统一和管理，进而完整著作权保护、用户隐私权保护、终端和网络资源撷取及事件报告等功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;来自 mpeg.org:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ISO/IEC 21000
Multimedia framework&lt;/p&gt;
&lt;p&gt;A suite of standard that define a normative open framework for end-to-end multimedia creation, delivery and consumption that provides content creators, producers, distributors and service providers with equal opportunities in the MPEG-21 enabled open market, and also be to the benefit of the content consumers providing them access to a large variety of content in an interoperable manner.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;6参考资料&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#6%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99&#34;&gt;
        ##
    &lt;/a&gt;
    6.参考资料
&lt;/div&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/MPEG-1&#34;&gt;https://zh.wikipedia.org/wiki/MPEG-1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/MPEG-2&#34;&gt;https://zh.wikipedia.org/wiki/MPEG-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/MPEG-3&#34;&gt;https://zh.wikipedia.org/wiki/MPEG-3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/MPEG-4&#34;&gt;https://zh.wikipedia.org/wiki/MPEG-4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mpeg.org/standards/MPEG-7/&#34;&gt;https://www.mpeg.org/standards/MPEG-7/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mpeg.org/standards/MPEG-21/&#34;&gt;https://www.mpeg.org/standards/MPEG-21/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%AA%92%E4%BD%93%E7%B1%BB%E5%9E%8B&#34;&gt;https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%AA%92%E4%BD%93%E7%B1%BB%E5%9E%8B&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://juejin.cn/post/6844904083904528392#heading-1&#34;&gt;https://juejin.cn/post/6844904083904528392#heading-1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://slideplayer.com/slide/2409533/&#34;&gt;https://slideplayer.com/slide/2409533/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/402346767&#34;&gt;https://zhuanlan.zhihu.com/p/402346767&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/yinxiangpei/articles/2821954.html&#34;&gt;https://www.cnblogs.com/yinxiangpei/articles/2821954.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/355803589&#34;&gt;https://zhuanlan.zhihu.com/p/355803589&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>摄像机模型及实现</title>
      <link>/2022/05/%E6%91%84%E5%83%8F%E6%9C%BA%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 07 May 2022 01:05:50 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2022/05/%E6%91%84%E5%83%8F%E6%9C%BA%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AE%9E%E7%8E%B0/</guid>
      <description>&lt;!--toc--&gt;
&lt;p&gt;3D 设计软件和游戏中的图像经常是以一个观测者的角度展示的，可以把这个过程想象成一个人拿着一台摄像机在拍摄，在机器视觉中叫摄像机模型。&lt;/p&gt;
&lt;p&gt;研究过程中基于 OpenCV 做了一个简单实现，项目代码可以在这里下载到 &lt;a href=&#34;https://github.com/singleye/camera-model&#34;&gt;“github 代码下载”&lt;/a&gt;，欢迎大家下载交流。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://www.singleye.net/media/2022/05/camera-model-1.png&#34; alt=&#34;camera&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;摄像机模型的数学模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%91%84%e5%83%8f%e6%9c%ba%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%95%b0%e5%ad%a6%e6%a8%a1%e5%9e%8b&#34;&gt;
        ##
    &lt;/a&gt;
    摄像机模型的数学模型
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;座标系&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ba%a7%e6%a0%87%e7%b3%bb&#34;&gt;
        #
    &lt;/a&gt;
    座标系
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;理解摄像机模型需要建立对应的座标系，在这个模型里面涉及到了下面 3 个座标系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;世界座标系 (World frame)&lt;/p&gt;
&lt;p&gt;被观测目标存在于世界座标系中，使用世界座标系座标表示位置，是个 3 维座标系，可以使用常用的单位，比如‘米’。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;相机座标系 (Camera frame)&lt;/p&gt;
&lt;p&gt;通常使用摄像机的光学中心为原点，是一个 3 维座标系，表示从相机的光学中心原点来衡量各个目标的位置，尺度可以保持和世界座标系统一，比如都使用‘米’；相机可以移动到世界座标系中的任意位置和任意角度（姿态）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;像平面座标系 (Image plane frame)&lt;/p&gt;
&lt;p&gt;这是最终观测的图像座标系，是一个 3 维座标系，在相机中是 CCD 的座标系，例如以左上角为原点，尺度为‘像素’。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://www.singleye.net/media/2022/05/camera-model-2.png&#34; alt=&#34;coordinate&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;座标转换&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ba%a7%e6%a0%87%e8%bd%ac%e6%8d%a2&#34;&gt;
        #
    &lt;/a&gt;
    座标转换
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;当移动摄像机时，摄像机成像的结果可以通过座标转换来完成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把世界座标系中的物体座标进行&amp;rsquo;座标系变换&amp;rsquo;，转换成相机座标系中的座标&lt;/li&gt;
&lt;li&gt;通过相机内参转换到像平面座标系&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;座标系变换过程&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ba%a7%e6%a0%87%e7%b3%bb%e5%8f%98%e6%8d%a2%e8%bf%87%e7%a8%8b&#34;&gt;
        ##
    &lt;/a&gt;
    座标系变换过程
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;世界座标 $O_w$ 用下面形式表示:&lt;/p&gt;
$$
\left(
	\begin{matrix}
		X_w \\
		Y_w \\
		Z_w
	\end{matrix}
\right)
$$
&lt;p&gt;摄像机在世界座标系中被移动到 $t$ 位置：&lt;/p&gt;
$$
\left(
	\begin{matrix}
		x_t \\
		y_t \\
		z_t
	\end{matrix}
\right)
$$
&lt;p&gt;&lt;strong&gt;第一步&lt;/strong&gt;：先抵消掉摄像机的空间移动 $t$，也就是 $O_w - t$。这一步后新的座标系与摄像机座标系原点重叠。&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		O_w - t
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		X_w - t_x \\\
		Y_w - t_y \\\
		Z_w - t_z
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://www.singleye.net/media/2022/05/camera-model-3.png&#34; alt=&#34;Step1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二步&lt;/strong&gt;：旋转座标系第一步后的新座标系到摄像机座标座标系，旋转矩阵 $R$ ，关于座标旋转参见&lt;a href=&#34;http://www.singleye.net/2021/01/%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5/&#34;&gt;旋转矩阵&lt;/a&gt;，完成旋转后得到了摄像机座标系下的座标 $O_c$&lt;/p&gt;
&lt;div&gt;
$$
O_c =
R*
\left(
		O_w - t
\right)=
R*
\left(
	\begin{matrix}
		X_w - t_x \\\
		Y_w - t_y \\\
		Z_w - t_z
	\end{matrix}
\right)
=
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://www.singleye.net/media/2022/05/camera-model-4.png&#34; alt=&#34;Step2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;相机座标转化到像平面座标&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%9b%b8%e6%9c%ba%e5%ba%a7%e6%a0%87%e8%bd%ac%e5%8c%96%e5%88%b0%e5%83%8f%e5%b9%b3%e9%9d%a2%e5%ba%a7%e6%a0%87&#34;&gt;
        ##
    &lt;/a&gt;
    相机座标转化到像平面座标
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;先看一下小孔成像模型，使用虚拟像平面可以把座标转换简化。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://www.singleye.net/media/2022/05/camera-model-6.png&#34; alt=&#34;虚拟像平面&#34;&gt;&lt;/p&gt;
&lt;p&gt;简化后的模型如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://www.singleye.net/media/2022/05/camera-model-5.png&#34; alt=&#34;Step3&#34;&gt;&lt;/p&gt;
&lt;p&gt;摄像机座标系与虚拟像平面交于点 $(x_o, y_o)$，摄像机座标系下的点 $O_c$ 在虚拟像平面上的投影点是 $(x&amp;rsquo;, y&amp;rsquo;)$&lt;/p&gt;
&lt;p&gt;通过相似三角形可以容易得到：$ x&amp;rsquo; \over X_c $ = $ y&amp;rsquo; \over Y_c $ = $ f \over Z_c $，也就是：&lt;/p&gt;
$$ x‘ = f \frac {X_c} {Z_c} $$
$$ y’ = f \frac {Y_c} {Z_c} $$
$$ z‘ = f \frac {Z_c} {Z_c} $$
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x&#39; \\\
		y&#39; \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;在摄像机虚拟像平面座标系下（左上角为原点，像素为单位），摄像机座标系与虚拟像平面的交点像素座标为 $(x_o, y_o)$，摄像机座标系下的点 $O_c$ 在虚拟像平面上投影点像素级座标是 $(x, y)$，摄像机 CCD 的像素点在 x 和 y 轴方向上的排列密度为 $\sigma_x$ （单位：pixels/meter）和 $\sigma_y$ （单位：pixels/meter），那么：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x&#39; \\\
		y&#39; \\\
		f
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		\frac {x - x_o} {\sigma_x} \\\
		\frac {y - x_o} {\sigma_y} \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;中间式子可以写成下面形式：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		\frac {x - x_o} {\sigma_x} \\\
		\frac {y - x_o} {\sigma_y} \\\
		f
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		\frac 1 {\sigma_x}		&amp;	0	&amp;	0 \\\
		0	&amp;	\frac 1 {\sigma_y}	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		x - x_o \\\
		y - y_o \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;通过逆矩阵运算得到：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x - x_o \\\
		y - y_o \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		\sigma_x		&amp;	0	&amp;	0 \\\
		0	&amp;	\sigma_y	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;再把第一个矩阵拆成下面的形式：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x - x_o \\\
		y - y_o \\\
		f
	\end{matrix}
\right)=
\left(
	\begin{matrix}
		1	&amp;	0	&amp;	-\frac {x_o} f 	\\\
		0	&amp;	1	&amp;	-\frac {y_o} f	\\\
		0	&amp;	0	&amp;	1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		x \\\
		y \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		\sigma_x		&amp;	0	&amp;	0 \\\
		0	&amp;	\sigma_y	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;再做矩阵逆运算得到：&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x \\\
		y \\\
		f
	\end{matrix}
\right)=
f/Z
\left(
	\begin{matrix}
		1	&amp;	0	&amp;	\frac {x_o} f 	\\\
		0	&amp;	1	&amp;	\frac {y_o} f	\\\
		0	&amp;	0	&amp;	1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		\sigma_x		&amp;	0	&amp;	0 \\\
		0	&amp;	\sigma_y	&amp;	0 \\\
		0	&amp;	0				&amp;		1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)=
1/Z
\left(
	\begin{matrix}
		f \sigma_x	&amp;	0				&amp;	x_o \\\
		0				&amp;	f \sigma_y	&amp;	y_o \\\
		0				&amp;	0				&amp;	1
	\end{matrix}
\right)
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;h2 id=&#34;摄像机数学模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e6%91%84%e5%83%8f%e6%9c%ba%e6%95%b0%e5%ad%a6%e6%a8%a1%e5%9e%8b&#34;&gt;
        #
    &lt;/a&gt;
    摄像机数学模型
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;现在已经有了一个摄像机的数学模型：&lt;/p&gt;
&lt;p&gt;**第一步：**把观察目标从世界坐标旋转到摄像机坐标&lt;/p&gt;
&lt;div&gt;
$$
O_c =
R*
\left(
		O_w - t
\right)=
R*
\left(
	\begin{matrix}
		X_w - t_x \\\
		Y_w - t_y \\\
		Z_w - t_z
	\end{matrix}
\right)
=
\left(
	\begin{matrix}
		X_c \\\
		Y_c \\\
		Z_c
	\end{matrix}
\right)
$$
&lt;/div&gt;
&lt;p&gt;**第二步：**把摄像机坐标转换到摄像机虚拟像平面像素坐标&lt;/p&gt;
&lt;div&gt;
$$
\left(
	\begin{matrix}
		x \\\
		y \\\
		f
	\end{matrix}
\right)=
&lt;p&gt;1/Z
\left(
\begin{matrix}
f \sigma_x	&amp;amp;	0				&amp;amp;	x_o \\
0				&amp;amp;	f \sigma_y	&amp;amp;	y_o \\
0				&amp;amp;	0				&amp;amp;	1
\end{matrix}
\right)
\left(
\begin{matrix}
X_c \\
Y_c \\
Z_c
\end{matrix}
\right)
$$&lt;/p&gt;
&lt;/div&gt;
&lt;h1 id=&#34;实现一个摄像机模型&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%ae%9e%e7%8e%b0%e4%b8%80%e4%b8%aa%e6%91%84%e5%83%8f%e6%9c%ba%e6%a8%a1%e5%9e%8b&#34;&gt;
        ##
    &lt;/a&gt;
    实现一个摄像机模型
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;**第一步：**世界坐标系到相机坐标系转换&lt;/p&gt;
&lt;p&gt;根据摄像机旋转角度计算出旋转矩阵 R：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      def rotate(self, roll, pitch, yaw):
          &amp;#39;&amp;#39;&amp;#39;
          Rotate camera by roll, pitch, yaw
          &amp;#39;&amp;#39;&amp;#39;
          rx, _ = cv2.Rodrigues((pitch, 0, 0))
 Rodrigues(src, dst=None, jacobian=None, /) -&amp;gt; dst, jacobian                                                                            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;被观测物体的世界坐标转换到相机坐标：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      def trans_to_cam(self, v):
          &amp;#39;&amp;#39;&amp;#39;
          Transform the world coordinate vertices to camera coordinate vertices
              v: vertices in world coordinate frame
          &amp;#39;&amp;#39;&amp;#39;
          vc = np.dot(self.R, (v.T - np.array([[self._x], [self._y], [self._z]])))
          return vc.T
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;**第二步：**把相机坐标投影到相机虚拟像平面上&lt;/p&gt;
&lt;p&gt;定义相机内参：包括焦距、CCD像素密度参数，写出相机内参矩阵&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;          # camera focus length in meter
          self._f = 1

          # scale factor: pixels/meter
          self._s = 800
          
          # camera intrinsic matrix
          self.intrinsic = np.array([[self._f*self._s,    0,                  self._canvas_width/2.0],
                                     [0,                  self._f*self._s,    self._canvas_height/2.0],
                                     [0,                  0,                  1]])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;进行投影转换计算。**注：**由于程序实现时世界/相机坐标系采用的是右手Z轴向前的形式，因此计算结果多了一步转换的运算。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      def project(self, v):
          &amp;#39;&amp;#39;&amp;#39;
          Project the vertices of camera coordinate to camera image plane coordinate
              v: vertices in camera coordinate frame
                  u = width - f*(Y/X)
                  v = height - f*(Z/X)
          &amp;#39;&amp;#39;&amp;#39;
          Z = np.expand_dims(v[:, -1], axis=1)
          proj_v = np.dot(self.intrinsic, v.T) / Z
          proj_v = proj_v.T
          proj_v[:, 0:2] = [self._canvas_width, self._canvas_height] - proj_v[:, 0:2]
          return proj_v[:, :2]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Demo：&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&#34;video_container&#34;&gt;
  &lt;video controls=&#34;true&#34; allowfullscreen=&#34;true&#34; poster=&#34;https://raw.githubusercontent.com/singleye/camera-model/master/examples/camera-model-1.png&#34; width=&#34;400&#34; height=&#34;300&#34;&gt;
    &lt;source src=&#34;https://raw.githubusercontent.com/singleye/camera-model/master/examples/demo.m4v&#34; type=&#34;video/mp4&#34;&gt;
  &lt;/video&gt;
&lt;/figure&gt;
&lt;h1 id=&#34;参考&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;
        ##
    &lt;/a&gt;
    参考
&lt;/div&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CV-xueba/A01_cvclass_basic&#34;&gt;CS231A 鲁鹏&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kth.instructure.com/courses/6163&#34;&gt;DD2429 from KTH&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>哈希计算图片相似性</title>
      <link>/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</link>
      <pubDate>Mon, 03 Jun 2019 15:19:04 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2019/06/%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E7%9B%B8%E4%BC%BC%E6%80%A7/</guid>
      <description>&lt;!--toc--&gt;
&lt;h1 id=&#34;ahash平均哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#ahash%e5%b9%b3%e5%9d%87%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    aHash（平均哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;将图片缩小到8x8的尺寸&lt;/li&gt;
&lt;li&gt;将缩小后的图片转换成灰度图&lt;/li&gt;
&lt;li&gt;计算8x8图片所有像素灰度值的平均值&lt;/li&gt;
&lt;li&gt;创建一个新的8x8矩阵，矩阵的每个值取值为0或1，计算方法是将原矩阵中对应像素的的灰度值与平均值进行对比，当大于等于平均值时记1，小于平均值时记0&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def ahash(filepath):
    img = cv2.imread(filepath)
    small = cv2.resize(img, (8, 8), interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    fp = 0
    mean = gray.mean()
    w, h = gray.shape
    for x in range(w):
        for y in range(h):
            if gray[x][y] &amp;gt;= mean:
                fp += ((fp &amp;lt;&amp;lt; 1) + 1)
            else:
                fp += ((fp &amp;lt;&amp;lt; 1) + 0)
    return fp
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;dhash差值哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#dhash%e5%b7%ae%e5%80%bc%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    dHash（差值哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def dhash(filepath):
    img = cv2.imread(filepath)
    small = cv2.resize(img, (9, 8), interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    fp = 0
    mean = gray.mean()
    w, h = gray.shape
    for x in range(w-1):
        for y in range(h):
            # if the pixel on the left is brighter mark it as 1
            if gray[x][y] &amp;gt; gray[x+1][y]:
                fp += ((fp &amp;lt;&amp;lt; 1) + 1)
            else:
                fp += ((fp &amp;lt;&amp;lt; 1) + 0)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;phash感知哈希&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#phash%e6%84%9f%e7%9f%a5%e5%93%88%e5%b8%8c&#34;&gt;
        ##
    &lt;/a&gt;
    pHash（感知哈希）
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;pHash算法主要是使用了离散余弦变换（DCT）进行转换。&lt;/p&gt;
&lt;p&gt;利用感知哈希算法计算图片相似度
计算步骤：&lt;/p&gt;
&lt;p&gt;缩放图片：一般大小为32*32，这样方便DCT计算&lt;/p&gt;
&lt;p&gt;简化色彩，转化为灰度图：可以使用Image的convert(&amp;lsquo;L&amp;rsquo;)方法&lt;/p&gt;
&lt;p&gt;计算DCT（离散余弦变换）:&lt;/p&gt;
&lt;p&gt;获得图像的二维数据矩阵f(x,y)&lt;/p&gt;
&lt;p&gt;求离散余弦变换的系数矩阵[A]&lt;/p&gt;
&lt;p&gt;求系数矩阵对应的转置矩阵[A]T&lt;/p&gt;
&lt;p&gt;根据公式[F(u,v)]=[A][f(x,y)][A]T 计算离散余弦变换
缩小DCT：DCT计算后的矩阵是32&lt;em&gt;32，保留左上角的8&lt;/em&gt;8，这些代表的图片的最低频率&lt;/p&gt;
&lt;p&gt;计算平均值：计算缩小DCT后的所有像素点的平均&lt;/p&gt;
&lt;p&gt;进一步减小DCT：大于平均值记录为1，否则为0&lt;/p&gt;
&lt;p&gt;得到64位信息指纹&lt;/p&gt;
&lt;p&gt;记录两张图片的图像指纹的汉明距离，计算图片相似度&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def phash(filepath, shape=(1, 1)):
    fp = np.zeros(shape, dtype=np.ulonglong)
    try:
        img = cv2.imread(filepath)
        resize = cv2.resize(img, (32, 32))
        gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)
    except Exception as e:
        print(&amp;#39;-&amp;#39;*80)
        print(&amp;#39;Exception: image [%s]&amp;#39; % filepath)
        print(e)
        print(&amp;#39;-&amp;#39;*80)
        return fp

    left_upper = cv2.dct(gray.astype(float))[:8, :8]
    mean = left_upper.mean()
    h, w = left_upper.shape
    for x in range(w):
        for y in range(h):
            val = int(fp[y//8, x//8])
            if left_upper[y, x] &amp;gt;= mean:
                fp[y//8, x//8] = ((val &amp;lt;&amp;lt; 1) | 1)
            else:
                fp[y//8, x//8] = ((val &amp;lt;&amp;lt; 1) | 0)
    return fp
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;直方图&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%9b%b4%e6%96%b9%e5%9b%be&#34;&gt;
        ##
    &lt;/a&gt;
    直方图
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nivance/image-similarity&#34;&gt;https://github.com/nivance/image-similarity&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nivance/image-similarity/blob/master/src/main/java/image/similarity/ImageHistogram.java&#34;&gt;https://github.com/nivance/image-similarity/blob/master/src/main/java/image/similarity/ImageHistogram.java&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;直方图算法是对源图像与要筛选的图像进行直方图数据采集，对采集的各自图像直方图进行归一化再使用巴氏系数算法对直方图数据进行计算，最终得出图像相似度值，其值范围在[0, 1]之间0表示极其不同，1表示极其相似（相同）。&lt;/p&gt;
&lt;p&gt;算法步骤大致可以分为两步，根据源图像与候选图像的像素数据，生成各自直方图数据。第二步：使用第一步输出的直方图结果，运用巴氏系数（Bhattacharyya coefficient）算法，计算出相似程度值。&lt;/p&gt;
&lt;p&gt;第一步：直方图计算 直方图分为灰度直方图与RGB直方图，对于灰度图像直方图计算十分简单，只要初始化一个大小为256的直方图数组H，然后根据像素值完成频率分布统计，假设像素值为124，则H[124] += 1, 而对于彩色RGB像素来说直方图表达有两种方式，一种是单一直方图，另外一种是三维直方图，三维直方图比较简单明了，分别对应RGB三种颜色，定义三个直方图HR,HG, HB, 假设某一个像素点P的RGB值为(4, 231,129), 则对于的直方图计算为HR[4] += 1,HG[231] += 1, HB[129] += 1, 如此对每个像素点完成统计以后，RGB彩色直方图数据就生成了。 而RGB像素的单一直方图SH表示稍微复杂点，每个颜色的值范围为0 ~ 255之间的，假设可以分为一定范围等份，当8等份时，每个等份的值范围为32， 16等份时，每个等份值范围为16，当4等份时候，每个等份值的范围为64，假设RGB值为(14, 68, 221), 16等份之后，它对应直方图索引值(index)分别为: (0, 4, 13), 根据计算索引值公式:index = R + G * 16 + B * 16 * 16 对应的直方图index = 0 + 4 * 16 + 13 * 16 * 16， SH[3392] += 1如此遍历所有RGB像素值，完成直方图数据计算。&lt;/p&gt;
&lt;p&gt;第二步：巴氏系数计算，计算公式如下：$\sum_{i=1}^N\sqrt{p(i)p^{&amp;rsquo;}(i)}$ 。其中p, p&amp;rsquo;分别代表源与候选的图像直方图数据，对每个相同i的数据点乘积开平方以后相加得出的结果即为图像相似度值（巴氏系数因子值），范围为0到1之间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cse.yorku.ca/~kosta/CompVis_Notes/bhattacharyya.pdf&#34;&gt;Bhattacharyya Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;其他思想&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%85%b6%e4%bb%96%e6%80%9d%e6%83%b3&#34;&gt;
        ##
    &lt;/a&gt;
    其他思想
&lt;/div&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;大津法&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%a4%a7%e6%b4%a5%e6%b3%95&#34;&gt;
        #
    &lt;/a&gt;
    大津法
&lt;/div&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html&#34;&gt;Otsu Thresholding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html&#34;&gt;阮一峰blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1979年，日本学者大津展之证明了，&amp;ldquo;类内差异最小&amp;quot;与&amp;quot;类间差异最大&amp;quot;是同一件事，即对应同一个阈值。他提出一种简单的算法，可以求出这个阈值，这被称为&amp;quot;大津法&amp;rdquo;（Otsu&amp;rsquo;s method）。下面就是他的计算方法。&lt;/p&gt;
&lt;p&gt;假定一张图片共有n个像素，其中灰度值小于阈值的像素为 n1 个，大于等于阈值的像素为 n2 个（ n1 + n2 = n ）。w1 和 w2 表示这两种像素各自的比重。
　　w1 = n1 / n
　　w2 = n2 / n
再假定，所有灰度值小于阈值的像素的平均值和方差分别为 μ1 和 σ1，所有灰度值大于等于阈值的像素的平均值和方差分别为 μ2 和 σ2。于是，可以得到
　　类内差异 = w1(σ1的平方) + w2(σ2的平方)
　　类间差异 = w1w2(μ1-μ2)^2
可以证明，这两个式子是等价的：得到&amp;quot;类内差异&amp;quot;的最小值，等同于得到&amp;quot;类间差异&amp;quot;的最大值。不过，从计算难度看，后者的计算要容易一些。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>图像卷积实践</title>
      <link>/2017/07/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 30 Jul 2017 18:30:50 +0800</pubDate>
      <author>**Email:** [singleye512@gmail.com](mailto:singleye512@gmail.com) (singleye)</author>
      <guid>/2017/07/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E5%AE%9E%E8%B7%B5/</guid>
      <description>&lt;p&gt;最近对图像识别技术很感兴趣，了解到在这个领域中CNN的应用可以比较有效的解决问题，这里对卷积（convolution）相关的知识进行一下记录说明。&lt;/p&gt;
&lt;h1 id=&#34;图像卷积是什么&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e5%9b%be%e5%83%8f%e5%8d%b7%e7%a7%af%e6%98%af%e4%bb%80%e4%b9%88&#34;&gt;
        ##
    &lt;/a&gt;
    图像卷积是什么？
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;将一张图片看作一张像素的矩阵的话，卷积就是把另一个矩阵（卷积核）在这张图片上移动，在移动的过程中取图片上对应大小的矩阵与卷积核进行运算，每次矩阵运算得出的结果保存成一个新的像素，这个过程就是图像的卷积运算。&lt;/p&gt;
&lt;p&gt;卷积的过程可以用下面的示意图展示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=536&amp;amp;h=392&#34; alt=&#34;图像卷积过程&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/convolution-001.png&#34; alt=&#34;卷积计算&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;为什么做卷积&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e4%b8%ba%e4%bb%80%e4%b9%88%e5%81%9a%e5%8d%b7%e7%a7%af&#34;&gt;
        ##
    &lt;/a&gt;
    为什么做卷积？
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;一张原始图像包含了大量的噪音信息，这些噪音信息会干扰后续的运算过程。如果将一张图像看作一个输入信号的话，如果找到一种过滤器将噪音信息过滤掉就可以提高后续运算的准确度。卷积就是这么一个过滤器，这个过滤器的正式称呼是卷积核。&lt;/p&gt;
&lt;p&gt;那么这个过滤器可以做些什么呢？其实常见的图像处理软件早已经在使用卷积进行图片处理了，比如图像锐化、模糊、浮雕效果等等&amp;hellip;&lt;/p&gt;
&lt;p&gt;下面收集了一些常用的过滤器，对这张图片处理后可以看一下效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/mini.png?x-oss-process=style/png2jpg&#34; alt=&#34;原图&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像边界检测&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
-1 &amp; -1 &amp; -1 \\
-1 &amp; 8 &amp; -1 \\
-1 &amp; -1 &amp; -1
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/edge.png?x-oss-process=style/png2jpg&#34; alt=&#34;边界检测&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像模糊&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 0
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/blur.png?x-oss-process=style/png2jpg&#34; alt=&#34;模糊&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像锐化&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
-1 &amp; -1 &amp; -1 \\
-1 &amp; 9 &amp; -1 \\
-1 &amp; -1 &amp; -1
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/sharpen.png?x-oss-process=style/png2jpg&#34; alt=&#34;锐化&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;浮雕&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
$$
\left[
\begin{matrix}
-1 &amp; -1 &amp; 0 \\
-1 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 1
\end{matrix}
\right]
$$
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/07/emboss.png?x-oss-process=style/png2jpg&#34; alt=&#34;浮雕&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;用numpy进行卷积计算&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#%e7%94%a8numpy%e8%bf%9b%e8%a1%8c%e5%8d%b7%e7%a7%af%e8%ae%a1%e7%ae%97&#34;&gt;
        ##
    &lt;/a&gt;
    用numpy进行卷积计算
&lt;/div&gt;
&lt;/h1&gt;
&lt;p&gt;以上的图片使用下面的算法生成，主要使用了numpy的array进行的计算。通过该算法生成的图片效果还不够理想：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;比如锐化及浮雕效果，锐化的边缘有些益处而其他部分亮度有些降低&lt;/li&gt;
&lt;li&gt;浮雕的效果感觉也不够明显&lt;/li&gt;
&lt;li&gt;程序执行速度有些慢&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    def convolution(self, kernel):
        &amp;#34;&amp;#34;&amp;#34;
        Create a new Image instance by applying the kernel
        &amp;#34;&amp;#34;&amp;#34;
        print &amp;#34;Run convolution transform&amp;#34;
        print &amp;#34;Start: %s&amp;#34; % time.ctime()

        k_height, k_width = kernel.shape
        n_width = self.width - k_width + 1
        n_height = self.height - k_height + 1

        if self.color_space == COLOR_SPACE_BW:
            new_img_data = np.zeros((n_height, n_width), dtype=self.img.dtype)
            channel_kernel = kernel
        elif self.color_space == COLOR_SPACE_RGB:
            new_img_data = np.zeros((n_height, n_width, 3), dtype=self.img.dtype)
            channel_kernel = np.zeros((k_height, k_width, 3))
            for c in range(3):
                channel_kernel[:,:,c] = kernel
        elif self.color_space == COLOR_SPACE_RGBA:
            # drop the alpha channel
            new_img_data = np.zeros((n_height, n_width, 3), dtype=self.img.dtype)
            channel_kernel = np.zeros((k_height, k_width, 3))
            for c in range(3):
                channel_kernel[:,:,c] = kernel
        else:
            print &amp;#34;Unknow color space&amp;#34;
            return None

        for y in range(n_height):
            for x in range(n_width):
                if self.color_space == COLOR_SPACE_RGBA:
                    new_img_data[y][x] = sum(sum(self.img[y:y+k_height, x:x+k_width,:3]*channel_kernel))
                else:
                    new_img_data[y][x] = sum(sum(self.img[y:y+k_height, x:x+k_width]*channel_kernel))

        imax = np.max(self.img)
        nmax = np.max(new_img_data)
        scale = 1.0*imax/nmax
        print &amp;#34;imax[{0}], nmax[{1}]&amp;#34;.format(imax, nmax)
        print &amp;#34;Scale:&amp;#34;, scale
        new_img_data = (new_img_data * scale).astype(self.img.dtype)

        print &amp;#34;End: %s&amp;#34; % time.ctime()

        new_image = Image()
        new_image.load_data(new_img_data)

        return new_image
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;完整的程序可以在&lt;a href=&#34;https://github.com/singleye/MachineLearning/blob/master/convolution/convolution.py&#34;&gt;GitHub&lt;/a&gt;上找到。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

<!DOCTYPE html>


<html lang="zh-cn" data-theme="">
<head>
    
        
<meta charset="utf-8">
<meta name="HandheldFriendly" content="True">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer-when-downgrade">

<title>神经网络之反向传播算法 - singleye</title>

<meta name="description" content="之前使用神经网络算法的时候并没有认真总结关键的算法，虽然可以用但总觉得不爽，于是这两天对神经网络算法中的反向传播（Back Propagation）进行了推导。即理解了算法的数学本质，也对神经网络算法的工程特性有了深刻体会，工程算法真的是以解决问题为驱动的，追求的是解决问题的实用性。">


    <meta name="keywords" content="BP,BackPropagation,反向传播">




<link rel="icon" type="image/x-icon" href="https://www.singleye.net/favicon.ico">
<link rel="apple-touch-icon-precomposed" href="https://www.singleye.net/favicon.png">








    



<style>
  body {
    visibility: hidden;
    opacity: 0;
  }
</style>

<noscript>
  <style>
    body {
      visibility: visible;
      opacity: 1;
    }
  </style>
</noscript>




    





    
    
        
    
    

    
        <link rel="stylesheet" href="/css/style.min.184a655c5ad8596648622468e6696abf0cf0a2cf8266df17b4f7a36fe9c97551.css" integrity="sha256-GEplXFrYWWZIYiRo5mlqvwzwos&#43;CZt8XtPejb&#43;nJdVE=">
    





    





    
    
        
    
    

    
        <link rel="stylesheet" href="/css/style.min.c4c04b3ef88e3d619ad4c7ee5e03048422bc55c4fefdc1f07657c1133670aa22.css" integrity="sha256-xMBLPviOPWGa1MfuXgMEhCK8VcT&#43;/cHwdlfBEzZwqiI=">
    





    





    
    
        
    
    

    
        <link rel="stylesheet" href="/css/style.min.21c5d8fe0a79d623b0adc1ce4bd4f6dd2c05cd939c9aaaa966ba7186b1464f4d.css" integrity="sha256-IcXY/gp51iOwrcHOS9T23SwFzZOcmqqpZrpxhrFGT00=">
    












    

    





    
    
        
    
    

    
        <script src="/js/script.min.08f04d96386c73c9bf4d160333f8f448c05a6e01c06770542ee0e013954ce930.js" type="text/javascript" charset="utf-8" integrity="sha256-CPBNljhsc8m/TRYDM/j0SMBabgHAZ3BULuDgE5VM6TA="></script>
    



















    
</head>
<body>
    <a class="skip-main" href="#main">Skip to main content</a>
    <div class="container">
        <header class="common-header">
            
                <div class="header-top">
    <div class="header-top-left">
        <h1 class="site-title noselect">
    <a href="/">singleye</a>
</h1>

        







    
        <div class="theme-switcher">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-sun-high"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828a4 4 0 1 0 -5.656 -5.656a4 4 0 0 0 5.656 5.656z" /><path d="M6.343 17.657l-1.414 1.414" /><path d="M6.343 6.343l-1.414 -1.414" /><path d="M17.657 6.343l1.414 -1.414" /><path d="M17.657 17.657l1.414 1.414" /><path d="M4 12h-2" /><path d="M12 4v-2" /><path d="M20 12h2" /><path d="M12 20v2" /></svg>


</span>

        </div>
    

    <script>
        const STORAGE_KEY = 'user-color-scheme'
        const defaultTheme = "light"

        let currentTheme
        let switchButton
        let autoDefinedScheme = window.matchMedia('(prefers-color-scheme: dark)')

        function switchTheme(e) {
            currentTheme = (currentTheme === 'dark') ? 'light' : 'dark';
            if (localStorage) localStorage.setItem(STORAGE_KEY, currentTheme);
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        const autoChangeScheme = e => {
            currentTheme = e.matches ? 'dark' : 'light'
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        document.addEventListener('DOMContentLoaded', function () {
            switchButton = document.querySelector('.theme-switcher')
            currentTheme = detectCurrentScheme()

            if (currentTheme === 'auto') {
                autoChangeScheme(autoDefinedScheme);
                autoDefinedScheme.addListener(autoChangeScheme);
            } else {
                document.documentElement.setAttribute('data-theme', currentTheme)
            }

            if (switchButton) {
                switchButton.addEventListener('click', switchTheme, false)
            }

            showContent();
        })

        function detectCurrentScheme() {
            if (localStorage !== null && localStorage.getItem(STORAGE_KEY)) {
                return localStorage.getItem(STORAGE_KEY)
            }
            if (defaultTheme) {
                return defaultTheme
            }
            return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
        }

        function showContent() {
            document.body.style.visibility = 'visible';
            document.body.style.opacity = 1;
        }

        function changeGiscusTheme (theme) {
            function sendMessage(message) {
              const iframe = document.querySelector('iframe.giscus-frame');
              if (!iframe) return;
              iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
            }

            sendMessage({
              setConfig: {
                theme: theme
              }
            });
        }
    </script>


        <ul class="social-icons noselect">







    <li>
            <a href="/index.xml" title="RSS" rel="me">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-rss"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 19m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" /><path d="M4 4a16 16 0 0 1 16 16" /><path d="M4 11a9 9 0 0 1 9 9" /></svg>


</span>

            </a>
        </li>
    

</ul>

    </div>
    <div class="header-top-right">

    </div>
</div>


    <nav class="noselect">
        
        
        <a class="" href="https://www.singleye.net/" title="">Home</a>
        
        <a class="" href="https://www.singleye.net/categories" title="">Categories</a>
        
        <a class="" href="https://www.singleye.net/tags" title="">Tags</a>
        
        <a class="" href="https://github.com/singleye" title="">GitHub</a>
        
    </nav>



<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>





            
        </header>
        <main id="main" tabindex="-1">
            
    

    <article class="post h-entry">
        <div class="post-header">
            <header>
                <h1 class="p-name post-title">神经网络之反向传播算法</h1>
                

            </header>
            



<div class="post-info noselect">
    
        <div class="post-date dt-published">
            <time datetime="2017-09-25">2017-09-25</time>
            
        </div>
    

    <a class="post-hidden-url u-url" href="/2017/09/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/">/2017/09/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/</a>
    <a href="https://www.singleye.net/" class="p-name p-author post-hidden-author h-card" rel="me"></a>


    <div class="post-taxonomies">
        
            <ul class="post-categories">
                
                    
                    <li><a href="/categories/machine-learning/">Machine Learning</a></li>
                
                    
                    <li><a href="/categories/neural-network/">Neural Network</a></li>
                
            </ul>
        
        
            <ul class="post-tags">
                
                    
                    <li><a href="/tags/bp/">#BP</a></li>
                
                    
                    <li><a href="/tags/backpropagation/">#BackPropagation</a></li>
                
                    
                    <li><a href="">#反向传播</a></li>
                
            </ul>
        
        
    </div>
</div>

        </div>
        

  
  




  
  
  
  <details class="toc noselect">
    <summary>Table of Contents</summary>
    <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#网络拓扑">网络拓扑</a></li>
    <li><a href="#神经元">神经元</a>
      <ul>
        <li><a href="#神经元输入">神经元输入</a></li>
        <li><a href="#神经元加权">神经元加权</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#代价函数">代价函数</a></li>
    <li><a href="#神经元错误量--delta_jl-">神经元错误量 $ \delta_j^{(l)} $</a></li>
    <li><a href="#权重调整及偏置调整">权重调整及偏置调整</a></li>
  </ul>
</nav></div>
  </details>
  



<script>
  var toc = document.querySelector(".toc");
  if (toc) {
    toc.addEventListener("click", function () {
      if (event.target.tagName !== "A") {
        event.preventDefault();
        if (this.open) {
          this.open = false;
          this.classList.remove("expanded");
        } else {
          this.open = true;
          this.classList.add("expanded");
        }
      }
    });
  }
</script>

        <div class="content e-content">
            <!-- more /-->
<p>之前使用神经网络算法的时候并没有认真总结关键的算法，虽然可以用但总觉得不爽，于是这两天对神经网络算法中的反向传播（Back Propagation）进行了推导。即理解了算法的数学本质，也对神经网络算法的工程特性有了深刻体会，工程算法真的是以解决问题为驱动的，追求的是解决问题的实用性。</p>
<h1 id="神经网络" >
<div>
    <a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c">
        ##
    </a>
    神经网络
</div>
</h1>
<h2 id="网络拓扑" >
<div>
    <a href="#%e7%bd%91%e7%bb%9c%e6%8b%93%e6%89%91">
        #
    </a>
    网络拓扑
</div>
</h2>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neural-network.jpg" alt="神经网络"></p>
<h2 id="神经元" >
<div>
    <a href="#%e7%a5%9e%e7%bb%8f%e5%85%83">
        #
    </a>
    神经元
</div>
</h2>
<p>神经元是神经网络的基本构成，上图的每一个圆圈代表了一个神经元。每一个神经元有一个输入和一个输出，神经元的作用是对输入值进行计算。下图是一个神经元的简单示意图：</p>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron.jpg" alt="神经元"></p>
<ul>
<li>该神经元的输出：$ a=f(z)=sigmoid(z) $</li>
</ul>
<h3 id="神经元输入" >
<div>
    <a href="#%e7%a5%9e%e7%bb%8f%e5%85%83%e8%be%93%e5%85%a5">
        ##
    </a>
    神经元输入
</div>
</h3>
<p>在一个复杂点的神经网络中，一个神经元接收来自多个前级神经元的激活输出，并进行加权相加后产生该神经元的输入值，这个过程示意图如下：</p>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-input.jpg" alt="neuron-input"></p>
<p>定义第 $ l^{th} $ 层第 $ j^{th} $ 个神经元的输入：</p>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-input-equation.png" alt="神经元输入"></p>
<h3 id="神经元加权" >
<div>
    <a href="#%e7%a5%9e%e7%bb%8f%e5%85%83%e5%8a%a0%e6%9d%83">
        ##
    </a>
    神经元加权
</div>
</h3>
<p>神经元的加权结构可以看下面的示意图：</p>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-weight.jpg" alt="neuron-weight"></p>
<p>注，第一层神经元的输入就是采样数据，不需要计算z值，这层采样数据直接通过权重计算输入到第二层的神经元。</p>
<h1 id="反向传播算法" >
<div>
    <a href="#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e7%ae%97%e6%b3%95">
        ##
    </a>
    反向传播算法
</div>
</h1>
<h2 id="代价函数" >
<div>
    <a href="#%e4%bb%a3%e4%bb%b7%e5%87%bd%e6%95%b0">
        #
    </a>
    代价函数
</div>
</h2>
<p>定义代价函数：$ cost = {1 \over 2} \sum (y^{(i)} - a^{(i)})^2 $</p>
<h2 id="神经元错误量--delta_jl-" >
<div>
    <a href="#%e7%a5%9e%e7%bb%8f%e5%85%83%e9%94%99%e8%af%af%e9%87%8f--delta_jl-">
        #
    </a>
    神经元错误量 $ \delta_j^{(l)} $
</div>
</h2>
<p>每个神经元的输入记为&rsquo;z&rsquo;，经过激活函数&rsquo;f(z)&lsquo;生成激活值&rsquo;a&rsquo;，通常情况下激活函数使用sigmoid()。那么假设对于每个神经元的输入&rsquo;z&rsquo;做一点微小的改变记为 $ \Delta z $，由这个改变引起的代价变化记为这个神经元的错误量 $ \delta_j^{(l)} $，从这个定义可以看出来这是一个代价函数相对于神经元的输入&rsquo;z&rsquo;的偏导数。</p>
<p>定义 $ \delta_j^{(l)} $ 为 $ l^{th} $ 层中的第 $ j^{th} $ 个神经元的错误量，记作：$ \delta_j^{(l)} =\frac{\partial C}{\partial z_j^{(l)}} $</p>
<p>经过数学推导可以得出结论：</p>
<ul>
<li>最后一层（L层）第j个神经元的错误量：</li>
</ul>
$$ \delta_j^{(L)} = -(y-a_j^{(L)}) \bigodot [a_j^{(L)}(1-a_j^{(L)})] $$
<p>简单推导若成如下：</p>
$$ \delta_j^{(L)} = \frac{\partial C}{\partial z_j^{(l)}} $$
$$ \frac{\partial C}{\partial z_j^{(l)}} = \frac{\partial C}{\partial a_j^{(L)}} \frac{\partial a_j^{(L)}}{\partial z_j^{(L)}} $$
$$ \frac{\partial C}{\partial a_j^{(L)}} \frac{\partial a_j^{(L)}}{\partial z_j^{(L)}} = -(y-a_j^{(L)}) \bigodot [a_j^{(L)}(1-a_j^{(L)})] $$
<p>y：采样的结果</p>
<p>$ a_j^{(L)} $：样本输入计算的结果</p>
<ul>
<li>其余各层(l层)第j个神经元的错误量：</li>
</ul>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/delta-layer-l.png" alt="delta-equation"></p>
<p>因为首先可以算出来每一层的激活量 $ a_j^{(l)} $，那么可以看出来除了最后一层外的其他层的错误量可以靠后面一层的错误量计算出来，直至推算到最后一层 $ \delta_j^{(L)} $。</p>
<p>因此反向传播算法也就是从最后一层往前一层一层计算的过程，与计算激活量的方向正好相反，因此得名反向传播。</p>
<h2 id="权重调整及偏置调整" >
<div>
    <a href="#%e6%9d%83%e9%87%8d%e8%b0%83%e6%95%b4%e5%8f%8a%e5%81%8f%e7%bd%ae%e8%b0%83%e6%95%b4">
        #
    </a>
    权重调整及偏置调整
</div>
</h2>
<p>观察每个神经元的输入可以发现神经网络计算过程中最重要的是要确定两个量权重w和偏置b。</p>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/neuron-input-equation.png" alt="神经元输入"></p>
<p>仿照错误量计算方法将问题进行一下转化，是否可以计算出代价函数相对于权重和偏置的变化速率（偏微分），然后通过乘以一个小数字（学习速率）来一点一点降低代价函数的输出，从而逼近最终需要的权重及偏置值呢？</p>
<p>因此可以将问题转化为求 $ \frac{\partial C}{\partial w_{jk}^{(l)}} $ 和 $ \frac{\partial C}{\partial b_j^{(l)}} $</p>
<p>通过推导可以得出：</p>
$$ \frac{\partial C}{\partial w_{jk}^{(l)}} = \delta_j^{(l+1)} a_k^{(l)} $$
$$ \frac{\partial C}{\partial b_{jk}^{(l)}} = \delta_j^{(l)} $$
<p>基于前面对于错误量 $ \delta_j^{(l)} $ 就可以非常简单的得到相应的结果。</p>
<p>那么最终对于权重及偏置的调整可以这样做：</p>
$$ w = w-\eta \frac{\partial C}{\partial w_{jk}^{(l)}} $$
$$ b = b-\eta \frac{\partial C}{\partial b_{jk}^{(l)}} $$
<p>其中 $ \eta $ 是一个非常小的正数，这个数字也被叫做“学习速率”，通过这个值的调整可以控制拟合的速度。</p>
<h1 id="推导过程" >
<div>
    <a href="#%e6%8e%a8%e5%af%bc%e8%bf%87%e7%a8%8b">
        ##
    </a>
    推导过程
</div>
</h1>
<p>前面的部分直接使用了结论，实际推到过程比较啰嗦，markdown直接编写公式也不方便，索性把推到过程的草稿贴出来参考好了</p>
<p>:-)</p>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/derivation-process.JPG?x-oss-process=style/png2jpg" alt="推导过程"></p>
<h1 id="实验代码" >
<div>
    <a href="#%e5%ae%9e%e9%aa%8c%e4%bb%a3%e7%a0%81">
        ##
    </a>
    实验代码
</div>
</h1>
<p>做一个简单的神经网络实验，网络设计为3层，第一层对应3个输入，第二层用4个神经元，第三层为输出层使用1个神经元。</p>
<p>网络初始化过程如下：</p>
<pre><code># network design:
# input(layer_1): 3 nodes
#    weights: 3x4 matrix
# layer_2: 4 nodes
#    weights: 4x1 matrix
# output: 1 node

# create training data
input = np.array([[0, 0, 1],
                 [0, 1, 0],
                 [0, 1, 1],
                 [1, 0, 0],
                 [1, 0, 1]])

# create the label related with the input training data
output = np.array([[0],
                  [1],
                  [0],
                  [1],
                  [1]])

# initialize random weight
weight_layer_1 = np.random.rand(3, 4)
weight_layer_2 = np.random.rand(4, 1)
</code></pre>
<p>训练过程主要代码：</p>
<pre><code># x/y is for drawing chart
x=[]
y=[]

# learning rate
eta = 0.1

loop = 0
while loop &lt; 50000:
    # feed forward calculation
    z_layer_2 = np.dot(input, weight_layer_1)
    a_layer_2 = sigmoid(z_layer_2)

    z_layer_3 = np.dot(a_layer_2, weight_layer_2)
    a_layer_3 = sigmoid(z_layer_3)
    
    if loop % 100 == 0:
        # calculate the cost
        c = cost(output, a_layer_3)
        print &quot;[%d] Cost: %f&quot; % (loop, c)
        print &quot;Perception: &quot;, a_layer_3
        x.append(loop)
        y.append(c)
    loop += 1
    
    # back propagation
    # calculate delta_3
    delta_layer_3 = cost_derivative(output, a_layer_3)*deriv_z(a_layer_3)
    
    # calculate delta_2
    delta_layer_2 = np.dot(delta_layer_3, weight_layer_2.T)*deriv_z(a_layer_2)
    
    # there is NO delta_layer_1, since layer1 is the input layer

    # calculate new weight for layer 2
    weight_layer_2 -= eta*np.dot(a_layer_2.T, delta_layer_3)
    
    # calculate new weight for layer 1
    weight_layer_1 -= eta*np.dot(input.T, delta_layer_2)
</code></pre>
<p>上面代码可以观察到每100次计算修正后的代价函数输出以及预测值，可以发现代价值在逐渐趋近于0，说明误差在降低，预测值越来越接近实际采样的数值。</p>
<p>为了更加清晰的看到这个过程，把x/y输出在图上进行查看，可以观察到拟合过程，并且可以看到拟合的速度变化情况。</p>
<pre><code>import matplotlib.pyplot as plt
plt.plot(x, y)
plt.xlabel(&quot;Epoch&quot;)
plt.ylabel(&quot;Cost&quot;)
plt.show()
</code></pre>
<p><img src="http://singleye-public-read.oss-cn-shanghai.aliyuncs.com/singleye.net/static/2017/09/BP-experiment/cost-epoch.png" alt="拟合过程"></p>
<p><a href="https://github.com/singleye/MachineLearning/blob/master/NeuralNetwork/BackPropagation/experiment-back-propagation.ipynb">完整代码</a></p>
<h1 id="参考" >
<div>
    <a href="#%e5%8f%82%e8%80%83">
        ##
    </a>
    参考
</div>
</h1>
<p><a href="https://www.youtube.com/watch?v=mOmkv5SI9hU&amp;list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&amp;index=52">https://www.youtube.com/watch?v=mOmkv5SI9hU&amp;list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&amp;index=52</a></p>
<p><a href="http://www.cnblogs.com/charlotte77/p/5629865.html">http://www.cnblogs.com/charlotte77/p/5629865.html</a></p>

        </div>

    </article>

    
    

    
        
        
    

    

    
        
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "singleye" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>











    

    

    

        </main>
        
            <footer class="common-footer noselect">
    
    

    <div class="common-footer-bottom">
        

        <div style="display: flex; align-items: center; gap:8px">
            © singleye, 2024
            
        </div>
        <div style="display:flex;align-items: center">
            
            
            
            
            
            
        </div>
        <div>
            Powered by <a target="_blank" rel="noopener noreferrer" href="https://gohugo.io/">Hugo</a>, theme <a target="_blank" rel="noopener noreferrer" href="https://github.com/Junyi-99/hugo-theme-anubis2">Anubis2</a>.<br>
            

        </div>
    </div>

    <p class="h-card vcard">

    <a href=https://www.singleye.net/ class="p-name u-url url fn" rel="me"></a>

    

    
</p>

</footer>

        
    </div>
</body>
</html>
